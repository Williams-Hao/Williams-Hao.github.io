<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="All greatness comes from the beginning of courage" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="所有的伟大,源于一个勇敢的开始">
<meta property="og:url" content="https://williams-hao.github.io/index.html">
<meta property="og:site_name" content="所有的伟大,源于一个勇敢的开始">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="所有的伟大,源于一个勇敢的开始">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://williams-hao.github.io/"/>





  <title>所有的伟大,源于一个勇敢的开始</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">所有的伟大,源于一个勇敢的开始</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">所有的伟大,源于一个勇敢的开始</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/07/13/后向传播-BP-算法推导与实现/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/13/后向传播-BP-算法推导与实现/" itemprop="url">后向传播(BP)算法推导与实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-13T11:52:44+08:00">
                2017-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="原理推导"><a href="#原理推导" class="headerlink" title="原理推导"></a>原理推导</h1><p><img src="/img/BP_推导1.JPG" alt="Alt text"><br><img src="/img/BP_推导2.JPG" alt="Alt text"><br><img src="/img/BP_推导3.JPG" alt="Alt text"></p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/07/11/几种回归算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/11/几种回归算法/" itemprop="url">几种回归算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-11T09:55:39+08:00">
                2017-07-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-回归/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-回归</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="几种回归算法"><a href="#几种回归算法" class="headerlink" title="几种回归算法"></a>几种回归算法</h1><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p><code>目的：预测数值型的目标值</code><br> <strong>做法：用曲线去拟合数据的趋势,达到预测未知数据的目的</strong></p>
<blockquote>
<p>损失函数：平方损失函数</p>
</blockquote>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>求一组参数，使得和数据拟合较好，使得损失函数最小化。</p>
<p><code>画出一条直线</code><br><img src="http://img.blog.csdn.net/20160514123333785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="enter image description here"></p>
<h3 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h3><p>此文公式推导有点问题： <a href="http://www.cnblogs.com/softlin/p/5965939.html" target="_blank" rel="external">该文写得好，不忍赘述</a></p>
<p><a href="http://www.cnblogs.com/GuoJiaSheng/p/3928160.html" target="_blank" rel="external">下面图片摘自</a><br><img src="http://images.cnitblog.com/blog2015/633472/201503/262037556613399.jpg" alt="enter image description here"><br>  假设有训练数据<br>  <img src="http://images.cnitblog.com/blog2015/633472/201503/262041198028564.jpg" alt="enter image description here"><br>  那么为了方便我们写成矩阵的形式</p>
<p><img src="http://images.cnitblog.com/blog2015/633472/201503/262042295678545.jpg" alt="enter image description here"></p>
<p>损失函数：</p>
<blockquote>
<ul>
<li>J(w) = Σ(y<sub>i</sub> - h<sub>w</sub>(xi) )<sup>2</sup><br>=(Y-XW)<sup>T</sup>(Y-XW)<br>=(Y<sup>T</sup> - (XW)<sup>T</sup>) <em> (Y-XW)<br>=(Y<sup>T</sup> - W<sup>T</sup>X<sup>T</sup>) </em> (Y - XW)<br>=Y<sup>T</sup>Y - Y<sup>T</sup>XW - W<sup>T</sup>X<sup>T</sup>Y +  W<sup>T</sup>X<sup>T</sup>XW<br>=Y<sup>T</sup>Y - 2W<sup>T</sup>X<sup>T</sup>Y  +  W<sup>T</sup>X<sup>T</sup>XW</li>
</ul>
<p>这里： Y<sup>T</sup>XW  == W<sup>T</sup>X<sup>T</sup>Y</p>
<ul>
<li>因为：<br>  Y.shape=(m,1)<br>  X.shape=(m,n)<br>  W.shape=(n,1)<br>  Y<sup>T</sup>XW = (1,m) <em> (m,n) </em> (n,1) = (1,1)  即一个数<br>  W<sup>T</sup>X<sup>T</sup>Y = (1,n) <em> (n,m) </em> (m,1) = (1,1)  即一个数<br>  故两者相等</li>
</ul>
</blockquote>
<p><img src="http://images2015.cnblogs.com/blog/84976/201610/84976-20161016091207452-1108130635.png" alt="enter image description here"></p>
<p>故：J对W求导得：<br>-2X<sup>T</sup>Y + 2X<sup>T</sup>XW</p>
<p>令其等于0，得：<br>X<sup>T</sup>Y = X<sup>T</sup>XW</p>
<blockquote>
<ul>
<li>W =  (X<sup>T</sup>X)<sup>-1</sup>X<sup>T</sup>Y</li>
</ul>
</blockquote>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><code>standRegres()</code></p>
<h2 id="局部加权线性回归"><a href="#局部加权线性回归" class="headerlink" title="局部加权线性回归"></a>局部加权线性回归</h2><h3 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h3><p><code>线性回归存在的问题：有可能出现欠拟合现象</code><br><strong>因为它求的是具有最小均方误差的无偏估计</strong></p>
<p>所以，允许在估计中引入一些偏差，从而降低预测的均方误差</p>
<p><code>无偏估计:</code></p>
<blockquote>
<ul>
<li>其实就是样本均值的期望等于总体均值。</li>
</ul>
<ul>
<li>无偏估计啊。。。。<br>设总体均值为μ，样本均值为$\bar{x}$<br>无偏估计就是：<br>E( $\bar{x}$ ) =$\mu$<br>这么说吧：<br>同一个总体，一次抽样什么幺蛾子都有可能出现。<br>但是只要你肯一直坚持不懈的抽样下去，每次的样本均值的均值，还等于总体均值——就是无偏的。</li>
</ul>
</blockquote>
<h3 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h3><p><strong>给预测点附近的每一个点都赋予权重。随着样本点与待预测点距离递增，权重将以指数级衰减</strong></p>
<p>这里的$\theta$ 即是上面的W</p>
<p>损失函数J：<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fhluk3edkrj203j018q2p.jpg" alt=""><br>矩阵形式表示：<br>J=(Y-X$$\theta$$)<sup>T</sup>W(Y-X$$\theta$$)</p>
<blockquote>
<ul>
<li><p>W是一个对角矩阵W[i][i] 代表第i个数据的权重</p>
</li>
<li><p>与线性回归类似,中间多了一个W<br>这是高斯核权重：<br>  $$w(i,i) = exp(\frac{\left|x^i-x\right|}{-2k^2})$$</p>
</li>
</ul>
</blockquote>
<p>J=Y<sup>T</sup>WY - 2$\theta$<sup>T</sup>X<sup>T</sup>WY  +  $\theta$<sup>T</sup>X<sup>T</sup>WX$\theta$</p>
<p>J对$\theta$求导：<br>-2 X<sup>T</sup>WY + 2 X<sup>T</sup>WX$\theta$ = 0<br>得：</p>
<blockquote>
<ul>
<li>$\theta$ = (X<sup>T</sup>WX)<sup>-1</sup>X<sup>T</sup>WY</li>
</ul>
</blockquote>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p><code>lwlr()、lwlrTest()</code></p>
<p>当k=1.0时，权重很大，相当于将所有数据视为等权重，得出的最佳拟合直线与标准线性回归一致：<br><img src="http://img.blog.csdn.net/20151017110514600" alt="enter image description here"></p>
<p>当使用k=0.01时：<br><img src="http://img.blog.csdn.net/20151017110736544" alt="enter image description here"></p>
<p>当使用k=0.003时：<br><img src="http://img.blog.csdn.net/20151017110917633" alt="enter image description here"></p>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><h3 id="思想-2"><a href="#思想-2" class="headerlink" title="思想"></a>思想</h3><p>　岭回归又称脊回归，它的名字来源于模型的解与正则化参数λ之间的图像</p>
<p>问题：线性回归使用最小二乘法会遇到问题：X<sup>T</sup>X是否可逆 &lt;=&gt;X是否可逆</p>
<blockquote>
<ul>
<li>|A|=0 &lt;=&gt;A不可逆&lt;=&gt;奇异矩阵&lt;=&gt;非满秩矩阵</li>
<li>r(A)=r(A<sup>T</sup>)=r(AA<sup>T</sup>)=r(A<sup>T</sup>A)<br>证明：<a href="https://www.zybang.com/question/54024709959209a7b4018af3dd7d700d.html" target="_blank" rel="external">这里</a>   或者<a href="https://www.zhihu.com/question/52114460" target="_blank" rel="external">这里</a></li>
</ul>
</blockquote>
<p>为了消除共线性，引入岭回归。增加原矩阵稳定性。使得X<sup>T</sup>X可逆</p>
<p>岭回归(Ridge Regression)是在平方误差的基础上增加正则项（正则化的l2范数）</p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fhluhsie7ej20fu083ab4.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fhforaaaomj23402c0kjl.jpg" alt=""></p>
<p>岭参数选择：<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fhlugf19f2j20fq07kt9p.jpg" alt=""></p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><blockquote>
<ul>
<li>用于在估计中加入偏差，得到更好的估计</li>
<li>通过引入$\lambda$ 来限制所有w之和。</li>
<li>通过引入这个惩罚项，能够减少不重要的参数，也叫shrinkage(缩减)</li>
</ul>
</blockquote>
<p>1.岭回归可以解决特征数量比样本量多的问题<br>2.岭回归作为一种缩减算法可以判断哪些特征重要或者不重要，有点类似于降维的效果<br>3.缩减算法可以看作是对一个模型增加偏差的同时减少方差</p>
<h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><p>需要将数据标准化：所有特征都减去各自的均值并除以方差</p>
<p><code>ridgeRegres()、ridegTest()</code></p>
<p><a href="http://blog.sina.com.cn/s/blog_e386b39f0102vzrv.html" target="_blank" rel="external">好文推荐</a></p>
<h2 id="lasso"><a href="#lasso" class="headerlink" title="lasso"></a>lasso</h2><h3 id="思想-3"><a href="#思想-3" class="headerlink" title="思想"></a>思想</h3><blockquote>
<ul>
<li>lasso是在线性回归基础上增加L1正则项而来的。</li>
<li>L1范数的好处是当$\lambda$充分大时可以把某些待估系数精确地收缩到0。</li>
<li>最小的绝对收缩通过构造一个一阶惩罚函数获得一个精炼的模型，通过最终确定一些指标（变量）的系数为0（岭回归估计系数等于0的机会微乎其微），解释力很强。擅长处理具有多重共线性的数据，与岭回归一样是有偏估计</li>
</ul>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fhfp3y0lopj20dm04v3yj.jpg" alt=""></p>
<h3 id="做法-1"><a href="#做法-1" class="headerlink" title="做法"></a>做法</h3><p><code>前向逐步回归</code><br><img src="http://img.blog.csdn.net/20151121203008782?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="enter image description here"></p>
<h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><p><code>stageWise()</code></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-15</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</div><div class="line"><span class="keyword">import</span> matplotlib</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line">baseDir = <span class="string">'D:\\IT_software\\python_code\MachineLearningInAction\\machinelearninginaction\\Ch08\\'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName=<span class="string">'ex0.txt'</span>)</span>:</span></div><div class="line">    fileName = baseDir + fileName</div><div class="line">    lines = open(fileName).readlines()</div><div class="line">    numFeat = len(lines[<span class="number">0</span>].split(<span class="string">'\t'</span>)) <span class="number">-1</span></div><div class="line">    dataMat = []; labelMat = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</div><div class="line">        lineArr = []</div><div class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeat):</div><div class="line">            lineArr.append(float(curLine[i]))</div><div class="line">        dataMat.append(lineArr)</div><div class="line">        labelMat.append(float(curLine[<span class="number">-1</span>]))</div><div class="line">    <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">standRegres</span><span class="params">(xArr, yArr)</span>:</span></div><div class="line">    xMat = np.mat(xArr); yMat = np.mat(yArr).T</div><div class="line">    xTx = xMat.T * xMat</div><div class="line">    <span class="keyword">if</span> la.det(xTx) == <span class="number">0.0</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'this matrix is singular, cannot do inverse'</span></div><div class="line">        <span class="keyword">return</span></div><div class="line">    ws = xTx.I * (xMat.T * yMat)</div><div class="line">    <span class="keyword">return</span> ws</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcxSort</span><span class="params">(xMat)</span>:</span></div><div class="line">    srtInd = xMat[:, <span class="number">1</span>].argsort(<span class="number">0</span>)</div><div class="line">    xSort = xMat[srtInd][:, <span class="number">0</span>, :]</div><div class="line">    <span class="keyword">return</span> xSort, srtInd</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(xMat, yMat, yHat)</span>:</span></div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line"></div><div class="line">    srtInd = xMat[:, <span class="number">1</span>].argsort(<span class="number">0</span>)</div><div class="line">    xSort = xMat[srtInd][:, <span class="number">0</span>, :]</div><div class="line"></div><div class="line">    ax.plot(xSort[:, <span class="number">1</span>], yHat[srtInd])</div><div class="line"></div><div class="line">    ax.scatter(xMat[:, <span class="number">1</span>].flatten().A[<span class="number">0</span>], yMat.T.flatten().A[<span class="number">0</span>], s=<span class="number">2</span>, c=<span class="string">'red'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># ax.scatter(xMat[:, 1].flatten().A[0], yMat.T[:, 0].flatten().A[0])</span></div><div class="line">    <span class="comment"># xCopy = xMat.copy()</span></div><div class="line">    <span class="comment"># xCopy.sort(0)</span></div><div class="line">    <span class="comment"># yHat = xCopy * ws</span></div><div class="line">    <span class="comment"># ax.plot(xCopy[:, 1], yHat)</span></div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    局部加权线性回归</div><div class="line">    每一个数据点,计算与其他所有点的距离,并计算出每个点对应的权重,随着带预测点和样本点的距离递增,权重会指数级衰减</div><div class="line">    利用这个权重矩阵计算出该点的w,然后与预测点相乘.得到预测值</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lwlr</span><span class="params">(testPoint, xArr, yArr, k=<span class="number">1.0</span>)</span>:</span></div><div class="line">    xMat = np.mat(xArr); yMat = np.mat(yArr).T</div><div class="line">    m = np.shape(xMat)[<span class="number">0</span>]</div><div class="line">    weights = np.mat(np.eye(m))</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</div><div class="line">        diffMat = testPoint - xMat[j, :]</div><div class="line">        weights[j, j] = np.exp(diffMat * diffMat.T / (<span class="number">-2.0</span> * k ** <span class="number">2</span>))</div><div class="line">    xTx = xMat.T * (weights * xMat)</div><div class="line">    <span class="keyword">if</span> la.det(xTx) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'this matrix is singular, cannot do inverse'</span></div><div class="line">        <span class="keyword">return</span></div><div class="line">    ws = xTx.I * (xMat.T * (weights * yMat))</div><div class="line">    <span class="keyword">return</span> testPoint * ws</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lwlrTest</span><span class="params">(testArr, xArr, yArr, k=<span class="number">1.0</span>)</span>:</span></div><div class="line">    m = np.shape(testArr)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> <span class="string">'xarr.shape:&#123;&#125;'</span>.format(np.shape(xArr))</div><div class="line">    yHat = np.zeros(m)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        yHat[i] = lwlr(testArr[i], xArr, yArr, k)</div><div class="line">    <span class="keyword">return</span> yHat</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rssError</span><span class="params">(yArr, yHatArr)</span>:</span></div><div class="line">    <span class="keyword">return</span> ((yArr - yHatArr) ** <span class="number">2</span>).sum()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></div><div class="line">    abX, abY = loadDataSet(<span class="string">'abalone.txt'</span>)</div><div class="line">    yHat01 = lwlrTest(abX[<span class="number">0</span>:<span class="number">99</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">0.1</span>)</div><div class="line">    yHat1 = lwlrTest(abX[<span class="number">0</span>:<span class="number">99</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">1</span>)</div><div class="line">    yHat10 = lwlrTest(abX[<span class="number">0</span>:<span class="number">99</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">10</span>)</div><div class="line"></div><div class="line">    error01 = rssError(abY[<span class="number">0</span>:<span class="number">99</span>], yHat01.T)</div><div class="line">    error1 = rssError(abY[<span class="number">0</span>:<span class="number">99</span>], yHat1.T)</div><div class="line">    error10 = rssError(abY[<span class="number">0</span>:<span class="number">99</span>], yHat10.T)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'error01:'</span>,error01</div><div class="line">    <span class="keyword">print</span> <span class="string">'error1:'</span>,error1</div><div class="line">    <span class="keyword">print</span> <span class="string">'error10:'</span>, error10</div><div class="line"></div><div class="line">    yHat01_new = lwlrTest(abX[<span class="number">100</span>:<span class="number">199</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">0.1</span>)</div><div class="line">    yHat1_new = lwlrTest(abX[<span class="number">100</span>:<span class="number">199</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">1</span>)</div><div class="line">    yHat10_new = lwlrTest(abX[<span class="number">100</span>:<span class="number">199</span>], abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>], <span class="number">10</span>)</div><div class="line">    <span class="comment"># print 'yHat01_new:', yHat01_new</span></div><div class="line">    <span class="comment"># print 'yHat1_new:', yHat1_new</span></div><div class="line">    <span class="comment"># print 'yHat10_new:', yHat10_new</span></div><div class="line"></div><div class="line"></div><div class="line">    error01_new = rssError(abY[<span class="number">100</span>:<span class="number">199</span>], yHat01_new.T)</div><div class="line">    error1_new = rssError(abY[<span class="number">100</span>:<span class="number">199</span>], yHat1_new.T)</div><div class="line">    error10_new = rssError(abY[<span class="number">100</span>:<span class="number">199</span>], yHat10_new.T)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'error01_new:'</span>,error01_new</div><div class="line">    <span class="keyword">print</span> <span class="string">'error1_new:'</span>,error1_new</div><div class="line">    <span class="keyword">print</span> <span class="string">'error10_new:'</span>,error10_new</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'lineRegression:'</span></div><div class="line"></div><div class="line">    ws = standRegres(abX[<span class="number">0</span>:<span class="number">99</span>], abY[<span class="number">0</span>:<span class="number">99</span>])</div><div class="line">    yHat = np.mat(abX[<span class="number">100</span>:<span class="number">199</span>]) * ws</div><div class="line">    <span class="keyword">print</span> rssError(abY[<span class="number">100</span>:<span class="number">199</span>], yHat.T.A)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ridgeRegres</span><span class="params">(xMat, yMat, lam=<span class="number">0.2</span>)</span>:</span></div><div class="line">    xTx = xMat.T * xMat</div><div class="line">    denom = xTx + np.eye(np.shape(xMat)[<span class="number">1</span>]) * lam</div><div class="line">    <span class="keyword">if</span> la.det(denom) == <span class="number">0.0</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'this matrix is singular, cannot do inverse'</span></div><div class="line">        <span class="keyword">return</span></div><div class="line">    ws = denom.I * (xMat.T * yMat)</div><div class="line">    <span class="keyword">return</span> ws</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ridgeTest</span><span class="params">(xArr, yArr)</span>:</span></div><div class="line">    xMat = np.mat(xArr); yMat = np.mat(yArr).T</div><div class="line">    yMean = np.mean(yMat, <span class="number">0</span>)</div><div class="line">    yMat = yMat - yMean</div><div class="line">    xMeans = np.mean(xMat, <span class="number">0</span>)</div><div class="line">    xVar = np.var(xMat, <span class="number">0</span>)</div><div class="line">    xMat = (xMat - xMeans) / xVar</div><div class="line">    numTestPts = <span class="number">30</span></div><div class="line">    wMat = np.zeros((numTestPts, np.shape(xMat)[<span class="number">1</span>]))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestPts):</div><div class="line">        ws = ridgeRegres(xMat, yMat, np.exp(i<span class="number">-10</span>))</div><div class="line">        wMat[i, :] = ws.T</div><div class="line">    <span class="keyword">return</span> wMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 将特征标准化处理为均值为0，方差为1</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">regularize</span><span class="params">(xMat)</span>:</span><span class="comment">#regularize by columns</span></div><div class="line">    inMat = xMat.copy()</div><div class="line">    inMeans = np.mean(inMat,<span class="number">0</span>)   <span class="comment">#calc mean then subtract it off</span></div><div class="line">    inVar = np.var(inMat,<span class="number">0</span>)      <span class="comment">#calc variance of Xi then divide by it</span></div><div class="line">    inMat = (inMat - inMeans)/inVar</div><div class="line">    <span class="keyword">return</span> inMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    前向逐步回归 Forward Stepwise</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stageWise</span><span class="params">(xArr, yArr, eps=<span class="number">0.01</span>, numIt=<span class="number">100</span>)</span>:</span></div><div class="line">    xMat = np.mat(xArr); yMat = np.mat(yArr).T</div><div class="line">    yMean = np.mean(yMat, <span class="number">0</span>)</div><div class="line">    yMat = yMat - yMean</div><div class="line">    xMat = regularize(xMat)</div><div class="line">    m,n = np.shape(xMat)</div><div class="line">    returnMat = np.zeros((numIt, n))</div><div class="line">    ws = np.zeros((n, <span class="number">1</span>)); wsTest = ws.copy(); wsMax = ws.copy()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</div><div class="line">        <span class="keyword">print</span> ws.T</div><div class="line">        lowestError = np.inf</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</div><div class="line">            <span class="keyword">for</span> sign <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">1</span>]:</div><div class="line">                wsTest = ws.copy()</div><div class="line">                wsTest[j] += eps * sign</div><div class="line">                yTest = xMat * wsTest</div><div class="line">                rssE = rssError(yMat.A, yTest.A)</div><div class="line">                <span class="keyword">if</span> rssE &lt; lowestError:</div><div class="line">                    lowestError = rssE</div><div class="line">                    wsMax = wsTest</div><div class="line">        ws = wsMax.copy()</div><div class="line">        returnMat[i, :] = ws.T</div><div class="line">    <span class="keyword">return</span> returnMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    从页面读取数据，生成retX和retY列表</div><div class="line">    数据属性:年份,零件数量,新旧,原价格</div><div class="line"></div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">scrapePage</span><span class="params">(retX, retY, inFile, yr, numPce, origPrc)</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># 打开并读取HTML文件</span></div><div class="line">    fr = open(inFile);</div><div class="line">    soup = BeautifulSoup(fr.read())</div><div class="line">    i=<span class="number">1</span></div><div class="line"></div><div class="line">    <span class="comment"># 根据HTML页面结构进行解析</span></div><div class="line">    currentRow = soup.findAll(<span class="string">'table'</span>, r=<span class="string">"%d"</span> % i)</div><div class="line">    <span class="keyword">while</span>(len(currentRow)!=<span class="number">0</span>):</div><div class="line">        currentRow = soup.findAll(<span class="string">'table'</span>, r=<span class="string">"%d"</span> % i)</div><div class="line">        title = currentRow[<span class="number">0</span>].findAll(<span class="string">'a'</span>)[<span class="number">1</span>].text</div><div class="line">        lwrTitle = title.lower()</div><div class="line"></div><div class="line">        <span class="comment"># 查找是否有全新标签</span></div><div class="line">        <span class="keyword">if</span> (lwrTitle.find(<span class="string">'new'</span>) &gt; <span class="number">-1</span>) <span class="keyword">or</span> (lwrTitle.find(<span class="string">'nisb'</span>) &gt; <span class="number">-1</span>):</div><div class="line">            newFlag = <span class="number">1.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            newFlag = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="comment"># 查找是否已经标志出售，我们只收集已出售的数据</span></div><div class="line">        soldUnicde = currentRow[<span class="number">0</span>].findAll(<span class="string">'td'</span>)[<span class="number">3</span>].findAll(<span class="string">'span'</span>)</div><div class="line">        <span class="keyword">if</span> len(soldUnicde)==<span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">"item #%d did not sell"</span> % i</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># 解析页面获取当前价格</span></div><div class="line">            soldPrice = currentRow[<span class="number">0</span>].findAll(<span class="string">'td'</span>)[<span class="number">4</span>]</div><div class="line">            priceStr = soldPrice.text</div><div class="line">            priceStr = priceStr.replace(<span class="string">'$'</span>,<span class="string">''</span>) <span class="comment">#strips out $</span></div><div class="line">            priceStr = priceStr.replace(<span class="string">','</span>,<span class="string">''</span>) <span class="comment">#strips out ,</span></div><div class="line">            <span class="keyword">if</span> len(soldPrice)&gt;<span class="number">1</span>:</div><div class="line">                priceStr = priceStr.replace(<span class="string">'Free shipping'</span>, <span class="string">''</span>)</div><div class="line">            sellingPrice = float(priceStr)</div><div class="line"></div><div class="line">            <span class="comment"># 去掉不完整的套装价格</span></div><div class="line">            <span class="keyword">if</span>  sellingPrice &gt; origPrc * <span class="number">0.5</span>:</div><div class="line">                    <span class="keyword">print</span> <span class="string">"%d\t%d\t%d\t%f\t%f"</span> % (yr,numPce,newFlag,origPrc, sellingPrice)</div><div class="line">                    retX.append([yr, numPce, newFlag, origPrc])</div><div class="line">                    retY.append(sellingPrice)</div><div class="line">        i += <span class="number">1</span></div><div class="line">        currentRow = soup.findAll(<span class="string">'table'</span>, r=<span class="string">"%d"</span> % i)</div><div class="line"></div><div class="line"><span class="comment"># 依次读取六种乐高套装的数据，并生成数据矩阵        </span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">setDataCollect</span><span class="params">(retX, retY)</span>:</span></div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego8288.html'</span>, <span class="number">2006</span>, <span class="number">800</span>, <span class="number">49.99</span>)</div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego10030.html'</span>, <span class="number">2002</span>, <span class="number">3096</span>, <span class="number">269.99</span>)</div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego10179.html'</span>, <span class="number">2007</span>, <span class="number">5195</span>, <span class="number">499.99</span>)</div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego10181.html'</span>, <span class="number">2007</span>, <span class="number">3428</span>, <span class="number">199.99</span>)</div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego10189.html'</span>, <span class="number">2008</span>, <span class="number">5922</span>, <span class="number">299.99</span>)</div><div class="line">    scrapePage(retX, retY, baseDir+<span class="string">'setHtml\\lego10196.html'</span>, <span class="number">2009</span>, <span class="number">3263</span>, <span class="number">249.99</span>)</div><div class="line"></div><div class="line"><span class="comment"># 交叉验证</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">crossValidation</span><span class="params">(xArr, yArr, numVal=<span class="number">10</span>)</span>:</span></div><div class="line">    m = len(yArr)</div><div class="line">    indexList = range(m)</div><div class="line">    errorMat = np.zeros((numVal, <span class="number">30</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numVal):</div><div class="line">        <span class="comment">#part-1 分割训练集和测试集</span></div><div class="line">        trainX = []; trainY = []</div><div class="line">        testX = []; testY = []</div><div class="line">        np.random.shuffle(indexList)</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</div><div class="line">            <span class="keyword">if</span> j &lt; m * <span class="number">0.9</span>:</div><div class="line">                trainX.append(xArr[indexList[j]])</div><div class="line">                trainY.append(yArr[indexList[j]])</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                testX.append(xArr[indexList[j]])</div><div class="line">                testY.append(yArr[indexList[j]])</div><div class="line">        <span class="comment">#part-2 调用Ridge Regression 计算weights 默认会根据不同的参数,计算30组</span></div><div class="line">        wMat = ridgeTest(trainX, trainY) <span class="comment"># wMat.shape:(30,4)</span></div><div class="line">        <span class="comment">#part-3 计算30组weights的测试集上的误差</span></div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">30</span>):</div><div class="line">            <span class="comment"># 对测试集进行和训练集相同的标准化</span></div><div class="line">            matTestX = np.mat(testX); matTrainX = np.mat(trainX)</div><div class="line">            meanTrain = np.mean(matTrainX, <span class="number">0</span>)</div><div class="line">            varTrain = np.var(matTrainX, <span class="number">0</span>)</div><div class="line">            matTestX = (matTestX - meanTrain) / varTrain</div><div class="line">            yEst = matTestX * np.mat(wMat[k, :]).T + np.mean(trainY)</div><div class="line">            errorMat[i, k] = rssError(yEst.T.A, np.array(testY))</div><div class="line">    <span class="comment"># 求出30组weights的10次误差的均值的最小值</span></div><div class="line">    meanErrors = np.mean(errorMat, <span class="number">0</span>)</div><div class="line">    minMean = float(min(meanErrors))</div><div class="line">    <span class="comment"># 将使得误差均值最小的weights作为bestWeights</span></div><div class="line">    bestWeights = wMat[np.nonzero(meanErrors == minMean)]</div><div class="line"></div><div class="line">    <span class="comment"># 为了与标准回归比较,需要将数据标准化进行还原</span></div><div class="line">    xMat = np.mat(xArr); yMat = np.mat(yArr).T</div><div class="line">    meanX = np.mean(xMat, <span class="number">0</span>); varX = np.var(xMat, <span class="number">0</span>)</div><div class="line">    unReg = bestWeights / varX</div><div class="line">    <span class="keyword">print</span> <span class="string">'the best model from Ridge Regression is :\n'</span>,unReg</div><div class="line">    <span class="keyword">print</span> <span class="string">'with constant term:'</span></div><div class="line">    tmp = <span class="number">-1</span> * np.sum(np.multiply(meanX, unReg)) + np.mean(yMat)</div><div class="line">    <span class="keyword">print</span> tmp</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/07/02/SVD简化数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/02/SVD简化数据/" itemprop="url">SVD简化数据</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-02T20:25:54+08:00">
                2017-07-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-降维/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-降维</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="SVD原理介绍"><a href="#SVD原理介绍" class="headerlink" title="SVD原理介绍"></a>SVD原理介绍</h1><h2 id="数学概念"><a href="#数学概念" class="headerlink" title="数学概念"></a>数学概念</h2><blockquote>
<ul>
<li><code>SVD</code>: 奇异值分解(Singular Value Decomposition)</li>
<li><code>正交矩阵</code>：<br>1、如果A<em>A<sup>T</sup>=E（E为单位矩阵，A<sup>T</sup>表示“矩阵A的转置矩阵”）或A<sup>T</sup> </em> A=E，则n阶实矩阵A称为正交矩阵<br>2、<strong>A<sup>-1</sup> = A<sup>T</sup></strong></li>
<li><code>酉矩阵</code>：<br>1、n阶复方阵U的n个列向量是U空间的一个标准正交基，则U是酉矩阵(Unitary Matrix)。显然<strong>酉矩阵是正交矩阵往复数域上的推广</strong>。<br>2、  是酉矩阵的充分必要条件是，<strong>它的n个列向量是两两正交的单位向量</strong></li>
</ul>
</blockquote>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>m*n的矩阵X可以分解为</strong></p>
<h3 id="Xmn-Umm-Σmn-VTnn"><a href="#Xmn-Umm-Σmn-VTnn" class="headerlink" title="Xmn = Umm  Σmn  VTnn"></a>X<sub>m<em>n</em></sub> = U<sub>mm</sub> <em> Σ<sub>m</sub></em>n <em> V<sup>T</sup><sub>n</sub></em>n</h3><p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">这部分图片与文字摘自这里</a></p>
<p><img src="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226342650.png" alt="enter image description here"></p>
<p><code>U 、V&lt;sup&gt;T&lt;/sup&gt;是酉矩阵，也是正交矩阵, Σ是是一个m * n的矩阵（除了对角线的元素都是0，对角线上的元素称为奇异值</code></p>
<blockquote>
<ul>
<li><strong>U的每一行都是A*A<sup>T</sup>的特征向量</strong></li>
<li><strong>V的每一行都是A<sup>T</sup>*A的特征向量</strong></li>
</ul>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fh6g9ql2vyj20qm0fot9y.jpg" alt=""></p>
<p><strong>在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上了。也就是说，我们也可以用前r大的奇异值来近似描述矩阵，这里定义一下部分奇异值分解:</strong><br><img src="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226358289.png" alt="enter image description here"><br> r是一个远小于m、n的数，这样矩阵的乘法看起来像是下面的样子<br> <img src="http://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101192226356370.png" alt="enter image description here"></p>
<p>右边的三个矩阵相乘的结果将会是一个接近于A的矩阵，在这儿，r越接近于n，则相乘的结果越接近于A。而这三个矩阵的面积之和（在存储观点来说，矩阵面积越小，存储量就越小）要远远小于原始的矩阵A，我们如果想要压缩空间来表示原矩阵A，我们存下这里的三个矩阵：U、Σ、V就好了。</p>
<p>更形象的图片：<br><img src="http://images2015.cnblogs.com/blog/1042406/201701/1042406-20170105140822191-1774139119.png" alt="enter image description here"></p>
<h3 id="手动求解SVD"><a href="#手动求解SVD" class="headerlink" title="手动求解SVD"></a>手动求解SVD</h3><p><a href="http://www.cnblogs.com/pinard/p/6251584.html" target="_blank" rel="external">看这里</a></p>
<h3 id="这里是重点"><a href="#这里是重点" class="headerlink" title="这里是重点"></a>这里是重点</h3><blockquote>
<ul>
<li><p>A<sub>m<em>n</em></sub> = U<sub>mm</sub> <em> Σ<sub>m</sub></em>n <em> V.T<sub>n</sub></em>n</p>
</li>
<li><p>取前r个奇异值</p>
</li>
<li>A<sub>m<em>n</em></sub> ≈ U<sub>mr</sub> <em> Σ<sub>r</sub></em>r <em> V.T<sub>r</sub></em>n</li>
</ul>
</blockquote>
<p><em>假设A的行代表不同用户,列代表不同物品 A[i,j]代表第i个用户对第j个物品的评价</em></p>
<p><strong>那么V矩阵代表r(r&lt;m)个用户对于n个物品的评价.即,把原来的m个用户的评价压缩为r个用户的评价.</strong><br><strong>那么U矩阵代表m个用户对于r(r&lt;n)个物品的评价.即,把原来的m个用户的对n个物品的评价压缩为对r个物品的评价.</strong></p>
<blockquote>
<p>A = U <em> Σ </em> V<sup>T</sup></p>
<p>因为U,V是正交矩阵</p>
<p>U<sup>T</sup> <em> A = U<sup>T</sup> </em> U <em> Σ </em> V<sup>T</sup></p>
<p>U<sup>T</sup> <em> A = Σ </em> V<sup>T</sup></p>
<p>Σ<sup>-1</sup> <em> U<sup>T</sup> </em> A = Σ<sup>-1</sup> <em> Σ </em> V<sup>T</sup></p>
<p>Σ<sup>-1</sup> <em> U<sup>T</sup> </em> A = V<sup>T</sup></p>
<p>V = (Σ<sup>-1</sup> <em> U<sup>T</sup> </em> A)<sup>T</sup></p>
<p>V = A<sup>T</sup> <em> (U<sup>T</sup>)<sup>T</sup> </em> (Σ<sup>-1</sup>)<sup>T</sup></p>
<p>因为Σ是对角阵</p>
<p>V = A<sup>T</sup> <em> (U<sup>T</sup>)<sup>T</sup> </em> Σ<sup>-1</sup></p>
<p>V = A<sup>T</sup> <em> U </em> Σ<sup>-1</sup></p>
</blockquote>
<p><code>V即是降维后的矩阵</code></p>
<h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><p>同理,新来一个所有用户对于一个商品评价的向量</p>
<blockquote>
<p>X<sub>m*1</sub></p>
<p>降维后的向量</p>
<p>v<sub>1,r</sub>=X<sup>T</sup> <em> U<sub>m,r</sub> </em>  Σ<sub>r,r</sub><sup>-1</sup></p>
</blockquote>
<p>v<sup>T</sup> 即是降维后的该商品的评价</p>
<h1 id="SVD协同过滤推荐引擎"><a href="#SVD协同过滤推荐引擎" class="headerlink" title="SVD协同过滤推荐引擎"></a>SVD协同过滤推荐引擎</h1><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p><code>协同过滤：</code>通过将用户和其他用户的数据进行对比来实现推荐</p>
<h2 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h2><p><strong>基于物品的相似性的推荐</strong></p>
<p><code>思想</code>：</p>
<blockquote>
<ul>
<li><strong>用2类物品的不同用户评价列向量的相似性,乘以该用户已知类物品的评价,来作为该用户未知评价物品的评价因子(t).</strong></li>
<li><strong>用户已知物品评价为多个,对t加权取平均作为未知评价物品的评价</strong></li>
</ul>
</blockquote>
<p>行：每个用户   列：每个物品</p>
<pre><code>mat=[[4, 4, 0, 2, 2],
     [4, 0, 0, 3, 3],
     [4, 0, 0, 1, 1],
     [1, 1, 1, 2, 0],
     [2, 2, 2, 0, 0],
     [1, 1, 1, 0, 0],
     [5, 5, 5, 0, 0]]
</code></pre><p>eg:   对user=2进行推荐<br>        mat[2,1] mat[2,2]为0。为user=2用户针对第二个和第三个物品推荐<br>        先对它进行推荐：mat[2,1]<br>            按列扫描矩阵,第j列：<br>            j=0,<br>            如果user=2用户未评价这个物品，跳过。<br>            否则：<br>                1、针对第j列和第2列寻找对这2个物品都评价的用户。<br>                2、如果没有这样的用户则不处理。<br>                3、如果有这样的用户，则计算这些用户第j列和第2列评价的相似度(mat里面的第j列和第2列的某几行分别组成的2个列向量来计算相似度)<br>                即：</p>
<pre><code>[4] [4]
[1] [1]
[2] [2]
[1] [1]
[5] [5]
</code></pre><p>4、ratSimTotal += 第j列user行的评价 * 上面相似度<br>                    simTotal += 上面相似度<br>        最后循环完每一列后<br>        return ratSimTotal/simTotal</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-15</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadExData</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">            [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">            [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">            [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">            [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>],</div><div class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>],</div><div class="line">            [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadExData2</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span>[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">           [<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">           [<span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>],</div><div class="line">           [<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">1</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">           [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line">           ]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclidSim</span><span class="params">(inA, inB)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + la.norm(inA - inB))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pearsSim</span><span class="params">(inA, inB)</span>:</span></div><div class="line">    <span class="keyword">if</span> len(inA) &lt; <span class="number">3</span> :</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">print</span> np.corrcoef(inA, inB, rowvar= <span class="number">0</span>)</div><div class="line">    <span class="keyword">print</span> np.corrcoef(inA, inB, rowvar= <span class="number">0</span>)[<span class="number">0</span>][<span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> <span class="number">0.5</span> + <span class="number">0.5</span> * np.corrcoef(inA, inB, rowvar= <span class="number">0</span>)[<span class="number">0</span>][<span class="number">1</span>] <span class="comment"># 相关系数矩阵的第i行,第j列是原矩阵第i,j列的相关系数</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosSim</span><span class="params">(inA, inB)</span>:</span></div><div class="line">    num = float(inA.T * inB)</div><div class="line">    denom = la.norm(inA) * la.norm(inB)</div><div class="line">    <span class="keyword">return</span> <span class="number">0.5</span> + <span class="number">0.5</span> * (num / denom)</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    基于物品的相似性的推荐</div><div class="line">    思想：用2类物品的不同用户评价列向量的相似性,乘以该用户已知类物品的评价,来作为该用户未知评价物品的评价因子(t).</div><div class="line">    用户已知物品评价为多个,对t加权取平均作为未知评价物品的评价</div><div class="line">    行：每个用户   列：每个物品</div><div class="line">mat=[[4, 4, 0, 2, 2],</div><div class="line">    [4, 0, 0, 3, 3],</div><div class="line">    [4, 0, 0, 1, 1],</div><div class="line">    [1, 1, 1, 2, 0],</div><div class="line">    [2, 2, 2, 0, 0],</div><div class="line">    [1, 1, 1, 0, 0],</div><div class="line">    [5, 5, 5, 0, 0]]</div><div class="line">    eg:对user=2进行推荐</div><div class="line">        mat[2,1] mat[2,2]为0。为user=2用户针对第二个和第三个物品推荐</div><div class="line"></div><div class="line">        mat[2,1]</div><div class="line">            按列扫描矩阵,第j列：</div><div class="line">            j=0,如果user=2用户未评价这个物品，跳过。</div><div class="line">            否则：</div><div class="line">                1、针对第j列和第2列寻找对这2个物品都评价的用户。</div><div class="line">                2、如果没有这样的用户则不处理。</div><div class="line">                3、如果有这样的用户，则计算这些用户第j列和第2列评价的相似度(mat里面的第j列和第2列的某几行分别组成的2个列向量来计算相似度)</div><div class="line">                即：[4][4]</div><div class="line">                    [1][1]</div><div class="line">                    [2][2]</div><div class="line">                    [1][1]</div><div class="line">                    [5][5]</div><div class="line">                4、ratSimTotal += 第j列user行的评价 * 上面相似度</div><div class="line">                    simTotal += 上面相似度</div><div class="line">        最后循环完每一列后</div><div class="line">        return ratSimTotal/simTotal</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">standEst</span><span class="params">(dataMat, user, simMeas, item)</span>:</span></div><div class="line">    n = np.shape(dataMat)[<span class="number">1</span>] <span class="comment"># 物品数目</span></div><div class="line">    simTotal = <span class="number">0.0</span>; ratSimTotal = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</div><div class="line">        userRating = dataMat[user, j] <span class="comment"># 某用户对每个商品的评价</span></div><div class="line">        <span class="keyword">if</span> userRating == <span class="number">0</span>:</div><div class="line">            <span class="keyword">continue</span> <span class="comment"># 若该用户对第j个物品未评价，则跳过</span></div><div class="line">        overLap = np.nonzero(np.logical_and(dataMat[:, item].A &gt; <span class="number">0</span>, dataMat[:, j].A &gt; <span class="number">0</span>))[<span class="number">0</span>] <span class="comment"># 针对第item个物品和第j个物品，寻找哪些用户都对其进行了评价</span></div><div class="line">        <span class="keyword">if</span> len(overLap) == <span class="number">0</span>:</div><div class="line">            similarity = <span class="number">0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># 如果有M(M&gt;=2)个用户对第item个物品和第j个物品都评价了，则计算这2种物品在这几个用户评价的相似度</span></div><div class="line">            similarity = simMeas(dataMat[overLap, item], dataMat[overLap, j])</div><div class="line">        <span class="keyword">print</span> <span class="string">'the &#123;&#125; and &#123;&#125; similiarity is: &#123;&#125;'</span>.format(item, j, similarity)</div><div class="line">        simTotal += similarity</div><div class="line">        ratSimTotal += similarity * userRating</div><div class="line">    <span class="keyword">if</span> simTotal == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> ratSimTotal / simTotal</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">recommend</span><span class="params">(dataMat, user, N=<span class="number">10</span>, simMeas=cosSim, estMethod=standEst)</span>:</span></div><div class="line">    unratedItems = np.nonzero(dataMat[user, :].A ==<span class="number">0</span>)[<span class="number">1</span>] <span class="comment"># 该用户未评价的物品列表</span></div><div class="line">    <span class="keyword">if</span> len(unratedItems) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">'you rated everything'</span></div><div class="line">    itemScores = []</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> unratedItems:</div><div class="line">        estimatedScore = estMethod(dataMat, user, simMeas, item)</div><div class="line">        itemScores.append((item, estimatedScore))</div><div class="line">    <span class="keyword">return</span> sorted(itemScores, key=<span class="keyword">lambda</span> k: k[<span class="number">1</span>], reverse=<span class="keyword">True</span>)[:N]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">svdEst</span><span class="params">(dataMat, user, simMeas, item)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'item:&#123;&#125;'</span>.format(item)</div><div class="line">    n = np.shape(dataMat)[<span class="number">1</span>]</div><div class="line">    simTotal = <span class="number">0.0</span>; ratSimTotal = <span class="number">0.0</span></div><div class="line">    U, Sigma, VT = la.svd(dataMat)</div><div class="line">    Sig4 = np.mat(np.eye(<span class="number">4</span>) * Sigma[:<span class="number">4</span>])</div><div class="line">    <span class="comment"># print 'U:',U.shape, U</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Sigma:'</span>,Sigma.shape, Sigma</div><div class="line">    <span class="comment"># print 'VT',VT.shape, VT</span></div><div class="line">    <span class="comment"># print 'Sig4', Sig4.shape, Sig4</span></div><div class="line">    <span class="comment"># print 'Sig4.I', Sig4.I</span></div><div class="line"></div><div class="line">    <span class="comment"># 压缩为(n,4)矩阵,xformedItems.T表示4个人对n个物品的评价</span></div><div class="line">    xformedItems = dataMat.T * U[:, :<span class="number">4</span>] * Sig4.I</div><div class="line"></div><div class="line">    <span class="comment"># xformedItems2 = dataMat.T * U[:, :4] * Sig4</span></div><div class="line"></div><div class="line">    <span class="comment"># print xformedItems.shape</span></div><div class="line">    <span class="comment"># print xformedItems</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</div><div class="line">        <span class="keyword">print</span> <span class="string">'j:&#123;&#125;'</span>.format(j)</div><div class="line">        userRating = dataMat[user, j]</div><div class="line">        <span class="keyword">if</span> userRating == <span class="number">0</span> <span class="keyword">or</span> j == item:</div><div class="line">            <span class="keyword">continue</span></div><div class="line"></div><div class="line">        <span class="comment"># 求第j个物品和第item个物品评论的相似性</span></div><div class="line">        similarity = simMeas(xformedItems[item, :].T, xformedItems[j, :].T)</div><div class="line">        <span class="keyword">print</span> <span class="string">'the &#123;&#125; and &#123;&#125; similarity is: &#123;&#125;'</span>.format(item,j,similarity)</div><div class="line">        simTotal += similarity</div><div class="line">        <span class="comment"># 两个物品评价的相似性 * 已知评价的物品评价 ,来预测未评价物品的评价</span></div><div class="line">        ratSimTotal += similarity * userRating</div><div class="line">    <span class="keyword">if</span> simTotal == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> ratSimTotal / simTotal</div></pre></td></tr></table></figure>
<h1 id="SVD压缩图片"><a href="#SVD压缩图片" class="headerlink" title="SVD压缩图片"></a>SVD压缩图片</h1><h2 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> la</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebuild_img</span><span class="params">(u, sigma, vt, p)</span>:</span> <span class="comment">#p表示奇异值的百分比</span></div><div class="line">    <span class="keyword">print</span> p</div><div class="line">    U = np.mat(u)</div><div class="line">    VT = np.mat(vt)</div><div class="line">    count = sum(sigma)</div><div class="line">    <span class="keyword">print</span> <span class="string">'count:&#123;&#125;'</span>.format(count)</div><div class="line">    <span class="keyword">print</span> <span class="string">'count * p:&#123;&#125;'</span>.format(count * p)</div><div class="line">    curSum = <span class="number">0.0</span></div><div class="line">    k = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> curSum &lt;= count * p:</div><div class="line">        curSum = sum(sigma[:k])</div><div class="line">        k += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'k:'</span>,k</div><div class="line">    Sig = np.mat(np.eye(k) * sigma[:k])</div><div class="line">    res = U[:,:k] * Sig * VT[:k, :]</div><div class="line">    r = res.A</div><div class="line">    r[r &lt; <span class="number">0</span>] = <span class="number">0</span></div><div class="line">    r[r &gt; <span class="number">255</span>] = <span class="number">255</span></div><div class="line">    <span class="keyword">return</span> np.rint(r).astype(<span class="string">"uint8"</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></div><div class="line">    pict = <span class="string">'black.jpg'</span></div><div class="line">    path = <span class="string">'C:\\Users\\Administrator\\Downloads\\'</span> + pict</div><div class="line">    img = Image.open(path)</div><div class="line">    img_arr = np.array(img)</div><div class="line">    p = <span class="number">0.9</span></div><div class="line">    U0, S0, VT0 = la.svd(img_arr[:, :, <span class="number">0</span>])</div><div class="line">    U1, S1, VT1 = la.svd(img_arr[:, :, <span class="number">1</span>])</div><div class="line">    U2, S2, VT2 = la.svd(img_arr[:, :, <span class="number">2</span>])</div><div class="line"></div><div class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> np.arange(<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">0.1</span>):</div><div class="line">        R = rebuild_img(U0, S0, VT0, p)</div><div class="line">        G = rebuild_img(U1, S1, VT1, p)</div><div class="line">        B = rebuild_img(U2, S2, VT2, p)</div><div class="line">        I = np.stack((R, G, B), <span class="number">2</span>)</div><div class="line">        <span class="comment">#保存图片在img文件夹下</span></div><div class="line">        Image.fromarray(I).save(<span class="string">"C:\\Users\\Administrator\\Downloads\\black\\svd_"</span> + str(p * <span class="number">100</span>) +<span class="string">'_'</span>+ pict)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    test()</div></pre></td></tr></table></figure>
<p><img src="/img/black.png" alt="Alt text"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/19/PCA降维/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/19/PCA降维/" itemprop="url">PCA降维</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-19T16:12:00+08:00">
                2017-06-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h1><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><p><code>方差D(x)</code></p>
<blockquote>
<p>是在概率论和统计方差衡量随机变量或一组数据是离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是各个数据分别与其平均数之差的平方的和的平均数。</p>
</blockquote>
<h4 id="定义：D-x-E-x-E-x-²"><a href="#定义：D-x-E-x-E-x-²" class="headerlink" title="定义：D(x)=E{[x-E(x)]²}"></a>定义：D(x)=E{[x-E(x)]²}</h4><pre><code>D(x)=1/n ∑[Xi - E(x)]²
    =1/n ∑{Xi² + [E(x)]² - 2XiE(x)}
    =1/n * ∑Xi² + 1/n * ∑[E(x)]² - 2 * E(x) * 1/n * ∑Xi
    =E(X²) + 1/n * n * [E(x)]² - 2 * [E(x)]²
    =E(X²) - [E(x)]²
</code></pre><p><strong>D(X)=E(X²)-[E(X)]²,E(X)是数学期望值</strong><br><img src="https://gss0.baidu.com/-fo3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/d50735fae6cd7b8940280fde092442a7d9330e22.jpg" alt="enter image description here"></p>
<p><code>协方差</code></p>
<blockquote>
<p>标准差和方差一般是用来描述一维数据的，但现实生活中我们常常会遇到含有多维数据的数据集，最简单的是大家上学时免不了要统计多个学科的考试成绩。面对这样的数据集，我们当然可以按照每一维独立的计算其方差，但是通常我们还想了解更多，比如，一个男孩子的猥琐程度跟他受女孩子的欢迎程度是否存在一些联系。协方差就是这样一种用来度量两个随机变量关系的统计量</p>
</blockquote>
<p><img src="/img/1497581961044.png" alt="Alt text"></p>
<p><code>在两个向量都中心化(都减去对应特征的均值)后</code><br><strong>当协方差为0，则表示这两个向量线性无关，正交</strong></p>
<blockquote>
<p>协方差的结果有什么意义呢？如果结果为正值，则说明两者是正相关的（从协方差可以引出“相关系数”的定义），也就是说一个人越猥琐越受女孩欢迎。如果结果为负值， 就说明两者是负相关，越猥琐女孩子越讨厌。如果为0，则两者之间没有关系，猥琐不猥琐和女孩子喜不喜欢之间没有关联，就是统计上说的“相互独立”。</p>
</blockquote>
<p><code>协方差矩阵</code><br>前面提到的猥琐和受欢迎的问题是典型的二维问题，而协方差也只能处理二维问题，那维数多了自然就需要计算多个协方差，比如n维的数据集就需要计算<img src="/img/1497582075209.png" alt="Alt text">个协方差，那自然而然我们会想到使用矩阵来组织这些数据。给出协方差矩阵的定义：<br><img src="/img/1497582184602.png" alt="Alt text"><br>这个定义还是很容易理解的，我们可以举一个三维的例子，假设数据集有三个维度，则协方差矩阵为：<br><img src="/img/1497582167914.png" alt="Alt text"><br>可见，协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。</p>
<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p><strong>将数据的维度降低</strong></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>数据默认已经中心化</strong></p>
<pre><code>x投影到P的一组基上
x1=[a1,a2,a3,...am]T （一条数据）
原矩阵X=[x1,x2,x3,...xn] （n条数据）
变换矩阵P是r个相互正交的行向量拼在一起
变换后矩阵Y=P * X {(r*m) * (m*n) = r*n }
r&lt;=m
</code></pre><p><code>把数据的维度从m维降到r维</code></p>
<p>度量Y的维度是否表示了原来X的主要成分，方法：方差<br><strong>方差越大，说明该维度数据越分散。更需要保留。</strong><br><code>Y的协方差矩阵D主对角线是各个维度的方差，其他元素则是各个维度两两之间的协方差</code></p>
<blockquote>
<p> <strong>优化目标:</strong>使D成为对角矩阵(除了主对角线其他元素都为0)<br> 等价于 使Y的各个维度之间正交<code>让X-&gt;Y能保留更多的信息</code></p>
</blockquote>
<pre><code>D=1/r * Y * Y.T
 =1/r * (P*X) * (P*X).T
 =1/r * p * (X * X.T) * P.T
 =p * (1/r * X * X.T) * P.T
另X的协方差矩阵C=1/m * X * X.T
这里好像把1/r 直接变成了 1/m (这只是一个常数的问题,对于全部数据统一操作,应该不会造成问题)
D=P * C * P.T
</code></pre><h3 id="D-P-C-P-T"><a href="#D-P-C-P-T" class="headerlink" title="D=P  C  P.T"></a>D=P <em> C </em> P.T</h3><p>让这个矩阵对角化，数学上早已有解决办法<br>结论：</p>
<blockquote>
<ul>
<li>C的特征值（与特征向量一一对应）按降序排列依次是每个维度上的方差。选出前K个特征向量单位化后组成P</li>
<li>P的每一行都是C的一个特征向量。</li>
</ul>
</blockquote>
<h3 id="得到降维后的数据"><a href="#得到降维后的数据" class="headerlink" title="得到降维后的数据"></a>得到降维后的数据</h3><blockquote>
<ul>
<li><strong>Y=P * X</strong></li>
</ul>
</blockquote>
<p>Y即是变换后的数据矩阵（每一列是一条数据）</p>
<h2 id="这个讲的特别清楚"><a href="#这个讲的特别清楚" class="headerlink" title="这个讲的特别清楚"></a>这个讲的特别清楚</h2><p><a href="http://blog.csdn.net/l494926429/article/details/52566693" target="_blank" rel="external">这里有好文</a></p>
<h2 id="降到多少维度合适"><a href="#降到多少维度合适" class="headerlink" title="降到多少维度合适"></a>降到多少维度合适</h2><p>计算出的<code>原矩阵X的协方差矩阵的特征值</code>降序排列后得到一个list L</p>
<blockquote>
<p><strong>L的元素依次是每个维度上的方差</strong><br>LS = L[0]+L[1]+…+L[n]</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left"><code>主成分</code></th>
<th style="text-align:right"><code>方差百分比</code></th>
<th style="text-align:center"><code>累计方差百分比</code></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:right">L[0]/LS</td>
<td style="text-align:center">L[0]/LS</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:right">L[1]/LS</td>
<td style="text-align:center">（L[0]+L[1])/LS</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:right">L[2]/LS</td>
<td style="text-align:center">(L[0]+L[1]+L[2])/LS</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:right">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
<p>有人使用能包含90%(<code>累计方差百分比</code>)信息量的主成分数量,<strong>或者更高</strong></p>
<p>书中用的是包含了97%的信息量</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-15</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> matplotlib</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName=<span class="string">'testSet.txt'</span>, delim=<span class="string">'\t'</span>)</span>:</span></div><div class="line">    Dir = <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch13'</span></div><div class="line">    file = <span class="string">'&#123;&#125;\\&#123;&#125;'</span>.format(Dir, fileName)</div><div class="line">    fr = open(file)</div><div class="line">    stringArr = [line.strip().split(delim) <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines()]</div><div class="line">    datArr = [map(float, line) <span class="keyword">for</span> line <span class="keyword">in</span> stringArr]</div><div class="line">    <span class="keyword">return</span> mat(datArr)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca</span><span class="params">(dataMat, topNfeat = <span class="number">9999999</span>)</span>:</span></div><div class="line">    meanVals = mean(dataMat, axis = <span class="number">0</span>)</div><div class="line">    meanRemoved = dataMat - meanVals</div><div class="line">    <span class="comment"># 原矩阵的协方差矩阵</span></div><div class="line">    covMat = cov(meanRemoved, rowvar = <span class="number">0</span>)</div><div class="line">    <span class="comment"># 求协方差矩阵的特征值和特征向量</span></div><div class="line">    eigVals, eigVects = linalg.eig(mat(covMat))</div><div class="line">    <span class="comment">#特征值升序排列</span></div><div class="line">    eigValInd = argsort(eigVals)</div><div class="line">    <span class="comment">#取出从大到小的前topNfeat个索引值</span></div><div class="line">    eigValInd = eigValInd[: -(topNfeat+<span class="number">1</span>):<span class="number">-1</span>]</div><div class="line">    redEigVects = eigVects[:, eigValInd]</div><div class="line">    lowDDataMat = meanRemoved * redEigVects <span class="comment">#降维后的数据</span></div><div class="line">    reconMat = (lowDDataMat * redEigVects.T) +meanVals</div><div class="line">    <span class="keyword">return</span> lowDDataMat, reconMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotRes</span><span class="params">(dataMat, reconMat)</span>:</span></div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line">    ax.scatter(dataMat[:, <span class="number">0</span>].flatten().A[<span class="number">0</span>], dataMat[:, <span class="number">1</span>].flatten().A[<span class="number">0</span>], marker=<span class="string">'^'</span>, s=<span class="number">90</span>)</div><div class="line">    ax.scatter(reconMat[:, <span class="number">0</span>].flatten().A[<span class="number">0</span>], reconMat[:, <span class="number">1</span>].flatten().A[<span class="number">0</span>], marker=<span class="string">'o'</span>, s=<span class="number">50</span>, c=<span class="string">'red'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="comment"># 将所有缺失值设为该属性值的平均值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">replaceNanWithMean</span><span class="params">()</span>:</span></div><div class="line">    dataMat = loadDataSet(<span class="string">'secom.data'</span>, <span class="string">' '</span>)</div><div class="line">    numFeat = shape(dataMat)[<span class="number">1</span>]</div><div class="line">    <span class="comment"># print dataMat[:,0].A</span></div><div class="line">    <span class="comment"># print ~isnan(dataMat[:,0].A)</span></div><div class="line">    <span class="comment"># print nonzero(~isnan(dataMat[:,0].A))</span></div><div class="line">    <span class="comment"># print nonzero(~isnan(dataMat[:,0].A))[0]</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeat):</div><div class="line">        meanVal = mean(dataMat[nonzero(~isnan(dataMat[:, i].A))[<span class="number">0</span>], i])</div><div class="line">        dataMat[nonzero(isnan(dataMat[:, i].A))[<span class="number">0</span>], i] = meanVal</div><div class="line">    <span class="keyword">return</span> dataMat</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/16/SVM文本情感分类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/16/SVM文本情感分类/" itemprop="url">SVM文本情感分类</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-16T10:16:47+08:00">
                2017-06-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-应用/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-应用</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="SVM文本情感分类"><a href="#SVM文本情感分类" class="headerlink" title="SVM文本情感分类"></a>SVM文本情感分类</h1><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><ul>
<li>向量化：包含标签的文本处理为向量(TF-IDF)，存储词表</li>
<li>训练：向量送入SVM训练,得到支持向量、支持向量标签、alphas和偏移量</li>
<li>预测：将输入句子处理成向量，送入SVM预测情感<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2></li>
</ul>
<h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><p><code>美团评论数据</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;comment&quot;: &quot;很好的，值得推荐，大家快去吃吧&quot;, &quot;url&quot;: &quot;http://zz.meituan.com/deal/9925712.html&quot;, &quot;score&quot;: 5, &quot;productName&quot;: &quot;童记米皮&quot;&#125;</div><div class="line">&#123;&quot;comment&quot;: &quot;一般&quot;, &quot;url&quot;: &quot;http://zz.meituan.com/deal/9925712.html&quot;, &quot;score&quot;: 5, &quot;productName&quot;: &quot;童记米皮&quot;&#125;</div><div class="line">&#123;&quot;comment&quot;: &quot;好吃&quot;, &quot;url&quot;: &quot;http://zz.meituan.com/deal/9925712.html&quot;, &quot;score&quot;: 5, &quot;productName&quot;: &quot;童记米皮&quot;&#125;</div><div class="line">&#123;&quot;comment&quot;: &quot;自己感觉东西味道挺好的，价格也比较公道，就是店面不怎么好找，口味比较单一，对美团用户的服务，也比较一般，感觉有点看不起的样子，希望以后能有所改进，毕竟顾客就是上帝，只有让顾客感到舒心，顾客才会介绍朋友去消费，&quot;, &quot;url&quot;: &quot;http://zz.meituan.com/deal/9925712.html&quot;, &quot;score&quot;: 4, &quot;productName&quot;: &quot;童记米皮&quot;&#125;</div></pre></td></tr></table></figure></p>
<h3 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h3><blockquote>
<p>jieba</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#encoding=utf-8</span></div><div class="line"><span class="keyword">import</span> jieba</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test2</span><span class="params">()</span>:</span></div><div class="line">    seg_list = jieba.cut(<span class="string">"我来到北京清华大学"</span>, cut_all=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">"Full Mode:"</span>, <span class="string">"/ "</span>.join(seg_list)  <span class="comment"># 全模式</span></div><div class="line">    seg_list = jieba.cut(<span class="string">"我来到北京清华大学"</span>, cut_all=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">"Default Mode:"</span>, <span class="string">"/ "</span>.join(seg_list)  <span class="comment"># 精确模式</span></div><div class="line">    seg_list = jieba.cut(<span class="string">"他来到了网易杭研大厦"</span>)  <span class="comment"># 默认是精确模式</span></div><div class="line">    <span class="keyword">print</span> <span class="string">", "</span>.join(seg_list)</div><div class="line">    seg_list = jieba.cut_for_search(<span class="string">"小明硕士毕业于中国科学院计算所，后在日本京都大学深造"</span>)  <span class="comment"># 搜索引擎模式</span></div><div class="line">    <span class="keyword">print</span> <span class="string">", "</span>.join(seg_list)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(query)</span>:</span></div><div class="line">    seg_list = jieba.cut(query, cut_all=<span class="keyword">False</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">" "</span>.join(seg_list)</div></pre></td></tr></table></figure>
<h3 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h3><h4 id="tf-idf"><a href="#tf-idf" class="headerlink" title="tf-idf"></a>tf-idf</h4><blockquote>
<ul>
<li><strong>之前用于训练的词表储存起来,新句子过来时用该词表训练生成向量</strong></li>
<li><strong>新句子向量维度与训练数据向量维度相同</strong></li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding=utf-8</span></div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeVocab</span><span class="params">(vocab, path)</span>:</span></div><div class="line">    fw = open(path,<span class="string">'w'</span>)</div><div class="line">    pickle.dump(vocab, fw)</div><div class="line">    fw.close()</div><div class="line"></div><div class="line">mydoclist = [<span class="string">u'温馨 提示 ： 家庭 畅享 套餐 介绍 、 主卡 添加 / 取消 副 卡 短信 办理 方式 , 可 点击 文档 左上方  短信  图标 即可 将 短信 指令 发送给 客户'</span>,</div><div class="line"><span class="string">u'客户 申请 i 我家 ， 家庭 畅享 计划  后 ， 可 选择 设置 1 - 6 个 同一 归属 地 的 中国移动 网 内 号码 作为 亲情 号码 ， 组建 一个 家庭 亲情 网  家庭 内 '</span>,</div><div class="line"><span class="string">u'所有 成员 可 享受 本地 互打 免费 优惠 ， 家庭 主卡 号码 还 可 享受 省内 / 国内 漫游 接听 免费 的 优惠'</span>]</div><div class="line"></div><div class="line">tfidf_vectorizer = TfidfVectorizer(min_df = <span class="number">1</span>)</div><div class="line">tfidf_matrix = tfidf_vectorizer.fit_transform(mydoclist)</div><div class="line"><span class="keyword">print</span> tfidf_matrix.todense()</div><div class="line"><span class="keyword">print</span> tfidf_matrix.todense().shape</div><div class="line"></div><div class="line"><span class="comment"># 存储前面文档的词表</span></div><div class="line">storeVocab(tfidf_vectorizer.vocabulary_, <span class="string">'tf_idf.txt'</span>)</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    把之前用于训练的词表储存起来,新句子过来时用该词表训练生成向量</div><div class="line">    新句子向量维度与训练数据向量维度相同</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="comment"># 载入词表,初始化tfidfVector</span></div><div class="line">vocab = pickle.load(open(<span class="string">'tf_idf.txt'</span>))</div><div class="line">tfidf_vectorizer_new = TfidfVectorizer(min_df = <span class="number">1</span>, vocabulary = vocab)</div><div class="line">new_docs = [<span class="string">'我 家住 在 黄土 高坡'</span>]</div><div class="line"><span class="comment"># 训练并生成新文档矩阵</span></div><div class="line">new_term_freq_matrix = tfidf_vectorizer_new.fit_transform(new_docs)</div><div class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> sorted(tfidf_vectorizer_new.vocabulary_.items(), key=<span class="keyword">lambda</span> d: d[<span class="number">1</span>]):</div><div class="line">    <span class="keyword">print</span> i,j</div><div class="line"><span class="keyword">print</span> new_term_freq_matrix.todense()</div><div class="line"><span class="keyword">print</span> new_term_freq_matrix.todense().shape</div></pre></td></tr></table></figure>
<h4 id="doc2vec"><a href="#doc2vec" class="headerlink" title="doc2vec"></a>doc2vec</h4><blockquote>
<ul>
<li>利用gensim.models.Doc2Vec生成文本句子向量</li>
<li>保存模型后，针对新来的句子生成句子向量</li>
<li>新向量还可以与原来的向量计算相似度<br><code>心得：有问题看看help帮助文档 经验之谈</code></li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(<span class="string">'utf8'</span>)</div><div class="line"><span class="keyword">import</span> gensim</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> jieba  <span class="comment"># 导入结巴分词</span></div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line">phanzi=re.compile(<span class="string">u'[0-9A-Za-z]|[\u4e00-\u9fa5]+'</span>)</div><div class="line">dimension = <span class="number">300</span></div><div class="line"><span class="comment"># 训练句子向量,并且保存模型和向量</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(raw_file)</span>:</span></div><div class="line">    cut_file, row, labels = getCutFile(raw_file)</div><div class="line">    sentences = gensim.models.doc2vec.TaggedLineDocument(cut_file)</div><div class="line">    <span class="keyword">print</span> sentences</div><div class="line">    model = gensim.models.Doc2Vec(</div><div class="line">        sentences, size=dimension, window=<span class="number">5</span>, sample=<span class="number">1e-4</span>, negative=<span class="number">5</span>, workers=<span class="number">8</span>, min_count=<span class="number">1</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        model.train(sentences, total_examples=len(labels), epochs=model.iter)</div><div class="line">    model_file = cut_file + <span class="string">'.model'</span></div><div class="line">    model.save(model_file)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'len(model.docvecs):&#123;&#125;'</span>.format(len(model.docvecs))</div><div class="line">    vec_file = model_file + <span class="string">'.vec'</span></div><div class="line">    out = file(vec_file, <span class="string">'w'</span>)</div><div class="line">    arr = []</div><div class="line">    <span class="keyword">for</span> idx, docvec <span class="keyword">in</span> enumerate(model.docvecs):</div><div class="line">        arr.append(docvec)</div><div class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> docvec:</div><div class="line">            out.write(str(value) + <span class="string">' '</span>)</div><div class="line">        out.write(<span class="string">'\n'</span>)</div><div class="line">        <span class="comment"># print idx</span></div><div class="line">        <span class="comment"># print docvec</span></div><div class="line">    out.close()</div><div class="line">    mat = np.matrix(arr)</div><div class="line">    <span class="keyword">print</span> <span class="string">'testDoc2vec.train mat.shape:&#123;&#125;'</span>.format(mat.shape)</div><div class="line">    <span class="keyword">return</span> mat, labels</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCutFile</span><span class="params">(raw_file)</span>:</span></div><div class="line">    f = open(raw_file, <span class="string">'r'</span>)</div><div class="line">    cnt = <span class="number">0</span></div><div class="line">    lines = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines()]</div><div class="line">    cut_file = raw_file + <span class="string">'.hit'</span></div><div class="line">    labels = []</div><div class="line">    <span class="keyword">with</span> open(cut_file, <span class="string">'wb'</span>) <span class="keyword">as</span> fw:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines:</div><div class="line">            splited = line.split(<span class="string">'\t'</span>)</div><div class="line">            query = splited[<span class="number">0</span>]</div><div class="line">            label = <span class="string">''</span></div><div class="line">            <span class="keyword">if</span> len(splited) == <span class="number">2</span>:</div><div class="line">                label = float(splited[<span class="number">1</span>])</div><div class="line">            <span class="keyword">if</span> len(query) &gt; <span class="number">3</span>:</div><div class="line">                cnt += <span class="number">1</span></div><div class="line">                <span class="comment"># 去除字符，保留中文，数字，英文</span></div><div class="line">                q = filterSymbol(query)</div><div class="line">                fw.write(<span class="string">" "</span>.join(jieba.lcut(q)) + <span class="string">"\n"</span>)</div><div class="line">                labels.append(label)</div><div class="line">    <span class="keyword">print</span> <span class="string">'getCutFile labels len:&#123;&#125;'</span>.format(len(labels))</div><div class="line">    <span class="keyword">return</span> cut_file, cnt, labels</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterSymbol</span><span class="params">(query)</span>:</span></div><div class="line">    q = query</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(query, unicode):</div><div class="line">        q = unicode(query,<span class="string">'utf8'</span>)</div><div class="line">    q = phanzi.findall(q)</div><div class="line">    res = <span class="string">''</span>.join(q)</div><div class="line">    <span class="keyword">print</span> res.encode(<span class="string">'utf8'</span>)</div><div class="line">    <span class="keyword">return</span> res</div><div class="line"></div><div class="line"><span class="comment"># 通过句子得到一个向量</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getVecs</span><span class="params">(queryList, modelDir)</span>:</span></div><div class="line">    queryMat = np.zeros((len(queryList), dimension))</div><div class="line">    queryHitList = [ jieba.lcut(query) <span class="keyword">for</span> query <span class="keyword">in</span> queryList]</div><div class="line">    model = gensim.models.Doc2Vec.load(modelDir)</div><div class="line">    <span class="keyword">for</span> i, query <span class="keyword">in</span> enumerate(queryHitList):</div><div class="line">        queryMat[i, :] = np.matrix(model.infer_vector(query))</div><div class="line">    <span class="keyword">print</span> queryMat[<span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> queryMat.shape</div><div class="line">    <span class="keyword">return</span> np.mat(queryMat)</div></pre></td></tr></table></figure>
<p><code>不过用这个doc2vec生成的向量送到SVM训练，效果奇差。。。 错误率97.5%。。。</code></p>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><blockquote>
<ul>
<li>用之前介绍过的PCA</li>
</ul>
</blockquote>
<p><strong>用TF-IDF方式生成的向量因为维度较大，可以进行降维</strong><br><em>存在问题：需要预测的句子太短,TF-IDF向量过于稀疏。PCA降维失败。因为一个向量的协方差矩阵是一个数，无法特征值分解</em></p>
<p><a href="http://blog.csdn.net/kuang_liu/article/details/16369475" target="_blank" rel="external">协方差矩阵计算</a></p>
<h3 id="分割数据集"><a href="#分割数据集" class="headerlink" title="分割数据集"></a>分割数据集</h3><table>
<thead>
<tr>
<th style="text-align:left">训练集</th>
<th style="text-align:right">测试集</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">8</td>
<td style="text-align:right">2</td>
</tr>
</tbody>
</table>
<h2 id="SVM训练"><a href="#SVM训练" class="headerlink" title="SVM训练"></a>SVM训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment"># 用到了之前写的svmMLIA.py</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">training</span><span class="params">(rawfile)</span>:</span></div><div class="line">    dataMat, labels = vectorizer_TFIDF(rawfile, <span class="keyword">False</span>)</div><div class="line">    <span class="comment"># dataMat, labels = vectorizer(rawfile, False)</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'type(dataMat):&#123;&#125;'</span>.format(type(dataMat))</div><div class="line">    <span class="keyword">print</span> <span class="string">'dataMat.shape:&#123;&#125;'</span>.format(dataMat.shape)</div><div class="line">    <span class="keyword">print</span> <span class="string">'len(labels):&#123;&#125;'</span>.format(len(labels))</div><div class="line">    <span class="keyword">assert</span> dataMat.shape[<span class="number">0</span>] == len(labels)</div><div class="line">    <span class="comment"># return 0</span></div><div class="line">    <span class="comment"># np.savetxt('/data/haojiawei/data/vector',dataMat)</span></div><div class="line">    <span class="comment"># three = dataMat[3]</span></div><div class="line">    <span class="comment"># print three</span></div><div class="line">    <span class="comment"># print three[three&gt;0]</span></div><div class="line">    <span class="comment"># 经测试原向量维度5000多维,降维至1000维</span></div><div class="line">    <span class="comment"># plotVarPercent(dataMat)</span></div><div class="line">    <span class="comment"># lowDDataMat = pca.pca_Low(dataMat, dimension)</span></div><div class="line">    <span class="comment"># print lowDDataMat.shape</span></div><div class="line">    <span class="comment"># print labels</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'生成训练集,测试集合'</span>.encode(<span class="string">'utf8'</span>)</div><div class="line"></div><div class="line">    ratio = <span class="number">0.8</span></div><div class="line">    trainMat, trainLabel, testMat, testLabel = sepData(</div><div class="line">        dataMat, labels, ratio)</div><div class="line">    <span class="comment"># svm</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'enter svm'</span></div><div class="line">    alphas, b = svmMLIA.testSVM(dataMat, labels, testMat, testLabel, <span class="number">200</span>, <span class="number">0.0001</span>,</div><div class="line">                        <span class="number">10000</span>, (<span class="string">'rbf'</span>, <span class="number">1.3</span>), supportVectorDir, supportLabelDir, alphasDir, bDir)</div><div class="line">    <span class="keyword">print</span> <span class="string">'alphas:'</span></div><div class="line">    <span class="keyword">print</span> alphas[alphas &gt; <span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> b</div></pre></td></tr></table></figure>
<h2 id="句子情感预测"><a href="#句子情感预测" class="headerlink" title="句子情感预测"></a>句子情感预测</h2><blockquote>
<ul>
<li>加载已训练好的支持向量，支持向量label，alphas，b 以及tf-idf词表</li>
<li>针对单句生成向量</li>
<li>带入到SVM中计算，得到结果</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(testfile)</span>:</span></div><div class="line">    querys = []</div><div class="line">    <span class="keyword">if</span> <span class="string">'/'</span> <span class="keyword">not</span> <span class="keyword">in</span> testfile:</div><div class="line">        querys.append(testfile.strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>))</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">with</span> open(testfile, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">                querys.append(line.strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>))</div><div class="line">    t1 = datetime.datetime.now()</div><div class="line">    <span class="keyword">print</span> <span class="string">'start predict &#123;&#125;'</span>.format(t1.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>))</div><div class="line">    <span class="comment">#去除字符</span></div><div class="line">    delSymbol_querys = [ testDoc2vec.filterSymbol(q) <span class="keyword">for</span> q <span class="keyword">in</span> querys]</div><div class="line">    <span class="comment"># 分词</span></div><div class="line">    sepQueryList = sepQuery(delSymbol_querys)</div><div class="line">    <span class="keyword">print</span> <span class="string">'len(sepQueryList):&#123;&#125;'</span>.format(len(sepQueryList))</div><div class="line">    <span class="comment"># 向量化</span></div><div class="line"></div><div class="line">    <span class="comment">#doc2vec</span></div><div class="line">    <span class="comment"># vectors = testDoc2vec.getVecs(sepQueryList, doc2VecModelDir)</span></div><div class="line">    vocab = grabDict(tf_idfVocabDir)</div><div class="line">    <span class="comment">#tf-idf</span></div><div class="line">    vectors, _ = vectorizer_TFIDF(sepQueryList, <span class="keyword">True</span>, vocab=vocab)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'vectors.shape:&#123;&#125;'</span>.format(vectors.shape)</div><div class="line">    <span class="comment"># 载入支持向量,alphas,b</span></div><div class="line">    sVs = np.mat(np.loadtxt(supportVectorDir))</div><div class="line">    labelSV = np.mat(np.loadtxt(supportLabelDir)).T</div><div class="line">    alphasSV = np.mat(np.loadtxt(alphasDir)).T</div><div class="line">    <span class="keyword">print</span> <span class="string">'sVs.type, labelSV.type, alphasSV.type:&#123;&#125;, &#123;&#125;, &#123;&#125;'</span>.format(type(sVs), type(labelSV), type(alphasSV))</div><div class="line">    <span class="keyword">print</span> <span class="string">'sVs.shape, labelSV.shape, alphasSV.shape:&#123;&#125;, &#123;&#125;, &#123;&#125;'</span>.format(sVs.shape, labelSV.shape, alphasSV.shape)</div><div class="line">    b = np.loadtxt(bDir).flat[<span class="number">0</span>]</div><div class="line">    <span class="comment"># 预测</span></div><div class="line">    m, n = np.shape(vectors)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = svmMLIA.kernelTrans(sVs, vectors[i, :], (<span class="string">'rbf'</span>, <span class="number">1.3</span>))</div><div class="line">        <span class="keyword">print</span> <span class="string">'kernelEval.shape:&#123;&#125;'</span>.format(kernelEval.shape)</div><div class="line">        a = np.multiply(labelSV, alphasSV)</div><div class="line">        <span class="keyword">print</span> <span class="string">'a.shape:&#123;&#125;'</span>.format(a.shape)</div><div class="line">        predict = kernelEval.T * np.multiply(labelSV, alphasSV) + b</div><div class="line">        res = <span class="number">0</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'predict:&#123;&#125;'</span>.format(predict)</div><div class="line">        <span class="keyword">if</span> predict &gt; <span class="number">0</span>:</div><div class="line">            res = <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            res = <span class="number">-1</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'&#123;&#125; class is :&#123;&#125;'</span>.format(querys[i], res)</div></pre></td></tr></table></figure>
<h2 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h2><p>训练数据：1000条带标签的团购评价数据<br>训练集错误率：1%</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><code>包含了上述所有代码(除了testDoc2vec.py)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-15</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</div><div class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</div><div class="line"><span class="keyword">import</span> pca</div><div class="line"><span class="keyword">import</span> jieba</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">from</span> jieba_test <span class="keyword">import</span> test <span class="keyword">as</span> sepTest</div><div class="line"><span class="keyword">import</span> testDoc2vec</div><div class="line"><span class="keyword">import</span> svmMLIA</div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(<span class="string">'utf8'</span>)</div><div class="line">dataDir = <span class="string">'/data/haojiawei/data'</span></div><div class="line">supportVectorDir = <span class="string">'&#123;&#125;/supportVector'</span>.format(dataDir)</div><div class="line">supportLabelDir = <span class="string">'&#123;&#125;/supportLabel'</span>.format(dataDir)</div><div class="line">alphasDir = <span class="string">'&#123;&#125;/alphas'</span>.format(dataDir)</div><div class="line">bDir = <span class="string">'&#123;&#125;/offset_b'</span>.format(dataDir)</div><div class="line">tf_idfVocabDir = <span class="string">'&#123;&#125;/tf_idf_vocab.dict'</span>.format(dataDir)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># supportVectorDir = '&#123;&#125;/firstSVM_model/supportVector'.format(dataDir)</span></div><div class="line"><span class="comment"># supportLabelDir = '&#123;&#125;/firstSVM_model/supportLabel'.format(dataDir)</span></div><div class="line"><span class="comment"># alphasDir = '&#123;&#125;/firstSVM_model/alphas'.format(dataDir)</span></div><div class="line"><span class="comment"># bDir = '&#123;&#125;/firstSVM_model/offset_b'.format(dataDir)</span></div><div class="line"><span class="comment"># tf_idfVocabDir = '&#123;&#125;/firstSVM_model/tf_idf_vocab.dict'.format(dataDir)</span></div><div class="line"></div><div class="line">doc2VecModelDir = <span class="string">'&#123;&#125;/meituan-200.hit.model'</span>.format(dataDir)</div><div class="line">tfidf_vectorizer = <span class="keyword">None</span></div><div class="line">dimension = <span class="number">300</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">()</span>:</span></div><div class="line">    fileDir = <span class="string">'/data/haojiawei/data/items-meituan-head-20000-2.json'</span></div><div class="line">    t = <span class="number">0</span></div><div class="line">    goodList = []</div><div class="line">    badList = []</div><div class="line">    <span class="keyword">with</span> open(fileDir) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">            t += <span class="number">1</span></div><div class="line">            js_line = json.loads(line)</div><div class="line">            <span class="keyword">if</span> js_line[<span class="string">'score'</span>] == <span class="number">1</span>:</div><div class="line">                badList.append(js_line[<span class="string">'comment'</span>])</div><div class="line">            <span class="keyword">elif</span> js_line[<span class="string">'score'</span>] == <span class="number">5</span>:</div><div class="line">                goodList.append(js_line[<span class="string">'comment'</span>])</div><div class="line">    <span class="keyword">print</span> len(goodList), len(badList)</div><div class="line">    good = goodList[:<span class="number">1000</span>]</div><div class="line">    bad = badList[:<span class="number">1000</span>]</div><div class="line">    <span class="keyword">print</span> badList[<span class="number">0</span>].encode(<span class="string">'utf8'</span>)</div><div class="line">    labels = [<span class="number">1.0</span>] * len(good) + [<span class="number">-1.0</span>] * len(bad)</div><div class="line">    <span class="keyword">return</span> good + bad, labels</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorizer_TFIDF</span><span class="params">(rawfile, isPred, vocab=None)</span>:</span></div><div class="line">    queryList = []</div><div class="line">    labels = []</div><div class="line">    tfidf_vectorizer = <span class="keyword">None</span></div><div class="line">    <span class="keyword">if</span> isPred:</div><div class="line">        queryList = rawfile</div><div class="line">        tfidf_vectorizer = TfidfVectorizer(min_df=<span class="number">1</span>, vocabulary=vocab)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        cut_file, row, labels = testDoc2vec.getCutFile(rawfile)</div><div class="line">        fr = open(cut_file,<span class="string">'r'</span>)</div><div class="line">        queryList = [q.strip().replace(<span class="string">'\n'</span>,<span class="string">''</span>) <span class="keyword">for</span> q <span class="keyword">in</span> fr.readlines()]</div><div class="line">        tfidf_vectorizer = TfidfVectorizer(min_df=<span class="number">1</span>)</div><div class="line">    <span class="keyword">print</span> queryList</div><div class="line"></div><div class="line">    tfidf_matrix = tfidf_vectorizer.fit_transform(queryList)</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isPred:</div><div class="line">        storeDict(tfidf_vectorizer.vocabulary_, tf_idfVocabDir)</div><div class="line">    <span class="keyword">print</span> tfidf_matrix.todense().shape</div><div class="line">    vec = tfidf_matrix.todense()[<span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> vec[vec &gt; <span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="keyword">return</span> tfidf_matrix.todense(), labels</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorizer</span><span class="params">(rawfile, isPred, modelDir=<span class="string">''</span>)</span>:</span></div><div class="line">    dataMat = <span class="keyword">None</span>; labels = []</div><div class="line">    <span class="keyword">if</span> isPred:</div><div class="line">        dataMat = getVecs(queryList, modelDir)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        dataMat, labels = testDoc2vec.train(rawfile)</div><div class="line">    <span class="keyword">return</span> dataMat, labels</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sepData</span><span class="params">(dataMat, labels, ratio=<span class="number">0.8</span>)</span>:</span></div><div class="line">    length = len(labels)</div><div class="line">    <span class="keyword">assert</span> dataMat.shape[<span class="number">0</span>] == length</div><div class="line">    trainNum = int(length * ratio)</div><div class="line">    <span class="keyword">print</span> <span class="string">'trainNum:&#123;&#125;'</span>.format(trainNum)</div><div class="line">    trainMat = dataMat[:trainNum]</div><div class="line">    testMat = dataMat[trainNum:]</div><div class="line">    trainLabel = labels[:trainNum]</div><div class="line">    testLabel = labels[trainNum:]</div><div class="line">    <span class="keyword">print</span> <span class="string">'trainMat:&#123;&#125; trainLabel:&#123;&#125;'</span>.format(trainMat.shape, len(trainLabel))</div><div class="line">    <span class="keyword">print</span> <span class="string">'testMat:&#123;&#125; testLabel:&#123;&#125;'</span>.format(testMat.shape, len(testLabel))</div><div class="line">    <span class="keyword">return</span> trainMat, trainLabel, testMat, testLabel</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sepQuery</span><span class="params">(queryList)</span>:</span></div><div class="line">    res = []</div><div class="line">    <span class="keyword">for</span> query <span class="keyword">in</span> queryList:</div><div class="line">        q = testDoc2vec.filterSymbol(query)</div><div class="line">        res.append(sepTest(query))</div><div class="line">    <span class="keyword">return</span> res</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveResult</span><span class="params">(result, file)</span>:</span></div><div class="line">    dir = <span class="string">'/data/haojiawei/data/'</span></div><div class="line">    resfile = dir + file</div><div class="line">    res = [i.strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>) <span class="keyword">for</span> i <span class="keyword">in</span> result]</div><div class="line">    f = open(resfile, <span class="string">'w'</span>)</div><div class="line">    f.write(<span class="string">'\n'</span>.join(res))</div><div class="line">    f.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterQuery</span><span class="params">(queryList, labelList)</span>:</span></div><div class="line">    querys = []</div><div class="line">    labels = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(queryList)):</div><div class="line">        <span class="keyword">if</span> len(queryList[i].strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>)) &gt;= <span class="number">2</span>:</div><div class="line">            querys.append(queryList[i])</div><div class="line">            labels.append(labelList[i])</div><div class="line">    <span class="keyword">return</span> querys, labels</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">training</span><span class="params">(rawfile)</span>:</span></div><div class="line">    <span class="comment"># queryList, labelList = loadData()</span></div><div class="line">    <span class="comment"># assert len(queryList) == len(labelList)</span></div><div class="line">    <span class="comment"># print queryList[0].encode('utf8')</span></div><div class="line">    <span class="comment"># print 'queryList len:&#123;&#125;'.format(len(queryList))</span></div><div class="line"></div><div class="line">    <span class="comment"># # filter too short query</span></div><div class="line">    <span class="comment"># querys, labels = filterQuery(queryList, labelList)</span></div><div class="line">    <span class="comment"># print 'querys len: &#123;&#125; labels len:&#123;&#125;'.format(len(querys), len(labels))</span></div><div class="line"></div><div class="line">    <span class="comment"># # separate sentence</span></div><div class="line">    <span class="comment"># sepQueryList = sepQuery(querys)</span></div><div class="line">    <span class="comment"># print 'sepQueryList len:&#123;&#125;'.format(len(sepQueryList))</span></div><div class="line">    <span class="comment"># # print sepQueryList[5].encode('utf8')</span></div><div class="line">    <span class="comment"># # saveResult(sepQueryList, 'sepQueryList')</span></div><div class="line">    dataMat, labels = vectorizer_TFIDF(rawfile, <span class="keyword">False</span>)</div><div class="line">    <span class="comment"># dataMat, labels = vectorizer(rawfile, False)</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'type(dataMat):&#123;&#125;'</span>.format(type(dataMat))</div><div class="line">    <span class="keyword">print</span> <span class="string">'dataMat.shape:&#123;&#125;'</span>.format(dataMat.shape)</div><div class="line">    <span class="keyword">print</span> <span class="string">'len(labels):&#123;&#125;'</span>.format(len(labels))</div><div class="line">    <span class="keyword">assert</span> dataMat.shape[<span class="number">0</span>] == len(labels)</div><div class="line">    <span class="comment"># return 0</span></div><div class="line">    <span class="comment"># np.savetxt('/data/haojiawei/data/vector',dataMat)</span></div><div class="line">    <span class="comment"># three = dataMat[3]</span></div><div class="line">    <span class="comment"># print three</span></div><div class="line">    <span class="comment"># print three[three&gt;0]</span></div><div class="line">    <span class="comment"># 经测试原向量维度5000多维,降维至1000维</span></div><div class="line">    <span class="comment"># plotVarPercent(dataMat)</span></div><div class="line">    <span class="comment"># lowDDataMat = pca.pca_Low(dataMat, dimension)</span></div><div class="line">    <span class="comment"># print lowDDataMat.shape</span></div><div class="line">    <span class="comment"># print labels</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'生成训练集,测试集合'</span>.encode(<span class="string">'utf8'</span>)</div><div class="line"></div><div class="line">    ratio = <span class="number">0.8</span></div><div class="line">    trainMat, trainLabel, testMat, testLabel = sepData(</div><div class="line">        dataMat, labels, ratio)</div><div class="line">    <span class="comment"># svm</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'enter svm'</span></div><div class="line">    alphas, b = svmMLIA.testSVM(dataMat, labels, testMat, testLabel, <span class="number">200</span>, <span class="number">0.0001</span>,</div><div class="line">                        <span class="number">10000</span>, (<span class="string">'rbf'</span>, <span class="number">1.3</span>), supportVectorDir, supportLabelDir, alphasDir, bDir)</div><div class="line">    <span class="keyword">print</span> <span class="string">'alphas:'</span></div><div class="line">    <span class="keyword">print</span> alphas[alphas &gt; <span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> b</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(testfile)</span>:</span></div><div class="line">    querys = []</div><div class="line">    <span class="keyword">if</span> <span class="string">'/'</span> <span class="keyword">not</span> <span class="keyword">in</span> testfile:</div><div class="line">        querys.append(testfile.strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>))</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">with</span> open(testfile, <span class="string">'r'</span>) <span class="keyword">as</span> f:</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">                querys.append(line.strip().replace(<span class="string">'\n'</span>, <span class="string">''</span>))</div><div class="line">    t1 = datetime.datetime.now()</div><div class="line">    <span class="keyword">print</span> <span class="string">'start predict &#123;&#125;'</span>.format(t1.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>))</div><div class="line">    <span class="comment">#去除字符</span></div><div class="line">    delSymbol_querys = [ testDoc2vec.filterSymbol(q) <span class="keyword">for</span> q <span class="keyword">in</span> querys]</div><div class="line">    <span class="comment"># 分词</span></div><div class="line">    sepQueryList = sepQuery(delSymbol_querys)</div><div class="line">    <span class="keyword">print</span> <span class="string">'len(sepQueryList):&#123;&#125;'</span>.format(len(sepQueryList))</div><div class="line">    <span class="comment"># 向量化</span></div><div class="line"></div><div class="line">    <span class="comment">#doc2vec</span></div><div class="line">    <span class="comment"># vectors = testDoc2vec.getVecs(sepQueryList, doc2VecModelDir)</span></div><div class="line">    vocab = grabDict(tf_idfVocabDir)</div><div class="line">    <span class="comment">#tf-idf</span></div><div class="line">    vectors, _ = vectorizer_TFIDF(sepQueryList, <span class="keyword">True</span>, vocab=vocab)</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">'vectors.shape:&#123;&#125;'</span>.format(vectors.shape)</div><div class="line">    <span class="comment"># 载入支持向量,alphas,b</span></div><div class="line">    sVs = np.mat(np.loadtxt(supportVectorDir))</div><div class="line">    labelSV = np.mat(np.loadtxt(supportLabelDir)).T</div><div class="line">    alphasSV = np.mat(np.loadtxt(alphasDir)).T</div><div class="line">    <span class="keyword">print</span> <span class="string">'sVs.type, labelSV.type, alphasSV.type:&#123;&#125;, &#123;&#125;, &#123;&#125;'</span>.format(type(sVs), type(labelSV), type(alphasSV))</div><div class="line">    <span class="keyword">print</span> <span class="string">'sVs.shape, labelSV.shape, alphasSV.shape:&#123;&#125;, &#123;&#125;, &#123;&#125;'</span>.format(sVs.shape, labelSV.shape, alphasSV.shape)</div><div class="line">    b = np.loadtxt(bDir).flat[<span class="number">0</span>]</div><div class="line">    <span class="comment"># 预测</span></div><div class="line">    m, n = np.shape(vectors)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = svmMLIA.kernelTrans(sVs, vectors[i, :], (<span class="string">'rbf'</span>, <span class="number">1.3</span>))</div><div class="line">        <span class="keyword">print</span> <span class="string">'kernelEval.shape:&#123;&#125;'</span>.format(kernelEval.shape)</div><div class="line">        a = np.multiply(labelSV, alphasSV)</div><div class="line">        <span class="keyword">print</span> <span class="string">'a.shape:&#123;&#125;'</span>.format(a.shape)</div><div class="line">        predict = kernelEval.T * np.multiply(labelSV, alphasSV) + b</div><div class="line">        res = <span class="number">0</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'predict:&#123;&#125;'</span>.format(predict)</div><div class="line">        <span class="keyword">if</span> predict &gt; <span class="number">0</span>:</div><div class="line">            res = <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            res = <span class="number">-1</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'&#123;&#125; class is :&#123;&#125;'</span>.format(querys[i], res)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeDict</span><span class="params">(dict, filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    fw = open(filename, <span class="string">'w'</span>)</div><div class="line">    pickle.dump(dict, fw)</div><div class="line">    fw.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabDict</span><span class="params">(filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">return</span> pickle.load(fr)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">if</span> len(sys.argv) != <span class="number">3</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'enter predict/train(1/0), testfile/trainfile'</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    task = int(sys.argv[<span class="number">1</span>])</div><div class="line">    file = sys.argv[<span class="number">2</span>]</div><div class="line">    <span class="keyword">if</span> task == <span class="number">1</span>:</div><div class="line">        predict(file)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        training(file)</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/07/SVM分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/07/SVM分类算法/" itemprop="url">SVM分类算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-07T11:01:02+08:00">
                2017-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-分类/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p><strong>使距离分隔超平面最近的异类样本点的距离最大</strong></p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p><em>对于数据集</em></p>
<blockquote>
<p>D = {(x1,y1),(x2,y2),…(xn,yn)} y=[-1,+1]<br>xi = (x1,x2,x3,…xm)</p>
</blockquote>
<p><em>有一个超平面把不同类别的数据分开</em></p>
<blockquote>
<p><em>超平面:w.T </em> x + b = 0</p>
<p>*w = (w1,w2, … ,w3)为法向量,决定超平面方向.<br>b为位移项,决定超平面与远点距离</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fgll1q3l6lj22c0340u0x.jpg" alt=""></p>
<p>上述问题等价于<br><strong>min{ 1/2 <em> ||w||<sup>2</sup>}  s.t. yi(w.T </em> xi + b)&gt;=1 i=1,2,3…m</strong></p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>(范数这段摘自:<a href="http://blog.csdn.net/zouxy09/article/details/24971995/" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/24971995/</a>)</p>
<h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><blockquote>
<ul>
<li>L0范数：<strong>是指向量中非0的元素的个数</strong></li>
<li>L1范数：<strong>是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）</strong></li>
<li>L2范数：<strong>是指向量各元素的平方和然后求平方根</strong></li>
</ul>
</blockquote>
<p><strong>L0范数、L1范数倾向于w的分量尽量稀疏,即非零分量个数尽量少</strong><br><strong>L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</strong><br><strong>L2范数倾向于w的分量取值尽量均衡,即非零分量个数尽量稠密</strong></p>
<h3 id="参数稀疏的好处"><a href="#参数稀疏的好处" class="headerlink" title="参数稀疏的好处"></a>参数稀疏的好处</h3><h4 id="1）特征选择-Feature-Selection-："><a href="#1）特征选择-Feature-Selection-：" class="headerlink" title="1）特征选择(Feature Selection)："></a>1）特征选择(Feature Selection)：</h4><blockquote>
<ul>
<li>大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。</li>
</ul>
</blockquote>
<h4 id="2）可解释性-Interpretability-："><a href="#2）可解释性-Interpretability-：" class="headerlink" title="2）可解释性(Interpretability)："></a>2）可解释性(Interpretability)：</h4><blockquote>
<ul>
<li>另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1<em>x1+w2</em>x2+…+w1000<em>x1000+b（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w</em>就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。</li>
</ul>
</blockquote>
<p>L2范数因为它的强大功效是改善机器学习里面一个非常重要的问题：<strong>过拟合</strong></p>
<blockquote>
<ul>
<li>过拟合是什么，上面也解释了，就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。通俗的讲就是应试能力很强，实际应用能力很差。擅长背诵知识，却不懂得灵活利用知识。</li>
</ul>
</blockquote>
<p><strong>为什么L2范数可以防止过拟合？</strong>。<br>L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。</p>
<blockquote>
<ul>
<li>这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。</li>
</ul>
</blockquote>
<p><strong>上面问题的等价转换用到了L2范数</strong></p>
<h2 id="拉格朗日乘子法转化问题"><a href="#拉格朗日乘子法转化问题" class="headerlink" title="拉格朗日乘子法转化问题"></a>拉格朗日乘子法转化问题</h2><blockquote>
<ul>
<li>原问题：<strong>min 1/2 <em> ||w||<sup>2</sup>  s.t. yi(w.T </em> xi + b)&gt;=1 i=1,2,3…m</strong></li>
</ul>
</blockquote>
<p>构造拉格朗日函数:<br><img src="http://images2015.cnblogs.com/blog/731104/201606/731104-20160601161233696-300846876.png" alt=""></p>
<blockquote>
<ul>
<li>L(w,b,alpha) = <strong>1/2 <em> ||w||<sup>2</sup> + sigma{alpha[i] </em> (1-yi(w.T * x+b))}  s.t. alpha[i]&gt;=0</strong></li>
</ul>
</blockquote>
<p>由前面的约束得到:<strong>(1-yi(w.T * x+b)&lt;=0</strong><br>当alpha[i] &gt;= 0 (1-yi(w.T <em> x+b)&lt;=0 都满足时:<br>**max L = 1/2 </em> ||w||<sup>2</sup><em>*<br>令theta(w) = max L(w,b,alpha) = 1/2 </em> ||w||<sup>2</sup></p>
<p><strong>min 1/2 * ||w||<sup>2</sup> = min  max L(w,b,alpha) = p</strong></p>
<p><strong>max min L(w,b,alpha) = d</strong></p>
<p>则:d&lt;=p</p>
<p><strong>这里交换了min、max的顺序.即最大值中的最小的也比最小值中的最大的大</strong><br>当满足KKT条件时 d=p<br>KKT条件详解:<a href="http://blog.csdn.net/on2way/article/details/47729419" target="_blank" rel="external">http://blog.csdn.net/on2way/article/details/47729419</a></p>
<p>L对w,b分别求偏导然后置0,得到:</p>
<blockquote>
<ul>
<li>w = sigma{alpha[i] <em> yi </em> xi}</li>
<li>0 = sigma{alpha[i] * yi}</li>
</ul>
</blockquote>
<p>两式带入L得原问题的对偶问题:<br><img src="http://my.csdn.net/uploads/201206/02/1338605996_4659.jpg" alt=""></p>
<h2 id="模型预测"><a href="#模型预测" class="headerlink" title="模型预测:"></a>模型预测:</h2><p>f(x) = w.T <em> x + b<br>带入w<br>f(x) = sum(alpha[i] </em> yi <em> (x </em> x[i].T)) + b<br><code>由下面算法求解alpha后就可以求某点的预测值</code><br>对于待分类数据x,只要计算f = sum(alpha[i] <em> yi </em> (x * x[i].T)) + b<br>f &gt; 0 +1类<br>f &lt; 0 -1类</p>
<h2 id="SMO算法求解问题"><a href="#SMO算法求解问题" class="headerlink" title="SMO算法求解问题:"></a>SMO算法求解问题:</h2><ul>
<li><p>[X]1.固定一个alpha[i]参数,如果alpha[i]违反了KKT条件则进入下一步,否则重新选择i</p>
</li>
<li><p>[X]2.在alpha中选择一个有效的(因为初始时alpha全置0)、不等于i的、预测值与实际值差距最大的alpha[j]</p>
</li>
<li><p>[X]3.根据KKT条件以及alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z 确定alpha[j]的上下界[L,H]</p>
<blockquote>
<ul>
<li>原问题得到的拉格朗日对偶问题约束条件sum(alphai <em> yi) = 0<br>仅考虑alpha[i],alpha[j]时,约束重写为:<br>alpha[i] </em> yi + alpha[j] <em> yj = z<br>(alpha[i]&gt;=0 alpha[j]&gt;=0  z=-sum(alpha[k]yk) k!=i,j)<br>则更新前后的alpha满足:<br>alphaInew</em>yi + alphaJnew<em>yj = alphaIold</em>yi + alphaJold<em>yj = z<br>yi和yj不是+1就是-1<br>讨论yi=yj 和yi!=yj的两种情况,得到alphaJnew的上下界<br><em>*详见：<a href="http://blog.csdn.net/on2way/article/details/47730367" target="_blank" rel="external">http://blog.csdn.net/on2way/article/details/47730367</a></em></em></li>
</ul>
</blockquote>
</li>
<li><p>[X]4.更新alpha[j]</p>
<blockquote>
<ul>
<li>更新alphas[j]解来源:<br> 1.把拉格朗日对偶问题有alpha[i],alpha[j]单一式独展开的(一式)<br> 2.由于有alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z<br> 可以把alpha[i]消掉,带入一式,(得到二式)<br> 3.二式对alpha[j]求导等于0<br> 4.得到alpha[j]和alphaJold关系<br> <strong>推导详见:</strong><pre><code>http://blog.csdn.net/on2way/article/details/47730367
http://blog.csdn.net/v_july_v/article/details/7624837
</code></pre></li>
</ul>
</blockquote>
</li>
<li><p>[X]5.调整alpha[j]大小到[L,H]</p>
</li>
<li><p>[X]6.更新alpha[i]</p>
<blockquote>
<ul>
<li>由约束:alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z<br>  以及:yi<em>yi = 1 yj</em>yj = 1<br>  得：<br>  alphaInew<em>yi = alphaIold</em>yi + yj(alphaJold-alphaJnew)<br>  alphaInew = alphaIold + yi*yj(alphaJold-alphaJnew)</li>
</ul>
</blockquote>
</li>
<li><p>[X]7.更新b<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglouk6i4kj22c0340x6p.jpg" alt=""></p>
</li>
</ul>
<p><strong>直到某次循环没有一个alpha更新或者循环次数达到则完成。</strong></p>
<h2 id="非线性数据分类"><a href="#非线性数据分类" class="headerlink" title="非线性数据分类"></a>非线性数据分类</h2><p><code>引入核函数</code><br><strong>目的:将样本从原始空间映射到一个更高维的特征空间,是的样本在这个特征空间内线性可分.</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpn5dtdsj22c03404qq.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpo09568j22c03407wi.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpnnmoouj22c03401ky.jpg" alt=""></p>
<h2 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h2><blockquote>
<ul>
<li>之前的都是所有样本必须划分正确—“硬间隔”</li>
<li>允许某些样本不满足约束 yi(w.T <em> x + b) &gt;= 1 —“软间隔”<br>  即:某些样本与分隔超平面的距离小于 |w.T </em> x + b|/||w||<br>  在wx+b=+1 和wx+b=-1之间</li>
</ul>
</blockquote>
<p><code>hinge损失函数:l(z) = max(0,1-z)</code></p>
<blockquote>
<ul>
<li>优化目标可写为：<strong>min{ 1/2 <em> ||w||二次方 + C</em>sigma max(0, yi(w.T * x + b))}</strong></li>
</ul>
</blockquote>
<p><strong>松弛变量(slack variables):它对应数据点允许偏离的functional margin量</strong></p>
<p>函数间隔:<br><img src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131534858.png" alt=""></p>
<p>详见:<br><a href="http://blog.csdn.net/shenziheng1/article/details/53884071" target="_blank" rel="external">http://blog.csdn.net/shenziheng1/article/details/53884071</a></p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-05</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="comment">#import numpy as np</span></div><div class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName=<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSet.txt'</span>)</span>:</span></div><div class="line">    dataMat = [] ; labelMat = []</div><div class="line">    <span class="keyword">with</span> open(fileName) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">            lineArr = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">            dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</div><div class="line">            labelMat.append(float(lineArr[<span class="number">2</span>]))</div><div class="line">    <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"><span class="comment"># 在某一范围随机选择一个不同于指定数字的数</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span>:</span></div><div class="line">    j = i</div><div class="line">    <span class="keyword">while</span> j == i:</div><div class="line">        j = int(random.uniform(<span class="number">0</span>, m))</div><div class="line">    <span class="keyword">return</span> j</div><div class="line"></div><div class="line"><span class="comment"># 调整数值在一个范围内</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipApha</span><span class="params">(aj, H, L)</span>:</span></div><div class="line">    <span class="keyword">if</span> aj &gt; H:</div><div class="line">        aj = H</div><div class="line">    <span class="keyword">if</span> L &gt; aj:</div><div class="line">        aj = L</div><div class="line">    <span class="keyword">return</span> aj</div><div class="line"></div><div class="line"><span class="comment"># 简化版SMO算法</span></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    params:数据集 类别标签 常数C 容错率 推出前最大循环次数</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoSimple</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span>:</span></div><div class="line">    dataMatrix = mat(dataMatIn)</div><div class="line">    labelMat = mat(classLabels).transpose()</div><div class="line">    b = <span class="number">0</span></div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    alphas = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    iter = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> iter &lt; maxIter:</div><div class="line">        alphaPairsChanged = <span class="number">0</span>  <span class="comment"># 用于记录alpha是否已经进行优化</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">            <span class="comment"># fXi:预测的类别</span></div><div class="line">            fXi = float(multiply(alphas, labelMat).T *</div><div class="line">                        (dataMatrix * dataMatrix[i, :].T)) + b</div><div class="line">            Ei = fXi - float(labelMat[i])  <span class="comment"># 误差</span></div><div class="line">            <span class="comment"># 不论正负间隔都会测试,且alpha在(0,C)之间</span></div><div class="line">            <span class="keyword">if</span> ((labelMat[i] * Ei &lt; -toler) <span class="keyword">and</span> (alphas[i] &lt; C)) <span class="keyword">or</span> \</div><div class="line">                    ((labelMat[i] * Ei &gt; toler) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)):</div><div class="line">                j = selectJrand(i, m)  <span class="comment"># 随机选择另一个alpha</span></div><div class="line">                <span class="comment"># 计算出j对应的误差Ej</span></div><div class="line">                fXj = float(multiply(alphas, labelMat).T *</div><div class="line">                            (dataMatrix * dataMatrix[j, :].T)) + b</div><div class="line">                Ej = fXj - float(labelMat[j])</div><div class="line">                alphaIold = alphas[i].copy()  <span class="comment"># 保存旧的2个alpha 以便后面比较</span></div><div class="line">                alphaJold = alphas[j].copy()</div><div class="line">                <span class="comment"># 计算L、H 用于把alpha[j]调整到[L,H]</span></div><div class="line">                <span class="keyword">if</span> labelMat[i] != labelMat[j]:</div><div class="line">                    L = max(<span class="number">0</span>, alphas[j] - alphas[i])</div><div class="line">                    H = min(C, C + alphas[j] - alphas[i])</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    L = max(<span class="number">0</span>, alphas[j] + alphas[i] - C)</div><div class="line">                    H = min(C, alphas[j] + alphas[i])</div><div class="line">                <span class="keyword">if</span> L == H:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'L==H'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># eta是最优修改量</span></div><div class="line">                eta = <span class="number">2.0</span> * dataMatrix[i, :] * dataMatrix[j, :].T - \</div><div class="line">                    dataMatrix[i, :] * dataMatrix[i, :].T - \</div><div class="line">                    dataMatrix[j, :] * dataMatrix[j, :].T</div><div class="line">                <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'eta&gt;=0'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># 计算一个新的alpha[j],并且调整到[L,H]</span></div><div class="line">                alphas[j] -= labelMat[j] * (Ei - Ej) / eta</div><div class="line">                alphas[j] = clipApha(alphas[j], H, L)</div><div class="line">                <span class="keyword">if</span> abs(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'j not moving enough'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># 计算一个新的alpha[i] 变化方向和j相反</span></div><div class="line">                alphas[i] += labelMat[j] * labelMat[i] * \</div><div class="line">                    (alphaJold - alphas[j])</div><div class="line"></div><div class="line">                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T</div><div class="line"></div><div class="line">                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T</div><div class="line">                <span class="keyword">if</span> (<span class="number">0</span> &lt; alphas[i]) <span class="keyword">and</span> (C &gt; alphas[i]):</div><div class="line">                    b = b1</div><div class="line">                <span class="keyword">elif</span> (<span class="number">0</span> &lt; alphas[j]) <span class="keyword">and</span> (C &gt; alphas[j]):</div><div class="line">                    b = b2</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    b = (b1 + b2) / <span class="number">2.0</span></div><div class="line">                alphaPairsChanged += <span class="number">1</span></div><div class="line">                <span class="keyword">print</span> <span class="string">'iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>\</div><div class="line">                    .format(iter, i, alphaPairsChanged)</div><div class="line">        <span class="keyword">if</span> alphaPairsChanged == <span class="number">0</span>:</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            iter = <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> b, alphas</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotRes</span><span class="params">(data, label, weightsMat, bMat, alphasMat, drawSep=True)</span>:</span></div><div class="line">    svx = []; svy = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        <span class="keyword">if</span> alphasMat[i] &gt; <span class="number">0</span>:</div><div class="line">            svx.append(data[i][<span class="number">0</span>])</div><div class="line">            svy.append(data[i][<span class="number">1</span>])</div><div class="line">    b = bMat.A[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    x1cord = []; y1cord = []</div><div class="line">    x2cord = []; y2cord = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        tmp = data[i]</div><div class="line">        <span class="keyword">if</span> label[i] == <span class="number">1.0</span> :</div><div class="line">            x1cord.append(tmp[<span class="number">0</span>]); y1cord.append(tmp[<span class="number">1</span>])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            x2cord.append(tmp[<span class="number">0</span>]); y2cord.append(tmp[<span class="number">1</span>])</div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line">    ax.scatter(x1cord, y1cord, s=<span class="number">40</span>, c=<span class="string">'red'</span>, marker=<span class="string">'o'</span>)</div><div class="line">    ax.scatter(x2cord, y2cord, s=<span class="number">40</span>, c=<span class="string">'blue'</span>, marker=<span class="string">'s'</span>)</div><div class="line">    ax.scatter(svx, svy, s=<span class="number">10</span>, c=<span class="string">'yellow'</span>, marker=<span class="string">'s'</span>)</div><div class="line">    <span class="keyword">if</span> drawSep:</div><div class="line">        x = arange(<span class="number">2.0</span>, <span class="number">6.0</span>, <span class="number">0.1</span>)</div><div class="line">        y = (-b-weightsMat.flat[<span class="number">0</span>]*x) / weightsMat.flat[<span class="number">1</span>]</div><div class="line">        ax.plot(x,y)</div><div class="line">    plt.xlabel(<span class="string">'X'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Y'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    分割超平面:w.T*x+b=0</div><div class="line">    w是个向量,data[i]也是个向量。维度一一对应</div><div class="line">    w = sum(alphas[i]*label[i]*data[i])</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcW</span><span class="params">(alphasMat, label, dataMat)</span>:</span></div><div class="line">    alphasArr = alphasMat.T.A[<span class="number">0</span>]</div><div class="line">    labelArr = array(label)</div><div class="line">    alphasMulLab = alphasArr * labelArr</div><div class="line">    <span class="comment"># (2,100) * (100,1) = (2,1)</span></div><div class="line">    <span class="keyword">print</span> dataMat.T * mat(alphasMulLab).T</div><div class="line">    weight = dataMat.T * mat(alphasMulLab).T</div><div class="line">    <span class="keyword">print</span> weight</div><div class="line">    <span class="keyword">return</span> weight</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 作为优化SMO的数据结构类</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></div><div class="line">        self.X = dataMatIn</div><div class="line">        self.labelMat = classLabels</div><div class="line">        self.C = C</div><div class="line">        self.tol = toler</div><div class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</div><div class="line">        self.alphas = mat(zeros((self.m, <span class="number">1</span>)))</div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        self.eCache = mat(zeros((self.m, <span class="number">2</span>)))</div><div class="line">        self.K = mat(zeros((self.m, self.m)))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</div><div class="line">            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)</div><div class="line"></div><div class="line"><span class="comment"># 计算给定数据点k的误差 =预测值-实际值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        f(x) = sum(alpha[i] * label[i] * (x * x[i].T)) + b</div><div class="line">        (oS.X * oS.X[k, :].T) (100,2)*(2,1) = (100,1) 每个数据点和第k个数据点做内积</div><div class="line">        fXk:对于k点的模型预测值</div><div class="line">    '''</div><div class="line">    <span class="comment"># fXk = float(multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k, :].T)) + oS.b</span></div><div class="line">    fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:, k]) + oS.b</div><div class="line">    Ek = fXk - float(oS.labelMat[k])</div><div class="line">    <span class="keyword">return</span> Ek</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    启发式方法选择alpha[j]</div><div class="line">    选择</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></div><div class="line">    maxK = <span class="number">-1</span>; maxDeltaE = <span class="number">0</span>; Ej = <span class="number">0</span></div><div class="line">    oS.eCache[i] = [i, Ei]</div><div class="line">    validEcacheList = nonzero(oS.eCache[:, <span class="number">0</span>].A)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">if</span> len(validEcacheList) &gt; <span class="number">1</span> :</div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</div><div class="line">            <span class="keyword">if</span> k == i :</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            Ek = calcEk(oS, k)</div><div class="line">            deltaE = abs(Ei - Ek)</div><div class="line">            <span class="keyword">if</span> deltaE &gt; maxDeltaE :</div><div class="line">                maxK = k; maxDeltaE = deltaE; Ej = Ek</div><div class="line">        <span class="comment">#return maxK, Ej</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        j = selectJrand(i, oS.m)</div><div class="line">        Ej = calcEk(oS, j)</div><div class="line">        maxK = j</div><div class="line">    <span class="keyword">return</span> maxK, Ej</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    Ek = calcEk(oS, k)</div><div class="line">    oS.eCache[k] = [<span class="number">1</span>, Ek]</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    根据alphas[i]固定alphas[j],更新这两个值</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></div><div class="line">    Ei = calcEk(oS, i)</div><div class="line">    <span class="string">'''</span></div><div class="line">        违反KKT条件的两种情况</div><div class="line">        1.yi*Ei&lt;=1 and alphas[i]&lt;C</div><div class="line">        2.yi*Ei&gt;=1 and alphas[i]&gt;0</div><div class="line">        因为会存在一些噪声数据, 加入松弛变量允许一些点到分类平面的距离不满足原先的要求</div><div class="line">        原本的约束yi*(w*bi_b)&gt;=1 变为:yi*(w*bi_b)&gt;=1-S (i=1,2,... S&gt;=0)</div><div class="line">        这里的tol=1-S</div><div class="line">        详见：http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> ((oS.labelMat[i] * Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> \</div><div class="line">        ((oS.labelMat[i] * Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</div><div class="line">        j, Ej = selectJ(i, oS, Ei)</div><div class="line">        <span class="comment"># 保存旧的2个alpha 以便后面比较</span></div><div class="line">        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy()</div><div class="line"></div><div class="line">        <span class="string">'''</span></div><div class="line">            原问题得到的拉格朗日对偶问题约束条件sum(alphai * yi) = 0</div><div class="line">            仅考虑alpha[i],alpha[j]时,约束重写为:</div><div class="line">                alpha[i]*yi + alpha[j]*yj = z   </div><div class="line">                (alpha[i]&gt;=0 alpha[j]&gt;=0  z=-sum(alpha[k]yk) k!=i,j)</div><div class="line">            则更新前后的alpha满足:</div><div class="line">                alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">                yi和yj不是+1就是-1</div><div class="line">                讨论yi=yj 和yi!=yj的两种情况,得到alphaJnew的上下界</div><div class="line">                详见：http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">        '''</div><div class="line">        <span class="comment"># 计算L、H 用于把alpha[j]调整到[L,H]</span></div><div class="line">        <span class="keyword">if</span> oS.labelMat[i] != oS.labelMat[j]:</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</div><div class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</div><div class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</div><div class="line">        <span class="keyword">if</span> L == H:</div><div class="line">            <span class="keyword">print</span> <span class="string">'L==H'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line">        <span class="string">'''</span></div><div class="line">            更新alphas[j]解来源:</div><div class="line">            1.把拉格朗日对偶问题有alpha[i],alpha[j]单一式独展开的(一式)</div><div class="line">            2.由于有alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">            可以把alpha[i]消掉,带入一式,(得到二式)</div><div class="line">            3.二式对alpha[j]求导等于0</div><div class="line">            4.得到alpha[j]和alphaJold关系</div><div class="line">            推导详见:</div><div class="line">                http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">                http://blog.csdn.net/v_july_v/article/details/7624837</div><div class="line">        '''</div><div class="line">        <span class="comment"># alpha[j] updata formula alpha[j] = alpha[j] -/+ yi(Ei-Ej)/eta</span></div><div class="line">        <span class="comment"># eta=2*xi*xj -xi*xi.T-xj*xj.T : 实际上是度量两个样本i和j的相似性的</span></div><div class="line">        <span class="comment"># eta = 2.0 * oS.X[i, :] * oS.X[j, :].T - oS.X[i, :] * oS.X[i, :].T - \</span></div><div class="line">        <span class="comment">#             oS.X[j, :] * oS.X[j, :].T</span></div><div class="line"></div><div class="line">        <span class="comment"># use kernel function</span></div><div class="line">        eta = <span class="number">2.0</span> * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]</div><div class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">'eta&gt;=0'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta</div><div class="line">        oS.alphas[j] = clipApha(oS.alphas[j], H, L)</div><div class="line">        updateEk(oS, j)</div><div class="line">        <span class="keyword">if</span> abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span> :</div><div class="line">            <span class="keyword">print</span> <span class="string">'j not moving enough'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        <span class="string">'''</span></div><div class="line">            由约束:alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">            以及:yi*yi = 1 yj*yj = 1</div><div class="line">            得：</div><div class="line">            alphaInew*yi = alphaIold*yi + yj(alphaJold-alphaJnew)</div><div class="line">            alphaInew = alphaIold + yi*yj(alphaJold-alphaJnew)</div><div class="line">        '''</div><div class="line">        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])</div><div class="line">        updateEk(oS, i)</div><div class="line">        <span class="string">'''</span></div><div class="line">            http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">        '''</div><div class="line">        <span class="comment"># b1 = oS.b - Ei - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T</span></div><div class="line">        <span class="comment"># b2 = oS.b - Ej - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T</span></div><div class="line">        <span class="comment"># use kernel function</span></div><div class="line">        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]</div><div class="line">        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]</div><div class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]):</div><div class="line">            oS.b = b1</div><div class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]):</div><div class="line">            oS.b = b2</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            oS.b = (b1 + b2) / <span class="number">2.0</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter, kTup=<span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span></div><div class="line">    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup)</div><div class="line">    iter = <span class="number">0</span></div><div class="line">    entireSet = <span class="keyword">True</span>; alphaPairsChanged = <span class="number">0</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        1.entireSet = True 遍历所有数据点,更新alphas</div><div class="line">        2.entireSet 设为False 遍历非边界数据点,调整alpha (优先选择遍历非边界数据样本,因为非边界数据样本更有可能需要调整,边界数据样本常常不能得到进一步调整而留在边界上).</div><div class="line">        3.持续调整非边界数据点,直到没有更新一个alpha entireSet 再设为True</div><div class="line">        4.重新遍历所有数据点,更新alphas</div><div class="line">        5.如果整个集合的检验中又有数据样本被 进一步进化,则有必要再遍历非边界数据样本</div><div class="line">        6.反复交替遍历所有点和非边界点</div><div class="line">        7.直到所有数据点遍历后没有一个alpha变化 或者迭代次数到底预设值maxIter,退出循环</div><div class="line">    '''</div><div class="line">    <span class="keyword">while</span> (iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)) :</div><div class="line">        alphaPairsChanged = <span class="number">0</span></div><div class="line">        <span class="keyword">if</span> entireSet:</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">'fullSet, iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>.format(iter, i, alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># 取出alphas中在(0,C)之间的数值的index</span></div><div class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>)*(oS.alphas.A &lt; C))[<span class="number">0</span>]</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">'non-bound, iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>.format(iter, i ,alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> entireSet:</div><div class="line">            entireSet = <span class="keyword">False</span></div><div class="line">        <span class="keyword">elif</span> alphaPairsChanged == <span class="number">0</span>:</div><div class="line">            entireSet = <span class="keyword">True</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'iteration number: &#123;&#125;'</span>.format(iter)</div><div class="line">    <span class="keyword">return</span> oS.b, oS.alphas</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></div><div class="line">    m, n = shape(X)</div><div class="line">    K = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>] == <span class="string">'lin'</span>:</div><div class="line">        K = X * A.T</div><div class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>] == <span class="string">'rbf'</span>:</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</div><div class="line">            deltaRow = X[j, :] - A</div><div class="line">            K[j] = deltaRow * deltaRow.T</div><div class="line">        K = exp(K/(<span class="number">-1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>))</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">raise</span> NameError(<span class="string">'Houston We Have a Problem -- That Kernel is not recognized'</span>)</div><div class="line">    <span class="keyword">return</span> K</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testSVM</span><span class="params">(dataArr1, labelArr1, dataArr2, labelArr2, C, toler, maxIter, kTup)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'start smoP'</span></div><div class="line">    b, alphas = smoP(dataArr1, labelArr1, C, toler, maxIter, kTup)</div><div class="line">    <span class="keyword">print</span> <span class="string">'finish smoP'</span></div><div class="line">    datMat = mat(dataArr1); labelMat = mat(labelArr1).transpose()</div><div class="line">    svInd = nonzero(alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</div><div class="line">    sVs = datMat[svInd]</div><div class="line">    labelSV = labelMat[svInd]</div><div class="line">    <span class="keyword">print</span> <span class="string">'ther are &#123;&#125; support Vectors'</span>.format(shape(sVs)[<span class="number">0</span>])</div><div class="line">    m, n = shape(datMat)</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)</div><div class="line">        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict) != sign(labelArr1[i]):</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the training error rate is :&#123;&#125;'</span>.format(float(errorCount)/m)</div><div class="line"></div><div class="line">    <span class="comment"># test</span></div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    datMat = mat(dataArr2); labelMat = mat(labelArr2).transpose()</div><div class="line">    m, n = shape(datMat)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)</div><div class="line">        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict) != sign(labelArr2[i]):</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the test error rate is :&#123;&#125;'</span>.format(float(errorCount)/m)</div><div class="line">    <span class="keyword">return</span> alphas, b</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    测试径向核函数</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1=<span class="number">1.3</span>)</span>:</span></div><div class="line">    <span class="comment"># training</span></div><div class="line">    dataArr1, labelArr1 = loadDataSet(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSetRBF.txt'</span>)</div><div class="line">    dataArr2, labelArr2 = loadDataSet(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSetRBF2.txt'</span>)</div><div class="line">    alphas, b = testSVM(dataArr1, labelArr1, dataArr2, labelArr2, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">'rbf'</span>, k1))</div><div class="line">    <span class="keyword">return</span> dataArr1, labelArr1, alphas, b</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(filename)</span>:</span></div><div class="line">    returnVect = zeros((<span class="number">1</span>, <span class="number">1024</span>))</div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">        line = fr.readline()</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">            returnVect[<span class="number">0</span>, <span class="number">32</span> * i + j] = int(line[j])</div><div class="line">    <span class="keyword">return</span> returnVect</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadImages</span><span class="params">(dirName)</span>:</span></div><div class="line">    hwLabels = []</div><div class="line">    trainingFileList = listdir(dirName)</div><div class="line">    m = len(trainingFileList)</div><div class="line">    trainingMat = zeros((m, <span class="number">1024</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        fileNameStr = trainingFileList[i]</div><div class="line">        fileStr = fileNameStr.split(<span class="string">'.'</span>)[<span class="number">0</span>]</div><div class="line">        classNumStr = int(fileStr.split(<span class="string">'_'</span>)[<span class="number">0</span>])</div><div class="line">        <span class="keyword">if</span> classNumStr == <span class="number">9</span>:</div><div class="line">            hwLabels.append(<span class="number">-1</span>)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            hwLabels.append(<span class="number">1</span>)</div><div class="line">        trainingMat[i, :] = img2vector(<span class="string">'&#123;&#125;\\&#123;&#125;'</span>.format(dirName, fileNameStr))</div><div class="line">    <span class="keyword">return</span> trainingMat, hwLabels</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testDigits</span><span class="params">(kTup=<span class="params">(<span class="string">'rbf'</span>, <span class="number">10</span>)</span>)</span>:</span></div><div class="line">    dataArr1, labelArr1 = loadImages(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\trainingDigits'</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'read trainingSet finish'</span></div><div class="line">    dataArr2, labelArr2 = loadImages(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\testDigits'</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'read testSet finish'</span></div><div class="line"></div><div class="line">    alphas, b = testSVM(dataArr1, labelArr1, dataArr2, labelArr2, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, kTup)</div><div class="line">    <span class="comment">#return dataArr1, labelArr1, alphas, b</span></div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/04/Logistic回归分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/04/Logistic回归分类算法/" itemprop="url">Logistic回归分类算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-04T14:39:42+08:00">
                2017-06-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-分类/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h1><hr>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34ef0bf30a2cd7e90e87221cfc796dcf4f265d56" alt="sigmoid"><br><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png" alt=""></p>
<ul>
<li>S(x)’</li>
</ul>
<p><img src="http://img.blog.csdn.net/20170326113104537?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY2FpbW91c2U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>sigmoid函数为线性函数引入了非线性变化,让0到1之间的变化不是断崖式变化.</p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>有xi=[x1,x2,…,xn]—-yi<br>f(x) = a0+a1<em>x1+a2</em>x2+…+an<em>Xn<br>用f(x)去拟合y的变化<br><em>*实际上就是求一组参数a0….an</em></em></p>
<ul>
<li>cost Function J(ceta) : 用来度量模型预测值与真实值之间的差距。</li>
</ul>
<p><strong>这个值越好,就说明模型越接近真实情况</strong></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>线性回归后的结果再经过sigmoid函数,即：</p>
<pre><code>z(x) =  a0+a1x1+a2x2+...+anXn
f(x) = sigmoid(z)
</code></pre><p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg96xqgxarj20l30hjjs0.jpg" alt=""></p>
<ul>
<li>Cost(h(x),y)综合起来：</li>
</ul>
<p><img src="http://img.blog.csdn.net/20140716153740866" alt=""></p>
<p>最终的J:<br><img src="http://img.blog.csdn.net/20140716153733362" alt=""></p>
<p>梯度下降法更新参数值：<br><img src="http://img.my.csdn.net/uploads/201407/16/1405496972_1821.png" alt=""><br><img src="http://img.my.csdn.net/uploads/201407/16/1405496975_3372.png" alt=""></p>
<p><strong>梯度上升法则是一个负号的关系</strong></p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ul>
<li>构建数据集矩阵和标签列表</li>
<li>训练分类器</li>
<li>将测试数据分类</li>
</ul>
<h3 id="输入"><a href="#输入" class="headerlink" title="输入:"></a>输入:</h3><blockquote>
<p>待分类向量</p>
<p>dataSet向量集合(有签[A,B,C,D,E,F…])  </p>
<p>Label =[A,B,C,D,E,F… ]</p>
</blockquote>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul>
<li>优点: 计算代价不高、易于实现和理解</li>
<li>缺点: 容易欠拟合、分类精度不高</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-05-02</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 重置数据点的label 把以(0.0,6.0)为圆心, 4为半径的圆作为2类数据的分界线</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">circleSign</span><span class="params">(x, y)</span>:</span></div><div class="line">    <span class="comment"># print x, y</span></div><div class="line">    sq = (<span class="number">0.0</span> - x)**<span class="number">2</span> + (<span class="number">6.0</span> - y)**<span class="number">2</span></div><div class="line">    <span class="comment"># print sq</span></div><div class="line">    <span class="keyword">if</span> sq &gt; <span class="number">16</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">()</span>:</span></div><div class="line">    dataMat = []</div><div class="line">    labelMat = []</div><div class="line">    fr = open(</div><div class="line">        <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch05\\testSet.txt'</span>)</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</div><div class="line">        lineArr = line.strip().split()</div><div class="line">        <span class="comment"># dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])</span></div><div class="line">        <span class="comment"># # labelMat.append(int(lineArr[2]))</span></div><div class="line">        <span class="comment"># labelMat.append(circleSign(float(lineArr[0]), float(lineArr[1])))</span></div><div class="line"></div><div class="line">        <span class="comment"># 尝试用圆方程拟合曲线</span></div><div class="line">        dataMat.append([float(lineArr[<span class="number">0</span>])**<span class="number">2</span>, float(lineArr[<span class="number">1</span>])</div><div class="line">                        ** <span class="number">2</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>]), <span class="number">1.0</span>])</div><div class="line">        labelMat.append(circleSign(float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1</span> + exp(-inX))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></div><div class="line">    dataMatrix = mat(dataMatIn)</div><div class="line">    labelMat = mat(classLabels).transpose()</div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    alpha = <span class="number">0.001</span></div><div class="line">    maxCycles = <span class="number">50000</span></div><div class="line">    weights = ones((n, <span class="number">1</span>))</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):</div><div class="line">        h = sigmoid(dataMatrix * weights)</div><div class="line">        error = (labelMat - h)</div><div class="line">        <span class="string">'''</span></div><div class="line">            这里存在一个公式推导</div><div class="line">            推导损失函数的梯度</div><div class="line">            http://blog.csdn.net/lu597203933/article/details/38468303</div><div class="line">        '''</div><div class="line">        weights = weights + alpha * dataMatrix.transpose() * error</div><div class="line">    <span class="keyword">return</span> weights</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    随机梯度上升法0.0</div><div class="line">    参数weight type:numpy.ndarray shape:(5L,)</div><div class="line">    plotBestFit 函数需要的参数是 type:numpy.ndarray shape:(5L, 1L)</div><div class="line">    所以需要reshape操作</div><div class="line">    如果只训练数据个数次数,效果很差,连圆都画不出来,</div><div class="line">    在外面加了100此循环,有个双曲线,加到10000次,才拟合出椭圆</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGrandAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    alpha = <span class="number">0.01</span></div><div class="line">    weights = ones(n)</div><div class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">150</span>):</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">            h = sigmoid(sum(dataMatrix[i] * weights))</div><div class="line">            error = classLabels[i] - h</div><div class="line">            weights = weights + alpha * dataMatrix[i] * error</div><div class="line">    <span class="keyword">return</span> weights</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    随机梯度上升0.1</div><div class="line">    update: 1.增加了迭代参数</div><div class="line">            2.每一轮迭代随机选数据进行训练参数</div><div class="line">            3.训练步长每次递减</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGrandAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    weights = ones(n)</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</div><div class="line">        dataIndex = range(m)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">            alpha = <span class="number">4</span> / (<span class="number">1.0</span> + i + j) + <span class="number">0.01</span></div><div class="line">            randIndex = int(random.uniform(<span class="number">0</span>, len(dataIndex)))</div><div class="line">            h = sigmoid(sum(dataMatrix[randIndex] * weights))</div><div class="line">            error = classLabels[randIndex] - h</div><div class="line">            weights = weights + alpha * dataMatrix[randIndex] * error</div><div class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</div><div class="line">    <span class="keyword">return</span> weights</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></div><div class="line">    w = weights</div><div class="line">    dataMat, labelMat = loadData()</div><div class="line">    dataArr = array(dataMat)</div><div class="line">    n = shape(dataArr)[<span class="number">0</span>]</div><div class="line">    xcord1 = []</div><div class="line">    ycord1 = []</div><div class="line">    xcord2 = []</div><div class="line">    ycord2 = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">        <span class="keyword">if</span> int(labelMat[i]) == <span class="number">1</span>:</div><div class="line">            <span class="comment"># xcord1.append(dataArr[i, 1])</span></div><div class="line">            <span class="comment"># ycord1.append(dataArr[i, 2])</span></div><div class="line">            xcord1.append(dataArr[i, <span class="number">2</span>])</div><div class="line">            ycord1.append(dataArr[i, <span class="number">3</span>])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># xcord2.append(dataArr[i, 1])</span></div><div class="line">            <span class="comment"># ycord2.append(dataArr[i, 2])</span></div><div class="line">            xcord2.append(dataArr[i, <span class="number">2</span>])</div><div class="line">            ycord2.append(dataArr[i, <span class="number">3</span>])</div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">30</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</div><div class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">30</span>, c=<span class="string">'green'</span>)</div><div class="line">    <span class="comment"># x = arange(-3.0, 3.0, 0.1)</span></div><div class="line">    <span class="comment"># y = (-weights[0]-weights[1]*x)/weights[2]</span></div><div class="line">    <span class="comment"># x = arange(-2.5, 15.0, 0.1)</span></div><div class="line">    <span class="comment">#y = (-weights[0]-weights[1]*x)</span></div><div class="line"></div><div class="line">    x = y = arange(<span class="number">-15.0</span>, <span class="number">15.0</span>, <span class="number">0.1</span>)</div><div class="line">    x, y = meshgrid(x, y)</div><div class="line">    <span class="keyword">print</span> <span class="string">'x.shape:&#123;&#125;'</span>.format(x.shape)</div><div class="line">    <span class="keyword">print</span> <span class="string">'y.shape:&#123;&#125;'</span>.format(y.shape)</div><div class="line">    <span class="comment">#ax.plot(x, y)</span></div><div class="line"></div><div class="line">    plt.contour(x, y,</div><div class="line">                w[<span class="number">0</span>] * (x**<span class="number">2</span>) + w[<span class="number">1</span>] * (y**<span class="number">2</span>) + w[<span class="number">2</span>] * x + w[<span class="number">3</span>] * y + w[<span class="number">4</span>], [<span class="number">0</span>])</div><div class="line">    plt.xlabel(<span class="string">'X1'</span>)</div><div class="line">    plt.ylabel(<span class="string">'X2'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></div><div class="line">    prob = sigmoid(sum(inX * weights))</div><div class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></div><div class="line">    frTrain = open(</div><div class="line">        <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch05\\horseColicTraining.txt'</span>)</div><div class="line">    frTest = open(</div><div class="line">        <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch05\\horseColicTest.txt'</span>)</div><div class="line">    trainingSet = []</div><div class="line">    trainingLabels = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</div><div class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        lineArr = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</div><div class="line">            lineArr.append(float(currLine[i]))</div><div class="line">        trainingSet.append(lineArr)</div><div class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</div><div class="line">    trainWeights = stocGrandAscent1(array(trainingSet), trainingLabels, <span class="number">500</span>)</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    numTestVec = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</div><div class="line">        numTestVec += <span class="number">1.0</span></div><div class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">        lineArr = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</div><div class="line">            lineArr.append(float(currLine[i]))</div><div class="line">        classifyRes = int(classifyVector(array(lineArr), trainWeights))</div><div class="line">        <span class="keyword">if</span> classifyRes != int(currLine[<span class="number">21</span>]):</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">    errorRate = float(errorCount) / numTestVec</div><div class="line">    <span class="keyword">print</span> <span class="string">'the error rate of this test is :&#123;&#125; '</span>.format(errorRate)</div><div class="line">    <span class="keyword">return</span> errorRate</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiTest</span><span class="params">()</span>:</span></div><div class="line">    numTests = <span class="number">10</span></div><div class="line">    errorSum = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</div><div class="line">        errorSum += colicTest()</div><div class="line">    <span class="keyword">print</span> <span class="string">'after &#123;&#125; iterations the average error rate is : &#123;&#125;'</span>.format(numTests, errorSum / float(numTests))</div></pre></td></tr></table></figure>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>5W次迭代<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg97ckh56mj211y0ho74q.jpg" alt=""></p>
<p>随机0 150次<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg97e7y4vyj211y0ho3z7.jpg" alt=""></p>
<p>随机1 150次<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg97eoz4ptj211y0hoq3e.jpg" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/03/朴素贝叶斯分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/03/朴素贝叶斯分类算法/" itemprop="url">朴素贝叶斯分类算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-03T17:03:33+08:00">
                2017-06-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-分类/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><hr>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>贝叶斯定理是关于随机事件 A 和 B 的条件概率：<br><img src="http://upload.wikimedia.org/math/4/6/b/46b680c10ac90b0782843f4bbd0b4a95.png" alt=""><br><a href="http://blog.csdn.net/kesalin/article/details/40370325/" target="_blank" rel="external">概率定义;贝叶斯定义</a>—转自 (<a href="http://kesalin.github.io/" target="_blank" rel="external">http://kesalin.github.io/</a>)</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>根据已有的数据求出某类别下的数据出现的条件概率，运用贝叶斯原理求出在待分类数据条件下属于哪个类别概率最大</strong></p>
<p>这篇文章写得不错:!(<a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html" target="_blank" rel="external">http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html</a>)</p>
<h2 id="p-类别i-A-p-A-类别i-p-类别i-p-A"><a href="#p-类别i-A-p-A-类别i-p-类别i-p-A" class="headerlink" title="p(类别i| A) = p(A|类别i)* p(类别i) / p(A)"></a>p(类别i| A) = p(A|类别i)* p(类别i) / p(A)</h2><ul>
<li>A:待分类数据</li>
<li><em>因为计算每个类别的概率,分母p(A)相同,所以省略</em></li>
<li>p(A|类别i) 通过已有数据计算出</li>
<li>p(类别i) 通过已有数据计算出</li>
</ul>
<p><strong>计算出哪个类别概率大,即把待分类数据标记为哪个类别</strong></p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ul>
<li>构建数据集矩阵和标签列表</li>
<li>训练分类器</li>
<li>将测试数据分类</li>
</ul>
<h3 id="输入"><a href="#输入" class="headerlink" title="输入:"></a>输入:</h3><blockquote>
<p>待分类向量</p>
<p>dataSet向量集合(有签[A,B,C,D,E,F…])  </p>
<p>Label =[A,B,C,D,E,F… ]</p>
</blockquote>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul>
<li>优点: 数据少仍有效，多分类</li>
<li>缺点: 输入数据准备方式敏感</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-05-02</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"><span class="keyword">import</span> feedparser</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></div><div class="line">    fr = open(<span class="string">'sentence'</span>)</div><div class="line">    postingList = [line.strip().split() <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines()]</div><div class="line">    <span class="comment"># 1:humiliation 0:normal</span></div><div class="line">    classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> postingList, classVec</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></div><div class="line">    vocabSet = set([])</div><div class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</div><div class="line">        vocabSet = vocabSet | set(document)</div><div class="line">    <span class="keyword">return</span> list(vocabSet)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 词集模型</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWordsVec</span><span class="params">(vocabList, inputSet)</span>:</span></div><div class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</div><div class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</div><div class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">'the word: &#123;&#125; is not in my Vocabulary!'</span>.format(word)</div><div class="line">    <span class="keyword">return</span> returnVec</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 词袋模型</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList, inputSet)</span>:</span></div><div class="line">    returnVec = [<span class="number">0</span>] * len(vocabList)</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</div><div class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</div><div class="line">            returnVec[vocabList.index(word)] += <span class="number">1</span></div><div class="line">    <span class="comment"># print 'bagOfWords2VecMN:'</span></div><div class="line">    <span class="comment"># print inputSet</span></div><div class="line">    <span class="comment"># print returnVec</span></div><div class="line">    <span class="keyword">return</span> returnVec</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    二分类。</div><div class="line">    计算(正向/负向)句子每个词在(正向/负向)中出现的概率</div><div class="line">    p(ci|w) = p(w|ci)*p(ci) / p(w)</div><div class="line">                |</div><div class="line">                |---&gt;下面代码计算这一块</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></div><div class="line">    numTrainDocs = len(trainMatrix)</div><div class="line">    numWords = len(trainMatrix[<span class="number">0</span>])</div><div class="line">    <span class="comment"># 计算文档属于哪一类的概率 p(ci)</span></div><div class="line">    pAbusive = sum(trainCategory) / float(numTrainDocs)</div><div class="line"></div><div class="line">    <span class="comment"># p0Num中性文档每个词出现的次数,若不出现则为0。以vocabList为基准</span></div><div class="line">    <span class="comment"># p0Num = zeros(numWords)</span></div><div class="line">    <span class="comment"># p1Num = zeros(numWords)</span></div><div class="line">    <span class="comment"># p0Denom = 0.0</span></div><div class="line">    <span class="comment"># p1Denom = 0.0</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        利用贝叶斯分类时，一句话要被分为多个词,来计算概率然后相乘。</div><div class="line">        p(w0|ci)*p(w1|ci)*p(w2|ci)*p(w3|ci) ,如果一个词未出现概率为0.则整体为0</div><div class="line">        解决:所有词出现次数初始化为1,将出现的总次数初始化为2</div><div class="line">    '''</div><div class="line">    p0Num = ones(numWords)</div><div class="line">    p1Num = ones(numWords)</div><div class="line">    p0Denom = <span class="number">2.0</span></div><div class="line">    p1Denom = <span class="number">2.0</span></div><div class="line">    <span class="comment"># print 'numTrainDocs, numWords, pAbusive, p0Denom, p1Denom:'</span></div><div class="line">    <span class="comment"># print numTrainDocs, numWords, pAbusive, p0Denom, p1Denom</span></div><div class="line">    <span class="comment"># print 'p0Num, p1Num:'</span></div><div class="line">    <span class="comment"># print p0Num, p1Num</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</div><div class="line">        <span class="comment"># print 'i:&#123;&#125;'.format(i)</span></div><div class="line">        <span class="comment"># print 'trainMatrix[i]:'</span></div><div class="line">        <span class="comment"># print trainMatrix[i]</span></div><div class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</div><div class="line">            <span class="comment"># 累加每个句子出现的词 到p1Num对应词的位置</span></div><div class="line">            p1Num += trainMatrix[i]</div><div class="line">            <span class="comment"># 累加负向所有出现的词的次数</span></div><div class="line">            p1Denom += sum(trainMatrix[i])</div><div class="line"></div><div class="line">            <span class="comment"># print 'p1Num:&#123;&#125; \n p1Denom:&#123;&#125;'.format(p1Num, p1Denom)</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            p0Num += trainMatrix[i]</div><div class="line">            p0Denom += sum(trainMatrix[i])</div><div class="line">            <span class="comment"># print 'p0Num:&#123;&#125; \n p0Denom:&#123;&#125;'.format(p0Num, p0Denom)</span></div><div class="line"></div><div class="line">    <span class="string">'''</span></div><div class="line">        为了防止出现下溢出:许多小的因子相乘,程序会得不到正确答案</div><div class="line">        解决:用对数函数.</div><div class="line">        好处:1.不会影响函数趋势 2.ln(a*b) = lna + lnb 3.缩小了数据范围</div><div class="line">    '''</div><div class="line">    <span class="comment"># 负向   该词出现的次数/总的词数</span></div><div class="line">    <span class="comment"># p1Vect = p1Num/p1Denom</span></div><div class="line">    p1Vect = log(p1Num / p1Denom)</div><div class="line">    <span class="comment"># 正向   该词出现的次数/总的词数</span></div><div class="line">    <span class="comment"># p0Vect = p0Num/p0Denom</span></div><div class="line">    p0Vect = log(p0Num / p0Denom)</div><div class="line">    <span class="comment"># print p0Vect</span></div><div class="line">    <span class="comment"># print p1Vect</span></div><div class="line">    <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    针对一个句子向量，用朴素贝叶斯分类</div><div class="line">    input: 句子向量, trainNB0 计算出的第一个类每个词出现的概率,</div><div class="line">    第二个类每个词出现的概率, 第一类样本占总体的概率</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        两个向量对应相乘,得到待分类句子每个词出现的概率</div><div class="line">        又因p1Vec,p0Vec的概率经过了log函数</div><div class="line">        所以,原本是P(w1|c1)*p(w2|c1)*...*p(wn|c1)  *  p(c1)</div><div class="line">        转换为: ln(P(w1|c1)) + ln(p(w2|c1)) +... + ln(p(wn|c1)) + ln(p(c1))</div><div class="line">    '''</div><div class="line">    p1 = sum(vec2Classify * p1Vec) + log(pClass1)</div><div class="line">    p0 = sum(vec2Classify * p0Vec) + log(<span class="number">1.0</span> - pClass1)</div><div class="line">    <span class="keyword">if</span> p1 &gt; p0:</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></div><div class="line">    listData, listClasses = loadDataSet()</div><div class="line">    vocabList = createVocabList(listData)</div><div class="line">    trainMat = []</div><div class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> listData:</div><div class="line">        trainMat.append(bagOfWords2VecMN(vocabList, doc))</div><div class="line">    p0V, p1V, pAb = trainNB0(array(trainMat), array(listClasses))</div><div class="line">    <span class="comment"># query = 'love my dalmation'</span></div><div class="line">    query = <span class="string">'garbage'</span></div><div class="line">    testEntry = query.split()</div><div class="line">    testDoc = array(setOfWordsVec(vocabList, testEntry))</div><div class="line">    <span class="keyword">print</span> <span class="string">'&#123;&#125; is classifyed as :&#123;&#125; '</span>.format(query,</div><div class="line">                                            classifyNB(testDoc, p0V, p1V, pAb))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">textParse</span><span class="params">(bigString)</span>:</span></div><div class="line">    returnList = []</div><div class="line">    urls = re.findall(<span class="string">'\(.*?\)'</span>, bigString)</div><div class="line">    query = bigString</div><div class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">        query = query.replace(url, <span class="string">''</span>)</div><div class="line">    listOfTokens = re.split(<span class="string">r'\W*'</span>, query)</div><div class="line">    <span class="comment"># print listOfTokens</span></div><div class="line">    <span class="keyword">for</span> tok <span class="keyword">in</span> listOfTokens:</div><div class="line">        <span class="keyword">if</span> len(tok) &gt; <span class="number">2</span>:</div><div class="line">            returnList.append(tok.lower())</div><div class="line">    <span class="keyword">return</span> returnList</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    测试垃圾邮件分类</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">spamTest</span><span class="params">()</span>:</span></div><div class="line">    docList = []  <span class="comment"># 存储每封邮件分词后的list</span></div><div class="line">    classList = []  <span class="comment"># 存储每个封邮件的label  1 --- harm  0---normal</span></div><div class="line">    fullText = []  <span class="comment"># 存储全部的词,用于做词表</span></div><div class="line"></div><div class="line">    <span class="comment"># load data</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">26</span>):</div><div class="line">        spamFilePath = <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch04\\email\\spam\\&#123;&#125;.txt'</span>.format(</div><div class="line">            i)</div><div class="line">        hamFilePath = <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch04\\email\\ham\\&#123;&#125;.txt'</span>.format(</div><div class="line">            i)</div><div class="line">        <span class="comment"># spam</span></div><div class="line">        wordList = textParse(open(spamFilePath).read())</div><div class="line">        docList.append(wordList)</div><div class="line">        fullText.extend(wordList)</div><div class="line">        classList.append(<span class="number">1</span>)</div><div class="line">        <span class="comment"># ham</span></div><div class="line">        wordList = textParse(open(hamFilePath).read())</div><div class="line">        docList.append(wordList)</div><div class="line">        fullText.extend(wordList)</div><div class="line">        classList.append(<span class="number">0</span>)</div><div class="line">    <span class="comment"># generate vocab list</span></div><div class="line">    vocabList = createVocabList(docList)</div><div class="line">    trainingSet = range(<span class="number">50</span>)</div><div class="line">    testSet = []</div><div class="line">    <span class="comment"># random generate test set</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        randIndex = int(random.uniform(<span class="number">0</span>, len(trainingSet)))</div><div class="line">        testSet.append(trainingSet[randIndex])</div><div class="line">        <span class="keyword">del</span>(trainingSet[randIndex])</div><div class="line">    trainMat = []</div><div class="line">    trainClasses = []</div><div class="line">    <span class="comment"># wordList---&gt;vector save to trainMatrix</span></div><div class="line">    <span class="comment"># label save to trainClasses</span></div><div class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</div><div class="line">        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))</div><div class="line">        trainClasses.append(classList[docIndex])</div><div class="line">    <span class="comment"># 贝叶斯生成每个类别中每个词的概率和负向类别的概率</span></div><div class="line">    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    <span class="comment"># 测试</span></div><div class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</div><div class="line">        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])</div><div class="line">        <span class="keyword">if</span> classifyNB(wordVector, p0V, p1V, pSpam) != classList[docIndex]:</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">            <span class="keyword">print</span> docList[docIndex]</div><div class="line">            <span class="keyword">print</span> <span class="string">'the right label:&#123;&#125;'</span>.format(classList[docIndex])</div><div class="line">    rate = float(errorCount) / len(testSet)</div><div class="line">    <span class="keyword">print</span> <span class="string">'the error rate is :&#123;&#125;'</span>.format(rate)</div><div class="line">    <span class="keyword">return</span> rate</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    计算出现频率最高的30个词</div><div class="line">    返回值: [(word,count),(),()...]</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">caclMostFreq</span><span class="params">(vocabList, fullText)</span>:</span></div><div class="line">    freqDict = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> token <span class="keyword">in</span> vocabList:</div><div class="line">        freqDict[token] = fullText.count(token)</div><div class="line">    sortedFreq = sorted(freqDict.iteritems(), key=operator.itemgetter(<span class="number">1</span>),</div><div class="line">                        reverse=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> sortedFreq[:<span class="number">30</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeStopWords</span><span class="params">(wordList)</span>:</span></div><div class="line">    returnList = []</div><div class="line">    f = open(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\code\\stopWords.txt'</span>, <span class="string">'r'</span>)</div><div class="line">    stopWords = [word.strip() <span class="keyword">for</span> word <span class="keyword">in</span> f.readlines()]</div><div class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> wordList:</div><div class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopWords:</div><div class="line">            returnList.append(word)</div><div class="line">    <span class="keyword">return</span> returnList</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">localWords</span><span class="params">(feed1, feed0)</span>:</span></div><div class="line">    docList = []; classList = []; fullText = []</div><div class="line">    <span class="keyword">print</span> <span class="string">"len(feed1['entries']):&#123;&#125;  len(feed0['entries']):&#123;&#125;"</span>.format(len(feed1[<span class="string">'entries'</span>]), len(feed0[<span class="string">'entries'</span>]))</div><div class="line">    minLen = min(len(feed1[<span class="string">'entries'</span>]), len(feed0[<span class="string">'entries'</span>]))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(minLen):</div><div class="line">        wL = textParse(feed1[<span class="string">'entries'</span>][i][<span class="string">'summary'</span>])</div><div class="line">        wordList = removeStopWords(wL)</div><div class="line">        docList.append(wordList)</div><div class="line">        fullText.extend(wordList)</div><div class="line">        classList.append(<span class="number">1</span>)</div><div class="line"></div><div class="line">        wL = textParse(feed0[<span class="string">'entries'</span>][i][<span class="string">'summary'</span>])</div><div class="line">        wordList = removeStopWords(wL)</div><div class="line">        docList.append(wordList)</div><div class="line">        fullText.extend(wordList)</div><div class="line">        classList.append(<span class="number">0</span>)</div><div class="line">    vocabList = createVocabList(docList)</div><div class="line">    top30Words = caclMostFreq(vocabList, fullText)</div><div class="line">    <span class="keyword">for</span> pairW <span class="keyword">in</span> top30Words:</div><div class="line">        <span class="keyword">if</span> pairW[<span class="number">0</span>] <span class="keyword">in</span> vocabList:</div><div class="line">            vocabList.remove(pairW[<span class="number">0</span>])</div><div class="line">    trainingSet = range(<span class="number">2</span>*minLen); testSet = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</div><div class="line">        randIndex = int(random.uniform(<span class="number">0</span>, len(trainingSet)))</div><div class="line">        testSet.append(trainingSet[randIndex])</div><div class="line">        <span class="keyword">del</span>(trainingSet[randIndex])</div><div class="line">    trainMat = []; trainClasses = []</div><div class="line">    <span class="comment"># wordList---&gt;vector save to trainMatrix</span></div><div class="line">    <span class="comment"># label save to trainClasses</span></div><div class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</div><div class="line">        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))</div><div class="line">        trainClasses.append(classList[docIndex])</div><div class="line">    <span class="comment"># 贝叶斯生成每个类别中每个词的概率和负向类别的概率</span></div><div class="line">    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    <span class="comment"># 测试</span></div><div class="line">    <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</div><div class="line">        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])</div><div class="line">        <span class="keyword">if</span> classifyNB(wordVector, p0V, p1V, pSpam) != classList[docIndex]:</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">            <span class="keyword">print</span> docList[docIndex]</div><div class="line">            <span class="keyword">print</span> <span class="string">'the right label:&#123;&#125;'</span>.format(classList[docIndex])</div><div class="line">    rate = float(errorCount) / len(testSet)</div><div class="line">    <span class="keyword">print</span> <span class="string">'the error rate is :&#123;&#125;'</span>.format(rate)</div><div class="line">    <span class="keyword">return</span> vocabList, p0V, p1V</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTopWords</span><span class="params">(ny, sf)</span>:</span></div><div class="line">    vocabList, p0V, p1V = localWords(ny, sf)</div><div class="line">    topNY = []; topSF = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(p0V)):</div><div class="line">        <span class="keyword">if</span> p0V[i] &gt; <span class="number">-6.0</span>:</div><div class="line">            topSF.append((vocabList[i], p0V[i]))</div><div class="line">        <span class="keyword">if</span> p1V[i] &gt; <span class="number">-6.0</span>:</div><div class="line">            topNY.append((vocabList[i], p1V[i]))</div><div class="line">    sortedSF = sorted(topSF, key=<span class="keyword">lambda</span> pair: pair[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'SF**SF****SF****SF****SF****SF****SF****SF****SF****SF**'</span></div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> sortedSF[:<span class="number">20</span>]:</div><div class="line">        <span class="keyword">print</span> item[<span class="number">0</span>]</div><div class="line">    sortedNY = sorted(topNY, key=<span class="keyword">lambda</span> pair:pair[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY**NY'</span></div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> sortedNY[:<span class="number">20</span>]:</div><div class="line">        <span class="keyword">print</span> item[<span class="number">0</span>]</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/03/决策树分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/03/决策树分类算法/" itemprop="url">决策树分类算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-03T10:40:19+08:00">
                2017-06-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-分类/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><hr>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>对于待构建决策树数据集,选取其中的一个特征为划分条件(基于最大熵原则选取划分特征),来划分数据集.再对划分出的子数据集递归调用构建算法</strong><br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg7uwmsol7j20fl0btdgb.jpg" alt="决策树"></p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><ul>
<li><p>划分数据集的大原则:将无序的数据变得更加有序.</p>
</li>
<li><p>信息量:I[x] = log[1/P(x)] = -logP(x)</p>
</li>
<li><p>熵定义:<br><img src="http://img.blog.csdn.net/20140528165140328" alt=""></p>
</li>
<li>熵的特性</li>
</ul>
<blockquote>
<ul>
<li>熵均大于等于零，即，H_s &gt;= 0。</li>
<li>设N是系统S内的事件总数，则熵H_s&lt;= log2(N)。当且仅当p1=p2=…=pn时，等号成立，此时系统S的熵最大。</li>
</ul>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fg83t9ulx1j20kl0a70t3.jpg" alt=""></p>
<p><strong>信息增益:</strong> <em>在划分数据集之前之后信息发生的变化称为信息增益</em></p>
<blockquote>
<ul>
<li>原数据集熵-划分后数据集熵</li>
</ul>
</blockquote>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="输入"><a href="#输入" class="headerlink" title="输入:"></a>输入:</h3><blockquote>
<p>dataSet向量集合(有签[A,B,C,D,E,F…])  </p>
<p>Label =[A,B,C,D,E,F… ]</p>
</blockquote>
<h3 id="目的："><a href="#目的：" class="headerlink" title="目的："></a>目的：</h3><blockquote>
<p>将数据集构建决策树</p>
</blockquote>
<h3 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h3><ul>
<li>1.判断是否所有类别标签完全相同,是,则返回该标签</li>
<li>2.判断是否所有特征都使用完了,只剩下标签,是,则返回标签投票结果</li>
<li>3.选择一个最佳划分的特征序号bestFeat,和该序号对应的特征值bestFeatLabel</li>
<li>4.建立一个dict{bestFeatLabel:{}},把bestFeatLabel从特征列表中删除</li>
<li>5.求出bestFeatLabel所有可能的取值uniqueVals</li>
<li>6.对uniqueVals的每个值,以它为bestFeatLabel的值,划分为数据集subDataSet,<br>  递归调用创建决策树(subDataSet, 特征列表)<br>  赋值给dict{bestFeatLabel[uniqueVals该值]}</li>
<li>7.返回dict</li>
</ul>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul>
<li>优点: 计算复杂度不高、输出结果易于理解，对中间值缺失不敏感</li>
<li>缺点: 可能会产生过度匹配问题</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-05-02</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></div><div class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</div><div class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</div><div class="line">               [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</div><div class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</div><div class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</div><div class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</div><div class="line">    <span class="comment"># change to discrete values</span></div><div class="line">    <span class="keyword">return</span> dataSet, labels</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    决策树分类(已创建的决策树, 特征列表, 待分类的向量)</div><div class="line"></div><div class="line">    已创建的决策树形如:</div><div class="line"></div><div class="line">            no surfacing</div><div class="line">            /           \</div><div class="line">           0             1</div><div class="line">          /               \</div><div class="line">         no              flippers</div><div class="line">                        /        \</div><div class="line">                       0          1</div><div class="line">                      /            \</div><div class="line">                     no             yes</div><div class="line">    1.得到树的第一个节点的特征列表的序号,和第一个特征对应的dict</div><div class="line">    2.循环dict的key,判断是否与待分类对应的特征值相同.</div><div class="line">    3.若相同,则进一步判断key对应的value是不是dict. 如果是dict 则递归再进入分类算法,返回一个分类标签</div><div class="line">    4.如果不是dict,则直接返回分类标签</div><div class="line">    5.最后返回分类标签</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree, featLabels, testVec)</span>:</span></div><div class="line">    firstStr = inputTree.keys()[<span class="number">0</span>]</div><div class="line">    <span class="keyword">print</span> <span class="string">'firstStr:&#123;&#125;'</span>.format(firstStr)</div><div class="line">    secondDict = inputTree[firstStr]</div><div class="line">    featIndex = featLabels.index(firstStr)</div><div class="line">    <span class="keyword">print</span> <span class="string">'featIndex:&#123;&#125;'</span>.format(featIndex)</div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</div><div class="line">        <span class="keyword">print</span> <span class="string">'key:&#123;&#125;'</span>.format(key)</div><div class="line">        <span class="keyword">if</span> testVec[featIndex] == key:</div><div class="line">            <span class="keyword">print</span> <span class="string">'testVec[featIndex] == key'</span></div><div class="line">            <span class="keyword">if</span> type(secondDict[key]).__name__ == <span class="string">'dict'</span>:</div><div class="line">                classLabel = classify(secondDict[key], featLabels, testVec)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                classLabel = secondDict[key]</div><div class="line">    <span class="keyword">return</span> classLabel</div><div class="line"></div><div class="line"><span class="comment"># 计算信息熵</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></div><div class="line">    numEntries = len(dataSet)</div><div class="line">    labelCounts = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</div><div class="line">        currentLabel = featVec[<span class="number">-1</span>]</div><div class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</div><div class="line">            labelCounts[currentLabel] = <span class="number">0</span></div><div class="line">        labelCounts[currentLabel] += <span class="number">1</span></div><div class="line">    shannonEnt = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</div><div class="line">        prob = float(labelCounts[key]) / numEntries</div><div class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</div><div class="line">    <span class="keyword">return</span> shannonEnt</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 分割数据集</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></div><div class="line">    retDataSet = []</div><div class="line">    <span class="keyword">for</span> feacVec <span class="keyword">in</span> dataSet:</div><div class="line">        <span class="keyword">if</span> feacVec[axis] == value:</div><div class="line">            reducedFeatVec = feacVec[:axis]</div><div class="line">            reducedFeatVec.extend(feacVec[axis + <span class="number">1</span>:])</div><div class="line">            retDataSet.append(reducedFeatVec)</div><div class="line">    <span class="keyword">return</span> retDataSet</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 选一个特征,以此特征划分数据集，H=sum(每个区间概率*子区间熵) 选H最小的</span></div><div class="line"><span class="comment"># 也就是 信息增益=原数据集的熵-该特征的H  选信息增益最大的</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'enter chooseBestFeatureToSplit------------------------------'</span></div><div class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span></div><div class="line">    baseEntropy = calcShannonEnt(dataSet)</div><div class="line">    bestInfoGain = <span class="number">0.0</span></div><div class="line">    bestFeature = <span class="number">-1</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</div><div class="line">        <span class="comment"># print 'i:&#123;&#125;'.format(i)</span></div><div class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">        uniqueVals = set(featList)</div><div class="line">        <span class="comment"># print 'uniqueVals:&#123;&#125;'.format(uniqueVals)</span></div><div class="line">        newEntropy = <span class="number">0.0</span></div><div class="line">        <span class="comment"># print 'calc newEntropy:'</span></div><div class="line">        <span class="string">'''</span></div><div class="line">            若选取第一个特征作为划分</div><div class="line">            所有情况都在uniqueVals里面</div><div class="line">            遍历所有情况:</div><div class="line">            for value in uniqueVals:</div><div class="line">                当第一个特征为value时，划分的数据集为subDataSet</div><div class="line">                h(value)这种情况的熵= p * H(subDataSet)</div><div class="line">                              subDataSet占全数据集的概率 * subDataSet的熵</div><div class="line">            选取这个特征划分总的熵为:</div><div class="line">                H = h(value1) + h(value2)+ ...</div><div class="line">            选取这个特征划分的信息增益:</div><div class="line">                原数据集熵 - H</div><div class="line">        '''</div><div class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">            <span class="comment"># print 'value:&#123;&#125;'.format(value)</span></div><div class="line">            subDataSet = splitDataSet(dataSet, i, value)</div><div class="line">            <span class="comment"># print 'subDataSet&#123;&#125;'.format(subDataSet)</span></div><div class="line">            prob = len(subDataSet) / float(len(dataSet))</div><div class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</div><div class="line">            <span class="comment"># print 'prob:&#123;&#125; ShannonEnt:&#123;&#125;'.format(prob, calcShannonEnt(subDataSet))</span></div><div class="line">            <span class="comment"># print 'newEntropy:&#123;&#125;'.format(newEntropy)</span></div><div class="line">        infoGain = baseEntropy - newEntropy</div><div class="line">        <span class="comment"># print 'infoGain:&#123;&#125;'.format(infoGain)</span></div><div class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</div><div class="line">            bestInfoGain = infoGain</div><div class="line">            bestFeature = i</div><div class="line">    <span class="keyword">print</span> <span class="string">'end chooseBestFeatureToSplit------------------------------'</span></div><div class="line">    <span class="keyword">return</span> bestFeature</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classlist)</span>:</span></div><div class="line">    classCount = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classlist:</div><div class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount:</div><div class="line">            classCount[vote] = <span class="number">0</span></div><div class="line">        classCount[vote] += <span class="number">1</span></div><div class="line">    sortedClassCount = sorted(classCount.items(),</div><div class="line">                              key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line"></div><div class="line">cnt = <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    创建决策树，参数(数据集,特征列表)</div><div class="line">        1.判断是否所有类别标签完全相同,是,则返回该标签</div><div class="line">        2.判断是否所有特征都使用完了,只剩下标签,是,则返回标签投票结果</div><div class="line">        3.选择一个最佳划分的特征序号bestFeat,和该序号对应的特征值bestFeatLabel</div><div class="line">        4.建立一个dict&#123;bestFeatLabel:&#123;&#125;&#125;,把bestFeatLabel从特征列表中删除</div><div class="line">        5.求出bestFeatLabel所有可能的取值uniqueVals</div><div class="line">        6.对uniqueVals的每个值,以它为bestFeatLabel的值,划分为数据集subDataSet,</div><div class="line">            递归调用创建决策树(subDataSet, 特征列表) 赋值给dict&#123;bestFeatLabel[uniqueVals该值]&#125;</div><div class="line">        7.返回dict</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></div><div class="line">    <span class="keyword">global</span> cnt</div><div class="line">    cnt += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'cnt:&#123;&#125;'</span>.format(cnt)</div><div class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    <span class="comment"># 所有类别标签完全相同,停止继续划分</span></div><div class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</div><div class="line">        <span class="keyword">print</span> <span class="string">'     classList.count(classList[0]) == len(classList) return'</span></div><div class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</div><div class="line">    <span class="comment"># 所有特征都使用完了，只剩下标签了，仍不能把数据划分成只有一个标签的分组</span></div><div class="line">    <span class="comment"># 返回一个出现最多的标签</span></div><div class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">'     len(dataSet[0]) == 1 return'</span></div><div class="line">        <span class="keyword">return</span> majorityCnt(classList)</div><div class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</div><div class="line">    bestFeatLabel = labels[bestFeat]</div><div class="line">    <span class="keyword">print</span> <span class="string">'     the bestFeat:&#123;&#125; bestFeatLabel:&#123;&#125; '</span>.format(bestFeat, bestFeatLabel)</div><div class="line">    myTree = &#123;bestFeatLabel: &#123;&#125;&#125;</div><div class="line">    <span class="keyword">del</span>(labels[bestFeat])</div><div class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</div><div class="line">    uniqueVals = set(featValues)</div><div class="line">    <span class="keyword">print</span> <span class="string">'     uniqueVals:&#123;&#125;'</span>.format(uniqueVals)</div><div class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</div><div class="line">        subLabels = labels[:]</div><div class="line">        <span class="keyword">print</span> <span class="string">'     value:&#123;&#125;  对每个value递归调用createTree'</span>.format(value)</div><div class="line">        subDataSet = splitDataSet(dataSet, bestFeat, value)</div><div class="line">        <span class="keyword">print</span> <span class="string">'     subDataSet:&#123;&#125;'</span>.format(subDataSet)</div><div class="line">        myTree[bestFeatLabel][value] = createTree(</div><div class="line">            splitDataSet(dataSet, bestFeat, value), subLabels)</div><div class="line">    <span class="keyword">return</span> myTree</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree, filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    fw = open(filename, <span class="string">'w'</span>)</div><div class="line">    pickle.dump(inputTree, fw)</div><div class="line">    fw.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span>:</span></div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">return</span> pickle.load(fr)</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/03/KNN分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/06/03/KNN分类算法/" itemprop="url">KNN分类算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-03T10:00:20+08:00">
                2017-06-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><hr>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><strong>对于无标签的待分类数据,通过计算和带标签的数据集的相似度,选出前K个最相似的数据.把这K个数据中出现次数最多的分类作为待分类数据的类别返回.</strong></p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="输入"><a href="#输入" class="headerlink" title="输入:"></a>输入:</h3><blockquote>
<p>dataSet向量集合(有签[A,B,C,D,E,F…])  </p>
<p>Label =[A,B,C,D,E,F… ]</p>
<p>X待分类向量</p>
<p>K值</p>
</blockquote>
<h3 id="目的："><a href="#目的：" class="headerlink" title="目的："></a>目的：</h3><blockquote>
<p>将X分类到某个类别[A,B,C,..]</p>
</blockquote>
<h3 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h3><ul>
<li>1、计算X到dataSet每个向量的距离-&gt;distances(欧式距离)</li>
<li>2、distances按照升序排列，得到一个index List</li>
<li>3、取前K个index List的值作为序号，拿到Label对应序号的标签。存入一个dict中<label,count></label,count></li>
<li>4、对dict按照count降序排列，输出第一个的label。（即：距离X最近的K个向量的标签中，出现最多的那个标签）</li>
</ul>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul>
<li>优点: 精度高、对异常值不敏感、无输入数据假定</li>
<li>缺点: 计算复杂度高、空间复杂度高</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-05-02</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></div><div class="line">    group = array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</div><div class="line">    label = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</div><div class="line">    <span class="keyword">return</span> group, label</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify0</span><span class="params">(inX, dataSet, labels, k)</span>:</span></div><div class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</div><div class="line">    diffMat = tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet</div><div class="line">    sqDiffMat = diffMat**<span class="number">2</span></div><div class="line">    sqDistances = sqDiffMat.sum(axis=<span class="number">1</span>)</div><div class="line">    distances = sqDistances**<span class="number">0.5</span></div><div class="line">    sortedDistIndicies = distances.argsort()</div><div class="line">    classCount = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</div><div class="line">        voteIlabel = labels[sortedDistIndicies[i]]</div><div class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></div><div class="line">    sortedClassCount = sorted(classCount.iteritems(),</div><div class="line">                              key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">file2matrix</span><span class="params">(filename)</span>:</span></div><div class="line">    fr = open(filename)</div><div class="line">    numberOfLines = len(fr.readlines())  <span class="comment"># get the number of lines in the file</span></div><div class="line">    returnMat = zeros((numberOfLines, <span class="number">3</span>))  <span class="comment"># prepare matrix to return</span></div><div class="line">    classLabelVector = []  <span class="comment"># prepare labels return</span></div><div class="line">    fr = open(filename)</div><div class="line">    index = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</div><div class="line">        line = line.strip()</div><div class="line">        listFromLine = line.split(<span class="string">'\t'</span>)</div><div class="line">        returnMat[index, :] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</div><div class="line">        classLabelVector.append(int(listFromLine[<span class="number">-1</span>]))</div><div class="line">        index += <span class="number">1</span></div><div class="line">    <span class="keyword">return</span> returnMat, classLabelVector</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">autoNorm</span><span class="params">(dataSet)</span>:</span></div><div class="line">    minVals = dataSet.min(<span class="number">0</span>)</div><div class="line">    maxVals = dataSet.max(<span class="number">0</span>)</div><div class="line">    ranges = maxVals - minVals</div><div class="line">    <span class="keyword">print</span> <span class="string">'minVals:&#123;&#125;'</span>.format(minVals)</div><div class="line">    <span class="keyword">print</span> <span class="string">'maxVals:&#123;&#125;'</span>.format(maxVals)</div><div class="line">    <span class="keyword">print</span> <span class="string">'ranges:&#123;&#125;'</span>.format(ranges)</div><div class="line">    normDataSet = zeros(shape(dataSet))</div><div class="line">    m = dataSet.shape[<span class="number">0</span>]</div><div class="line">    normDataSet = dataSet - tile(minVals, (m, <span class="number">1</span>))</div><div class="line">    normDataSet = normDataSet / tile(ranges, (m, <span class="number">1</span>))  <span class="comment"># element wise divide</span></div><div class="line">    <span class="keyword">return</span> normDataSet, ranges, minVals</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">datingClassTest</span><span class="params">()</span>:</span></div><div class="line">    hoRatio = <span class="number">0.10</span></div><div class="line">    datingDataMat, datingLabels = file2matrix(</div><div class="line">        <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\datingTestSet2.txt'</span>)</div><div class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</div><div class="line">    m = normMat.shape[<span class="number">0</span>]</div><div class="line">    numTestVecs = int(m * hoRatio)</div><div class="line">    errorCount = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numTestVecs):</div><div class="line">        classiferResult = classify0(normMat[i, :], normMat[numTestVecs:m, :],</div><div class="line">                                    datingLabels[numTestVecs:m], <span class="number">3</span>)</div><div class="line">        <span class="keyword">print</span> <span class="string">'the classifer came back with: &#123;&#125;, the real answer is: &#123;&#125;'</span>\</div><div class="line">            .format(classiferResult, datingLabels[i])</div><div class="line">        <span class="keyword">if</span> classiferResult != datingLabels[i]:</div><div class="line">            errorCount += <span class="number">1.0</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the total error reate is : &#123;&#125;'</span>\</div><div class="line">        .format(errorCount / float(numTestVecs))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyPerson</span><span class="params">()</span>:</span></div><div class="line">    resultList = [<span class="string">'not at all'</span>, <span class="string">'in small doses'</span>, <span class="string">'in large doses'</span>]</div><div class="line">    percentTats = float(raw_input(</div><div class="line">        <span class="string">"perentange of time spend playing video games?"</span>))</div><div class="line">    ffMiles = float(raw_input(<span class="string">"frequent flier miles earned per year?"</span>))</div><div class="line">    iceCream = float(raw_input(<span class="string">"liters of ice cream consumed per year?"</span>))</div><div class="line">    datingDataMat, datingLabels = file2matrix(</div><div class="line">        <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\datingTestSet2.txt'</span>)</div><div class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</div><div class="line">    inArr = array([ffMiles, percentTats, iceCream])</div><div class="line">    classiferResult = classify0(</div><div class="line">        (inArr - minVals) / ranges, normMat, datingLabels, <span class="number">3</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'you will probably like this person : &#123;&#125;'</span>\</div><div class="line">        .format(resultList[classiferResult - <span class="number">1</span>])</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(filename)</span>:</span></div><div class="line">    returnVect = zeros((<span class="number">1</span>, <span class="number">1024</span>))</div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">        line = fr.readline()</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">            returnVect[<span class="number">0</span>, <span class="number">32</span> * i + j] = int(line[j])</div><div class="line">    <span class="keyword">return</span> returnVect</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handwritingClassTest</span><span class="params">()</span>:</span></div><div class="line">    trainingDir = <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\trainingDigits'</span></div><div class="line">    testDir = <span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\testDigits'</span></div><div class="line">    hwLabels = []</div><div class="line">    trainingFileList = listdir(trainingDir)</div><div class="line">    m = len(trainingFileList)</div><div class="line">    trainingMat = zeros((m, <span class="number">1024</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        fileNameStr = trainingFileList[i]</div><div class="line">        fileStr = fileNameStr.split(<span class="string">'.'</span>)[<span class="number">0</span>]</div><div class="line">        classNumStr = int(fileStr.split(<span class="string">'_'</span>)[<span class="number">0</span>])</div><div class="line">        hwLabels.append(classNumStr)</div><div class="line">        trainingMat[i, :] = img2vector(</div><div class="line">            <span class="string">'&#123;&#125;\\&#123;&#125;'</span>.format(trainingDir, fileNameStr))</div><div class="line">    testFileList = listdir(testDir)</div><div class="line">    errorCount = <span class="number">0.0</span></div><div class="line">    mTest = len(testFileList)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(mTest):</div><div class="line">        fileNameStr = testFileList[i]</div><div class="line">        fileStr = fileNameStr.split(<span class="string">'.'</span>)[<span class="number">0</span>]</div><div class="line">        classNumStr = int(fileStr.split(<span class="string">'_'</span>)[<span class="number">0</span>])</div><div class="line">        vectorUnderTest = img2vector(<span class="string">'&#123;&#125;\\&#123;&#125;'</span>.format(testDir, fileNameStr))</div><div class="line">        classifierResult = classify0(vectorUnderTest,</div><div class="line">                                     trainingMat, hwLabels, <span class="number">3</span>)</div><div class="line">        <span class="keyword">print</span> <span class="string">'the classifier came back with: &#123;&#125;, the real answer is :&#123;&#125;'</span> \</div><div class="line">            .format(classifierResult, classNumStr)</div><div class="line">        <span class="keyword">if</span> classifierResult != classNumStr :</div><div class="line">            errorCount += <span class="number">1.0</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the total number of eror is :&#123;&#125;'</span>.format(errorCount)</div><div class="line">    <span class="keyword">print</span> <span class="string">'the total number of test is :&#123;&#125;'</span>.format(mTest)</div><div class="line">    <span class="keyword">print</span> <span class="string">'the total error rate is :&#123;&#125;'</span>.format(errorCount/float(mTest))</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Williams-Hao" />
          <p class="site-author-name" itemprop="name">Williams-Hao</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Williams-Hao</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  

</body>
</html>

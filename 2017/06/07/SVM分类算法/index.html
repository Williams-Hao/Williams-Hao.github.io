<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="分类,SVM," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="定义使距离分隔超平面最近的异类样本点的距离最大 原理对于数据集  D = {(x1,y1),(x2,y2),…(xn,yn)} y=[-1,+1]xi = (x1,x2,x3,…xm)  有一个超平面把不同类别的数据分开  超平面:w.T  x + b = 0 *w = (w1,w2, … ,w3)为法向量,决定超平面方向.b为位移项,决定超平面与远点距离   上述问题等价于min{ 1/2  |">
<meta name="keywords" content="分类,SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM分类算法">
<meta property="og:url" content="https://williams-hao.github.io/2017/06/07/SVM分类算法/index.html">
<meta property="og:site_name" content="所有的伟大,源于一个勇敢的开始">
<meta property="og:description" content="定义使距离分隔超平面最近的异类样本点的距离最大 原理对于数据集  D = {(x1,y1),(x2,y2),…(xn,yn)} y=[-1,+1]xi = (x1,x2,x3,…xm)  有一个超平面把不同类别的数据分开  超平面:w.T  x + b = 0 *w = (w1,w2, … ,w3)为法向量,决定超平面方向.b为位移项,决定超平面与远点距离   上述问题等价于min{ 1/2  |">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fgll1q3l6lj22c0340u0x.jpg">
<meta property="og:image" content="http://images2015.cnblogs.com/blog/731104/201606/731104-20160601161233696-300846876.png">
<meta property="og:image" content="http://my.csdn.net/uploads/201206/02/1338605996_4659.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fglouk6i4kj22c0340x6p.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fglpn5dtdsj22c03404qq.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fglpo09568j22c03407wi.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fglpnnmoouj22c03401ky.jpg">
<meta property="og:image" content="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131534858.png">
<meta property="og:updated_time" content="2017-06-15T04:01:50.522Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVM分类算法">
<meta name="twitter:description" content="定义使距离分隔超平面最近的异类样本点的距离最大 原理对于数据集  D = {(x1,y1),(x2,y2),…(xn,yn)} y=[-1,+1]xi = (x1,x2,x3,…xm)  有一个超平面把不同类别的数据分开  超平面:w.T  x + b = 0 *w = (w1,w2, … ,w3)为法向量,决定超平面方向.b为位移项,决定超平面与远点距离   上述问题等价于min{ 1/2  |">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/75544e9fly1fgll1q3l6lj22c0340u0x.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://williams-hao.github.io/2017/06/07/SVM分类算法/"/>





  <title>SVM分类算法 | 所有的伟大,源于一个勇敢的开始</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">所有的伟大,源于一个勇敢的开始</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">所有的伟大,源于一个勇敢的开始</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://williams-hao.github.io/2017/06/07/SVM分类算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Williams-Hao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="所有的伟大,源于一个勇敢的开始">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">SVM分类算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-07T11:01:02+08:00">
                2017-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-分类/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习-分类</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p><strong>使距离分隔超平面最近的异类样本点的距离最大</strong></p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p><em>对于数据集</em></p>
<blockquote>
<p>D = {(x1,y1),(x2,y2),…(xn,yn)} y=[-1,+1]<br>xi = (x1,x2,x3,…xm)</p>
</blockquote>
<p><em>有一个超平面把不同类别的数据分开</em></p>
<blockquote>
<p><em>超平面:w.T </em> x + b = 0</p>
<p>*w = (w1,w2, … ,w3)为法向量,决定超平面方向.<br>b为位移项,决定超平面与远点距离</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fgll1q3l6lj22c0340u0x.jpg" alt=""></p>
<p>上述问题等价于<br><strong>min{ 1/2 <em> ||w||二次方}  s.t. yi(w.T </em> xi + b)&gt;=1 i=1,2,3…m</strong></p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>(范数这段摘自:<a href="http://blog.csdn.net/zouxy09/article/details/24971995/" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/24971995/</a>)</p>
<h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><blockquote>
<ul>
<li>L0范数：<strong>是指向量中非0的元素的个数</strong></li>
<li>L1范数：<strong>是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）</strong></li>
<li>L2范数：<strong>是指向量各元素的平方和然后求平方根</strong></li>
</ul>
</blockquote>
<p><strong>L0范数、L1范数倾向于w的分量尽量稀疏,即非零分量个数尽量少</strong><br><strong>L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</strong><br><strong>L2范数倾向于w的分量取值尽量均衡,即非零分量个数尽量稠密</strong></p>
<h3 id="参数稀疏的好处"><a href="#参数稀疏的好处" class="headerlink" title="参数稀疏的好处"></a>参数稀疏的好处</h3><h4 id="1）特征选择-Feature-Selection-："><a href="#1）特征选择-Feature-Selection-：" class="headerlink" title="1）特征选择(Feature Selection)："></a>1）特征选择(Feature Selection)：</h4><blockquote>
<ul>
<li>大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。</li>
</ul>
</blockquote>
<h4 id="2）可解释性-Interpretability-："><a href="#2）可解释性-Interpretability-：" class="headerlink" title="2）可解释性(Interpretability)："></a>2）可解释性(Interpretability)：</h4><blockquote>
<ul>
<li>另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1<em>x1+w2</em>x2+…+w1000<em>x1000+b（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w</em>就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。</li>
</ul>
</blockquote>
<p>L2范数因为它的强大功效是改善机器学习里面一个非常重要的问题：<strong>过拟合</strong></p>
<pre><code>过拟合是什么，上面也解释了，就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。通俗的讲就是应试能力很强，实际应用能力很差。擅长背诵知识，却不懂得灵活利用知识。
</code></pre><p><strong>为什么L2范数可以防止过拟合？</strong>。<br>L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。</p>
<pre><code>这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。
</code></pre><p><strong>上面问题的等价转换用到了L2范数</strong></p>
<h2 id="拉格朗日乘子法转化问题"><a href="#拉格朗日乘子法转化问题" class="headerlink" title="拉格朗日乘子法转化问题"></a>拉格朗日乘子法转化问题</h2><blockquote>
<ul>
<li>原问题：<strong>min 1/2 <em> ||w||二次方 s.t. yi(w.T </em> xi + b)&gt;=1 i=1,2,3…m</strong></li>
</ul>
</blockquote>
<p>构造拉格朗日函数:<br><img src="http://images2015.cnblogs.com/blog/731104/201606/731104-20160601161233696-300846876.png" alt=""></p>
<blockquote>
<ul>
<li>L(w,b,alpha) = <strong>1/2 <em> ||w||二次方 + sigma{alpha[i] </em> (1-yi(w.T * x+b))}  s.t. alpha[i]&gt;=0</strong></li>
</ul>
</blockquote>
<p>由前面的约束得到:<strong>(1-yi(w.T * x+b)&lt;=0</strong><br>当alpha[i] &gt;= 0 (1-yi(w.T <em> x+b)&lt;=0 都满足时:<br>**max L = 1/2 </em> ||w||二次方<strong><br>令theta(w) = max L(w,b,alpha) = 1/2 * ||w||二次方
</strong>min 1/2 <em> ||w||二次方 = min  max L(w,b,alpha) = p<strong>
</strong>max min L(w,b,alpha) = d<strong><br>则:d&lt;=p
</strong>这里交换了min、max的顺序.即最大值中的最小的也比最小值中的最大的大*</em><br>当满足KKT条件时 d=p<br>KKT条件详解:<a href="http://blog.csdn.net/on2way/article/details/47729419" target="_blank" rel="external">http://blog.csdn.net/on2way/article/details/47729419</a></p>
<p>L对w,b分别求偏导然后置0,得到:</p>
<blockquote>
<ul>
<li>w = sigma{alpha[i] <em> yi </em> xi}</li>
<li>0 = sigma{alpha[i] * yi}</li>
</ul>
</blockquote>
<p>两式带入L得原问题的对偶问题:<br><img src="http://my.csdn.net/uploads/201206/02/1338605996_4659.jpg" alt=""></p>
<h2 id="模型预测"><a href="#模型预测" class="headerlink" title="模型预测:"></a>模型预测:</h2><p>f(x) = w.T <em> x + b<br>带入w<br>f(x) = sum(alpha[i] </em> yi <em> (x </em> x[i].T)) + b<br><code>由下面算法求解alpha后就可以求某点的预测值</code><br>对于待分类数据x,只要计算f = sum(alpha[i] <em> yi </em> (x * x[i].T)) + b<br>f &gt; 0 +1类<br>f &lt; 0 -1类</p>
<h2 id="SMO算法求解问题"><a href="#SMO算法求解问题" class="headerlink" title="SMO算法求解问题:"></a>SMO算法求解问题:</h2><ul>
<li><p>[X]1.固定一个alpha[i]参数,如果alpha[i]违反了KKT条件则进入下一步,否则重新选择i</p>
</li>
<li><p>[X]2.在alpha中选择一个有效的(因为初始时alpha全置0)、不等于i的、预测值与实际值差距最大的alpha[j]</p>
</li>
<li><p>[X]3.根据KKT条件以及alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z 确定alpha[j]的上下界[L,H]</p>
<blockquote>
<ul>
<li>原问题得到的拉格朗日对偶问题约束条件sum(alphai <em> yi) = 0<br>仅考虑alpha[i],alpha[j]时,约束重写为:<br>alpha[i] </em> yi + alpha[j] <em> yj = z<br>(alpha[i]&gt;=0 alpha[j]&gt;=0  z=-sum(alpha[k]yk) k!=i,j)<br>则更新前后的alpha满足:<br>alphaInew</em>yi + alphaJnew<em>yj = alphaIold</em>yi + alphaJold<em>yj = z<br>yi和yj不是+1就是-1<br>讨论yi=yj 和yi!=yj的两种情况,得到alphaJnew的上下界<br><em>*详见：<a href="http://blog.csdn.net/on2way/article/details/47730367" target="_blank" rel="external">http://blog.csdn.net/on2way/article/details/47730367</a></em></em></li>
</ul>
</blockquote>
</li>
<li><p>[X]4.更新alpha[j]</p>
<blockquote>
<ul>
<li>更新alphas[j]解来源:<br> 1.把拉格朗日对偶问题有alpha[i],alpha[j]单一式独展开的(一式)<br> 2.由于有alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z<br> 可以把alpha[i]消掉,带入一式,(得到二式)<br> 3.二式对alpha[j]求导等于0<br> 4.得到alpha[j]和alphaJold关系<br> <strong>推导详见:</strong><pre><code>http://blog.csdn.net/on2way/article/details/47730367
http://blog.csdn.net/v_july_v/article/details/7624837
</code></pre></li>
</ul>
</blockquote>
</li>
<li><p>[X]5.调整alpha[j]大小到[L,H]</p>
</li>
<li><p>[X]6.更新alpha[i]</p>
<blockquote>
<ul>
<li>由约束:alphaInew<em>yi + alphaJnew</em>yj = alphaIold<em>yi + alphaJold</em>yj = z<br>  以及:yi<em>yi = 1 yj</em>yj = 1<br>  得：<br>  alphaInew<em>yi = alphaIold</em>yi + yj(alphaJold-alphaJnew)<br>  alphaInew = alphaIold + yi*yj(alphaJold-alphaJnew)</li>
</ul>
</blockquote>
</li>
<li><p>[X]7.更新b<br><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglouk6i4kj22c0340x6p.jpg" alt=""></p>
</li>
</ul>
<p><strong>直到某次循环没有一个alpha更新或者循环次数达到则完成。</strong></p>
<h2 id="非线性数据分类"><a href="#非线性数据分类" class="headerlink" title="非线性数据分类"></a>非线性数据分类</h2><p><code>引入核函数</code><br><strong>目的:将样本从原始空间映射到一个更高维的特征空间,是的样本在这个特征空间内线性可分.</strong></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpn5dtdsj22c03404qq.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpo09568j22c03407wi.jpg" alt=""></p>
<p><img src="http://ww1.sinaimg.cn/large/75544e9fly1fglpnnmoouj22c03401ky.jpg" alt=""></p>
<h2 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h2><blockquote>
<ul>
<li>之前的都是所有样本必须划分正确—“硬间隔”</li>
<li>允许某些样本不满足约束 yi(w.T <em> x + b) &gt;= 1 —“软间隔”<br>  即:某些样本与分隔超平面的距离小于 |w.T </em> x + b|/||w||<br>  在wx+b=+1 和wx+b=-1之间</li>
</ul>
</blockquote>
<p><code>hinge损失函数:l(z) = max(0,1-z)</code></p>
<blockquote>
<ul>
<li>优化目标可写为：<strong>min{ 1/2 <em> ||w||二次方 + C</em>sigma max(0, yi(w.T * x + b))}</strong></li>
</ul>
</blockquote>
<p><strong>松弛变量(slack variables):它对应数据点允许偏离的functional margin量</strong></p>
<p>函数间隔:<br><img src="http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103131131534858.png" alt=""></p>
<p>详见:<br><a href="http://blog.csdn.net/shenziheng1/article/details/53884071" target="_blank" rel="external">http://blog.csdn.net/shenziheng1/article/details/53884071</a></p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf8 -*-</span></div><div class="line"><span class="string">'''</span></div><div class="line">created at 2017-06-05</div><div class="line">author:Hao Jiawei</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</div><div class="line"><span class="comment">#import numpy as np</span></div><div class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</div><div class="line"><span class="keyword">import</span> operator</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName=<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSet.txt'</span>)</span>:</span></div><div class="line">    dataMat = [] ; labelMat = []</div><div class="line">    <span class="keyword">with</span> open(fileName) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</div><div class="line">            lineArr = line.strip().split(<span class="string">'\t'</span>)</div><div class="line">            dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</div><div class="line">            labelMat.append(float(lineArr[<span class="number">2</span>]))</div><div class="line">    <span class="keyword">return</span> dataMat, labelMat</div><div class="line"></div><div class="line"><span class="comment"># 在某一范围随机选择一个不同于指定数字的数</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i, m)</span>:</span></div><div class="line">    j = i</div><div class="line">    <span class="keyword">while</span> j == i:</div><div class="line">        j = int(random.uniform(<span class="number">0</span>, m))</div><div class="line">    <span class="keyword">return</span> j</div><div class="line"></div><div class="line"><span class="comment"># 调整数值在一个范围内</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipApha</span><span class="params">(aj, H, L)</span>:</span></div><div class="line">    <span class="keyword">if</span> aj &gt; H:</div><div class="line">        aj = H</div><div class="line">    <span class="keyword">if</span> L &gt; aj:</div><div class="line">        aj = L</div><div class="line">    <span class="keyword">return</span> aj</div><div class="line"></div><div class="line"><span class="comment"># 简化版SMO算法</span></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    params:数据集 类别标签 常数C 容错率 推出前最大循环次数</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoSimple</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span>:</span></div><div class="line">    dataMatrix = mat(dataMatIn)</div><div class="line">    labelMat = mat(classLabels).transpose()</div><div class="line">    b = <span class="number">0</span></div><div class="line">    m, n = shape(dataMatrix)</div><div class="line">    alphas = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    iter = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> iter &lt; maxIter:</div><div class="line">        alphaPairsChanged = <span class="number">0</span>  <span class="comment"># 用于记录alpha是否已经进行优化</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">            <span class="comment"># fXi:预测的类别</span></div><div class="line">            fXi = float(multiply(alphas, labelMat).T *</div><div class="line">                        (dataMatrix * dataMatrix[i, :].T)) + b</div><div class="line">            Ei = fXi - float(labelMat[i])  <span class="comment"># 误差</span></div><div class="line">            <span class="comment"># 不论正负间隔都会测试,且alpha在(0,C)之间</span></div><div class="line">            <span class="keyword">if</span> ((labelMat[i] * Ei &lt; -toler) <span class="keyword">and</span> (alphas[i] &lt; C)) <span class="keyword">or</span> \</div><div class="line">                    ((labelMat[i] * Ei &gt; toler) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)):</div><div class="line">                j = selectJrand(i, m)  <span class="comment"># 随机选择另一个alpha</span></div><div class="line">                <span class="comment"># 计算出j对应的误差Ej</span></div><div class="line">                fXj = float(multiply(alphas, labelMat).T *</div><div class="line">                            (dataMatrix * dataMatrix[j, :].T)) + b</div><div class="line">                Ej = fXj - float(labelMat[j])</div><div class="line">                alphaIold = alphas[i].copy()  <span class="comment"># 保存旧的2个alpha 以便后面比较</span></div><div class="line">                alphaJold = alphas[j].copy()</div><div class="line">                <span class="comment"># 计算L、H 用于把alpha[j]调整到[L,H]</span></div><div class="line">                <span class="keyword">if</span> labelMat[i] != labelMat[j]:</div><div class="line">                    L = max(<span class="number">0</span>, alphas[j] - alphas[i])</div><div class="line">                    H = min(C, C + alphas[j] - alphas[i])</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    L = max(<span class="number">0</span>, alphas[j] + alphas[i] - C)</div><div class="line">                    H = min(C, alphas[j] + alphas[i])</div><div class="line">                <span class="keyword">if</span> L == H:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'L==H'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># eta是最优修改量</span></div><div class="line">                eta = <span class="number">2.0</span> * dataMatrix[i, :] * dataMatrix[j, :].T - \</div><div class="line">                    dataMatrix[i, :] * dataMatrix[i, :].T - \</div><div class="line">                    dataMatrix[j, :] * dataMatrix[j, :].T</div><div class="line">                <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'eta&gt;=0'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># 计算一个新的alpha[j],并且调整到[L,H]</span></div><div class="line">                alphas[j] -= labelMat[j] * (Ei - Ej) / eta</div><div class="line">                alphas[j] = clipApha(alphas[j], H, L)</div><div class="line">                <span class="keyword">if</span> abs(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>:</div><div class="line">                    <span class="keyword">print</span> <span class="string">'j not moving enough'</span></div><div class="line">                    <span class="keyword">continue</span></div><div class="line">                <span class="comment"># 计算一个新的alpha[i] 变化方向和j相反</span></div><div class="line">                alphas[i] += labelMat[j] * labelMat[i] * \</div><div class="line">                    (alphaJold - alphas[j])</div><div class="line"></div><div class="line">                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T</div><div class="line"></div><div class="line">                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T</div><div class="line">                <span class="keyword">if</span> (<span class="number">0</span> &lt; alphas[i]) <span class="keyword">and</span> (C &gt; alphas[i]):</div><div class="line">                    b = b1</div><div class="line">                <span class="keyword">elif</span> (<span class="number">0</span> &lt; alphas[j]) <span class="keyword">and</span> (C &gt; alphas[j]):</div><div class="line">                    b = b2</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    b = (b1 + b2) / <span class="number">2.0</span></div><div class="line">                alphaPairsChanged += <span class="number">1</span></div><div class="line">                <span class="keyword">print</span> <span class="string">'iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>\</div><div class="line">                    .format(iter, i, alphaPairsChanged)</div><div class="line">        <span class="keyword">if</span> alphaPairsChanged == <span class="number">0</span>:</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            iter = <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> b, alphas</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotRes</span><span class="params">(data, label, weightsMat, bMat, alphasMat, drawSep=True)</span>:</span></div><div class="line">    svx = []; svy = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        <span class="keyword">if</span> alphasMat[i] &gt; <span class="number">0</span>:</div><div class="line">            svx.append(data[i][<span class="number">0</span>])</div><div class="line">            svy.append(data[i][<span class="number">1</span>])</div><div class="line">    b = bMat.A[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    x1cord = []; y1cord = []</div><div class="line">    x2cord = []; y2cord = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        tmp = data[i]</div><div class="line">        <span class="keyword">if</span> label[i] == <span class="number">1.0</span> :</div><div class="line">            x1cord.append(tmp[<span class="number">0</span>]); y1cord.append(tmp[<span class="number">1</span>])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            x2cord.append(tmp[<span class="number">0</span>]); y2cord.append(tmp[<span class="number">1</span>])</div><div class="line">    fig = plt.figure()</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>)</div><div class="line">    ax.scatter(x1cord, y1cord, s=<span class="number">40</span>, c=<span class="string">'red'</span>, marker=<span class="string">'o'</span>)</div><div class="line">    ax.scatter(x2cord, y2cord, s=<span class="number">40</span>, c=<span class="string">'blue'</span>, marker=<span class="string">'s'</span>)</div><div class="line">    ax.scatter(svx, svy, s=<span class="number">10</span>, c=<span class="string">'yellow'</span>, marker=<span class="string">'s'</span>)</div><div class="line">    <span class="keyword">if</span> drawSep:</div><div class="line">        x = arange(<span class="number">2.0</span>, <span class="number">6.0</span>, <span class="number">0.1</span>)</div><div class="line">        y = (-b-weightsMat.flat[<span class="number">0</span>]*x) / weightsMat.flat[<span class="number">1</span>]</div><div class="line">        ax.plot(x,y)</div><div class="line">    plt.xlabel(<span class="string">'X'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Y'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    分割超平面:w.T*x+b=0</div><div class="line">    w是个向量,data[i]也是个向量。维度一一对应</div><div class="line">    w = sum(alphas[i]*label[i]*data[i])</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcW</span><span class="params">(alphasMat, label, dataMat)</span>:</span></div><div class="line">    alphasArr = alphasMat.T.A[<span class="number">0</span>]</div><div class="line">    labelArr = array(label)</div><div class="line">    alphasMulLab = alphasArr * labelArr</div><div class="line">    <span class="comment"># (2,100) * (100,1) = (2,1)</span></div><div class="line">    <span class="keyword">print</span> dataMat.T * mat(alphasMulLab).T</div><div class="line">    weight = dataMat.T * mat(alphasMulLab).T</div><div class="line">    <span class="keyword">print</span> weight</div><div class="line">    <span class="keyword">return</span> weight</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 作为优化SMO的数据结构类</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></div><div class="line">        self.X = dataMatIn</div><div class="line">        self.labelMat = classLabels</div><div class="line">        self.C = C</div><div class="line">        self.tol = toler</div><div class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</div><div class="line">        self.alphas = mat(zeros((self.m, <span class="number">1</span>)))</div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        self.eCache = mat(zeros((self.m, <span class="number">2</span>)))</div><div class="line">        self.K = mat(zeros((self.m, self.m)))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</div><div class="line">            self.K[:, i] = kernelTrans(self.X, self.X[i, :], kTup)</div><div class="line"></div><div class="line"><span class="comment"># 计算给定数据点k的误差 =预测值-实际值</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        f(x) = sum(alpha[i] * label[i] * (x * x[i].T)) + b</div><div class="line">        (oS.X * oS.X[k, :].T) (100,2)*(2,1) = (100,1) 每个数据点和第k个数据点做内积</div><div class="line">        fXk:对于k点的模型预测值</div><div class="line">    '''</div><div class="line">    <span class="comment"># fXk = float(multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k, :].T)) + oS.b</span></div><div class="line">    fXk = float(multiply(oS.alphas, oS.labelMat).T * oS.K[:, k]) + oS.b</div><div class="line">    Ek = fXk - float(oS.labelMat[k])</div><div class="line">    <span class="keyword">return</span> Ek</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    启发式方法选择alpha[j]</div><div class="line">    选择</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></div><div class="line">    maxK = <span class="number">-1</span>; maxDeltaE = <span class="number">0</span>; Ej = <span class="number">0</span></div><div class="line">    oS.eCache[i] = [i, Ei]</div><div class="line">    validEcacheList = nonzero(oS.eCache[:, <span class="number">0</span>].A)[<span class="number">0</span>]</div><div class="line">    <span class="keyword">if</span> len(validEcacheList) &gt; <span class="number">1</span> :</div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</div><div class="line">            <span class="keyword">if</span> k == i :</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            Ek = calcEk(oS, k)</div><div class="line">            deltaE = abs(Ei - Ek)</div><div class="line">            <span class="keyword">if</span> deltaE &gt; maxDeltaE :</div><div class="line">                maxK = k; maxDeltaE = deltaE; Ej = Ek</div><div class="line">        <span class="comment">#return maxK, Ej</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        j = selectJrand(i, oS.m)</div><div class="line">        Ej = calcEk(oS, j)</div><div class="line">        maxK = j</div><div class="line">    <span class="keyword">return</span> maxK, Ej</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span></div><div class="line">    Ek = calcEk(oS, k)</div><div class="line">    oS.eCache[k] = [<span class="number">1</span>, Ek]</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    根据alphas[i]固定alphas[j],更新这两个值</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></div><div class="line">    Ei = calcEk(oS, i)</div><div class="line">    <span class="string">'''</span></div><div class="line">        违反KKT条件的两种情况</div><div class="line">        1.yi*Ei&lt;=1 and alphas[i]&lt;C</div><div class="line">        2.yi*Ei&gt;=1 and alphas[i]&gt;0</div><div class="line">        因为会存在一些噪声数据, 加入松弛变量允许一些点到分类平面的距离不满足原先的要求</div><div class="line">        原本的约束yi*(w*bi_b)&gt;=1 变为:yi*(w*bi_b)&gt;=1-S (i=1,2,... S&gt;=0)</div><div class="line">        这里的tol=1-S</div><div class="line">        详见：http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">    '''</div><div class="line">    <span class="keyword">if</span> ((oS.labelMat[i] * Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> \</div><div class="line">        ((oS.labelMat[i] * Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</div><div class="line">        j, Ej = selectJ(i, oS, Ei)</div><div class="line">        <span class="comment"># 保存旧的2个alpha 以便后面比较</span></div><div class="line">        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy()</div><div class="line"></div><div class="line">        <span class="string">'''</span></div><div class="line">            原问题得到的拉格朗日对偶问题约束条件sum(alphai * yi) = 0</div><div class="line">            仅考虑alpha[i],alpha[j]时,约束重写为:</div><div class="line">                alpha[i]*yi + alpha[j]*yj = z   </div><div class="line">                (alpha[i]&gt;=0 alpha[j]&gt;=0  z=-sum(alpha[k]yk) k!=i,j)</div><div class="line">            则更新前后的alpha满足:</div><div class="line">                alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">                yi和yj不是+1就是-1</div><div class="line">                讨论yi=yj 和yi!=yj的两种情况,得到alphaJnew的上下界</div><div class="line">                详见：http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">        '''</div><div class="line">        <span class="comment"># 计算L、H 用于把alpha[j]调整到[L,H]</span></div><div class="line">        <span class="keyword">if</span> oS.labelMat[i] != oS.labelMat[j]:</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</div><div class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</div><div class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</div><div class="line">        <span class="keyword">if</span> L == H:</div><div class="line">            <span class="keyword">print</span> <span class="string">'L==H'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line">        <span class="string">'''</span></div><div class="line">            更新alphas[j]解来源:</div><div class="line">            1.把拉格朗日对偶问题有alpha[i],alpha[j]单一式独展开的(一式)</div><div class="line">            2.由于有alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">            可以把alpha[i]消掉,带入一式,(得到二式)</div><div class="line">            3.二式对alpha[j]求导等于0</div><div class="line">            4.得到alpha[j]和alphaJold关系</div><div class="line">            推导详见:</div><div class="line">                http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">                http://blog.csdn.net/v_july_v/article/details/7624837</div><div class="line">        '''</div><div class="line">        <span class="comment"># alpha[j] updata formula alpha[j] = alpha[j] -/+ yi(Ei-Ej)/eta</span></div><div class="line">        <span class="comment"># eta=2*xi*xj -xi*xi.T-xj*xj.T : 实际上是度量两个样本i和j的相似性的</span></div><div class="line">        <span class="comment"># eta = 2.0 * oS.X[i, :] * oS.X[j, :].T - oS.X[i, :] * oS.X[i, :].T - \</span></div><div class="line">        <span class="comment">#             oS.X[j, :] * oS.X[j, :].T</span></div><div class="line"></div><div class="line">        <span class="comment"># use kernel function</span></div><div class="line">        eta = <span class="number">2.0</span> * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]</div><div class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">'eta&gt;=0'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta</div><div class="line">        oS.alphas[j] = clipApha(oS.alphas[j], H, L)</div><div class="line">        updateEk(oS, j)</div><div class="line">        <span class="keyword">if</span> abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span> :</div><div class="line">            <span class="keyword">print</span> <span class="string">'j not moving enough'</span></div><div class="line">            <span class="keyword">return</span> <span class="number">0</span></div><div class="line">        <span class="string">'''</span></div><div class="line">            由约束:alphaInew*yi + alphaJnew*yj = alphaIold*yi + alphaJold*yj = z</div><div class="line">            以及:yi*yi = 1 yj*yj = 1</div><div class="line">            得：</div><div class="line">            alphaInew*yi = alphaIold*yi + yj(alphaJold-alphaJnew)</div><div class="line">            alphaInew = alphaIold + yi*yj(alphaJold-alphaJnew)</div><div class="line">        '''</div><div class="line">        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])</div><div class="line">        updateEk(oS, i)</div><div class="line">        <span class="string">'''</span></div><div class="line">            http://blog.csdn.net/on2way/article/details/47730367</div><div class="line">        '''</div><div class="line">        <span class="comment"># b1 = oS.b - Ei - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T</span></div><div class="line">        <span class="comment"># b2 = oS.b - Ej - oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T</span></div><div class="line">        <span class="comment"># use kernel function</span></div><div class="line">        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]</div><div class="line">        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]</div><div class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]):</div><div class="line">            oS.b = b1</div><div class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]):</div><div class="line">            oS.b = b2</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            oS.b = (b1 + b2) / <span class="number">2.0</span></div><div class="line">        <span class="keyword">return</span> <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter, kTup=<span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span></div><div class="line">    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup)</div><div class="line">    iter = <span class="number">0</span></div><div class="line">    entireSet = <span class="keyword">True</span>; alphaPairsChanged = <span class="number">0</span></div><div class="line">    <span class="string">'''</span></div><div class="line">        1.entireSet = True 遍历所有数据点,更新alphas</div><div class="line">        2.entireSet 设为False 遍历非边界数据点,调整alpha (优先选择遍历非边界数据样本,因为非边界数据样本更有可能需要调整,边界数据样本常常不能得到进一步调整而留在边界上).</div><div class="line">        3.持续调整非边界数据点,直到没有更新一个alpha entireSet 再设为True</div><div class="line">        4.重新遍历所有数据点,更新alphas</div><div class="line">        5.如果整个集合的检验中又有数据样本被 进一步进化,则有必要再遍历非边界数据样本</div><div class="line">        6.反复交替遍历所有点和非边界点</div><div class="line">        7.直到所有数据点遍历后没有一个alpha变化 或者迭代次数到底预设值maxIter,退出循环</div><div class="line">    '''</div><div class="line">    <span class="keyword">while</span> (iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)) :</div><div class="line">        alphaPairsChanged = <span class="number">0</span></div><div class="line">        <span class="keyword">if</span> entireSet:</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">'fullSet, iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>.format(iter, i, alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># 取出alphas中在(0,C)之间的数值的index</span></div><div class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>)*(oS.alphas.A &lt; C))[<span class="number">0</span>]</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</div><div class="line">                alphaPairsChanged += innerL(i, oS)</div><div class="line">                <span class="keyword">print</span> <span class="string">'non-bound, iter: &#123;&#125; i:&#123;&#125;, pairs changed &#123;&#125;'</span>.format(iter, i ,alphaPairsChanged)</div><div class="line">            iter += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> entireSet:</div><div class="line">            entireSet = <span class="keyword">False</span></div><div class="line">        <span class="keyword">elif</span> alphaPairsChanged == <span class="number">0</span>:</div><div class="line">            entireSet = <span class="keyword">True</span></div><div class="line">        <span class="keyword">print</span> <span class="string">'iteration number: &#123;&#125;'</span>.format(iter)</div><div class="line">    <span class="keyword">return</span> oS.b, oS.alphas</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></div><div class="line">    m, n = shape(X)</div><div class="line">    K = mat(zeros((m, <span class="number">1</span>)))</div><div class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>] == <span class="string">'lin'</span>:</div><div class="line">        K = X * A.T</div><div class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>] == <span class="string">'rbf'</span>:</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</div><div class="line">            deltaRow = X[j, :] - A</div><div class="line">            K[j] = deltaRow * deltaRow.T</div><div class="line">        K = exp(K/(<span class="number">-1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>))</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">raise</span> NameError(<span class="string">'Houston We Have a Problem -- That Kernel is not recognized'</span>)</div><div class="line">    <span class="keyword">return</span> K</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testSVM</span><span class="params">(dataArr1, labelArr1, dataArr2, labelArr2, C, toler, maxIter, kTup)</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'start smoP'</span></div><div class="line">    b, alphas = smoP(dataArr1, labelArr1, C, toler, maxIter, kTup)</div><div class="line">    <span class="keyword">print</span> <span class="string">'finish smoP'</span></div><div class="line">    datMat = mat(dataArr1); labelMat = mat(labelArr1).transpose()</div><div class="line">    svInd = nonzero(alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</div><div class="line">    sVs = datMat[svInd]</div><div class="line">    labelSV = labelMat[svInd]</div><div class="line">    <span class="keyword">print</span> <span class="string">'ther are &#123;&#125; support Vectors'</span>.format(shape(sVs)[<span class="number">0</span>])</div><div class="line">    m, n = shape(datMat)</div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)</div><div class="line">        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict) != sign(labelArr1[i]):</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the training error rate is :&#123;&#125;'</span>.format(float(errorCount)/m)</div><div class="line"></div><div class="line">    <span class="comment"># test</span></div><div class="line">    errorCount = <span class="number">0</span></div><div class="line">    datMat = mat(dataArr2); labelMat = mat(labelArr2).transpose()</div><div class="line">    m, n = shape(datMat)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)</div><div class="line">        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b</div><div class="line">        <span class="keyword">if</span> sign(predict) != sign(labelArr2[i]):</div><div class="line">            errorCount += <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'the test error rate is :&#123;&#125;'</span>.format(float(errorCount)/m)</div><div class="line">    <span class="keyword">return</span> alphas, b</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line">    测试径向核函数</div><div class="line">'''</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testRbf</span><span class="params">(k1=<span class="number">1.3</span>)</span>:</span></div><div class="line">    <span class="comment"># training</span></div><div class="line">    dataArr1, labelArr1 = loadDataSet(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSetRBF.txt'</span>)</div><div class="line">    dataArr2, labelArr2 = loadDataSet(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch06\\testSetRBF2.txt'</span>)</div><div class="line">    alphas, b = testSVM(dataArr1, labelArr1, dataArr2, labelArr2, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">'rbf'</span>, k1))</div><div class="line">    <span class="keyword">return</span> dataArr1, labelArr1, alphas, b</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">img2vector</span><span class="params">(filename)</span>:</span></div><div class="line">    returnVect = zeros((<span class="number">1</span>, <span class="number">1024</span>))</div><div class="line">    fr = open(filename)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">        line = fr.readline()</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">            returnVect[<span class="number">0</span>, <span class="number">32</span> * i + j] = int(line[j])</div><div class="line">    <span class="keyword">return</span> returnVect</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadImages</span><span class="params">(dirName)</span>:</span></div><div class="line">    hwLabels = []</div><div class="line">    trainingFileList = listdir(dirName)</div><div class="line">    m = len(trainingFileList)</div><div class="line">    trainingMat = zeros((m, <span class="number">1024</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</div><div class="line">        fileNameStr = trainingFileList[i]</div><div class="line">        fileStr = fileNameStr.split(<span class="string">'.'</span>)[<span class="number">0</span>]</div><div class="line">        classNumStr = int(fileStr.split(<span class="string">'_'</span>)[<span class="number">0</span>])</div><div class="line">        <span class="keyword">if</span> classNumStr == <span class="number">9</span>:</div><div class="line">            hwLabels.append(<span class="number">-1</span>)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            hwLabels.append(<span class="number">1</span>)</div><div class="line">        trainingMat[i, :] = img2vector(<span class="string">'&#123;&#125;\\&#123;&#125;'</span>.format(dirName, fileNameStr))</div><div class="line">    <span class="keyword">return</span> trainingMat, hwLabels</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">testDigits</span><span class="params">(kTup=<span class="params">(<span class="string">'rbf'</span>, <span class="number">10</span>)</span>)</span>:</span></div><div class="line">    dataArr1, labelArr1 = loadImages(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\trainingDigits'</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'read trainingSet finish'</span></div><div class="line">    dataArr2, labelArr2 = loadImages(<span class="string">'D:\\IT_software\\python_code\\MachineLearningInAction\\machinelearninginaction\\Ch02\\testDigits'</span>)</div><div class="line">    <span class="keyword">print</span> <span class="string">'read testSet finish'</span></div><div class="line"></div><div class="line">    alphas, b = testSVM(dataArr1, labelArr1, dataArr2, labelArr2, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, kTup)</div><div class="line">    <span class="comment">#return dataArr1, labelArr1, alphas, b</span></div></pre></td></tr></table></figure>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/分类/" rel="tag"># 分类</a>
          
            <a href="/tags/SVM/" rel="tag"># SVM</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/06/04/Logistic回归分类算法/" rel="next" title="Logistic回归分类算法">
                <i class="fa fa-chevron-left"></i> Logistic回归分类算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Williams-Hao" />
          <p class="site-author-name" itemprop="name">Williams-Hao</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#定义"><span class="nav-number">1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#原理"><span class="nav-number">2.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#范数"><span class="nav-number">2.1.</span> <span class="nav-text">范数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义-1"><span class="nav-number">2.1.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数稀疏的好处"><span class="nav-number">2.1.2.</span> <span class="nav-text">参数稀疏的好处</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1）特征选择-Feature-Selection-："><span class="nav-number">2.1.2.1.</span> <span class="nav-text">1）特征选择(Feature Selection)：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2）可解释性-Interpretability-："><span class="nav-number">2.1.2.2.</span> <span class="nav-text">2）可解释性(Interpretability)：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#拉格朗日乘子法转化问题"><span class="nav-number">2.2.</span> <span class="nav-text">拉格朗日乘子法转化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型预测"><span class="nav-number">2.3.</span> <span class="nav-text">模型预测:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO算法求解问题"><span class="nav-number">2.4.</span> <span class="nav-text">SMO算法求解问题:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#非线性数据分类"><span class="nav-number">2.5.</span> <span class="nav-text">非线性数据分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#软间隔与正则化"><span class="nav-number">2.6.</span> <span class="nav-text">软间隔与正则化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代码"><span class="nav-number">3.</span> <span class="nav-text">代码</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Williams-Hao</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  

</body>
</html>
